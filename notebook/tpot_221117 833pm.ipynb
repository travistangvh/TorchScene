{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'tpot_221117 833pm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get new labels\n",
    "datalabels_iter7 = pd.read_csv('/Users/travistang/Documents/TorchScene/data/labels/INCA Outlet Image Dataset - oct2022+victor iter7label.csv',index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Victor_img_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>entity_id</th>\n",
       "      <th>saudagar_id</th>\n",
       "      <th>last_action</th>\n",
       "      <th>last_rule</th>\n",
       "      <th>last_sanction_datetime</th>\n",
       "      <th>outlet_photo_url</th>\n",
       "      <th>bank_acc_name</th>\n",
       "      <th>bank_acc_no</th>\n",
       "      <th>cnt_diff_entity_shared_bank_acc</th>\n",
       "      <th>...</th>\n",
       "      <th>restaurant_cart_inappropriateness_label</th>\n",
       "      <th>random</th>\n",
       "      <th>set</th>\n",
       "      <th>restaurant_store_cart_false_positive</th>\n",
       "      <th>restaurant_store_cart_false_negative</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction_score</th>\n",
       "      <th>victor_label_inappropriate_flag</th>\n",
       "      <th>group</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data</td>\n",
       "      <td>0012s00000NXGa6AAH</td>\n",
       "      <td>G285231232</td>\n",
       "      <td>SuspendMerchantPayout</td>\n",
       "      <td>IBT-M52-009-10A</td>\n",
       "      <td>2022-07-12 9:33:43</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "      <td>MOHAMAD RIDWAN</td>\n",
       "      <td>8.330079e+09</td>\n",
       "      <td>302.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.904060</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>1.0</td>\n",
       "      <td>test</td>\n",
       "      <td>burial_chamber 69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260</th>\n",
       "      <td>good_photos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G805388509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.575984</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>test</td>\n",
       "      <td>kindergarden_classroom 202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>good_photos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G024140195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.575580</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>test</td>\n",
       "      <td>bar 39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>good_photos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G268180486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.688902</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999392</td>\n",
       "      <td>1.0</td>\n",
       "      <td>test</td>\n",
       "      <td>outdoor 256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>good_photos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G290852858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.916971</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>test</td>\n",
       "      <td>ticket_booth 332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2414</th>\n",
       "      <td>good_photos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G318439890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.333878</td>\n",
       "      <td>val</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>val_train</td>\n",
       "      <td>ticket_booth 332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>data</td>\n",
       "      <td>0012s00000L6Dq9AAF</td>\n",
       "      <td>G559142822</td>\n",
       "      <td>SuspendMerchantGoResto</td>\n",
       "      <td>IBT-M52-015A</td>\n",
       "      <td>2022-08-25 10:45:04</td>\n",
       "      <td>https://api.midtrans.com/v1/onboardings/data/S...</td>\n",
       "      <td>CHANTIKA ALWA PUTRI HEDI</td>\n",
       "      <td>2.316349e+08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.269292</td>\n",
       "      <td>val</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.759632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>val_train</td>\n",
       "      <td>living_room 215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2416</th>\n",
       "      <td>good_photos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G854199120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.260184</td>\n",
       "      <td>val</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>val_train</td>\n",
       "      <td>roof_garden 290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417</th>\n",
       "      <td>good_photos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G028282079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.118239</td>\n",
       "      <td>val</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>val_train</td>\n",
       "      <td>loading_dock 216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4126</th>\n",
       "      <td>good_photos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G546012445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.052907</td>\n",
       "      <td>val</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>val_train</td>\n",
       "      <td>fabric_store 137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3980 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           source           entity_id saudagar_id             last_action  \\\n",
       "0            data  0012s00000NXGa6AAH  G285231232   SuspendMerchantPayout   \n",
       "2260  good_photos                 NaN  G805388509                     NaN   \n",
       "2261  good_photos                 NaN  G024140195                     NaN   \n",
       "2262  good_photos                 NaN  G268180486                     NaN   \n",
       "2268  good_photos                 NaN  G290852858                     NaN   \n",
       "...           ...                 ...         ...                     ...   \n",
       "2414  good_photos                 NaN  G318439890                     NaN   \n",
       "836          data  0012s00000L6Dq9AAF  G559142822  SuspendMerchantGoResto   \n",
       "2416  good_photos                 NaN  G854199120                     NaN   \n",
       "2417  good_photos                 NaN  G028282079                     NaN   \n",
       "4126  good_photos                 NaN  G546012445                     NaN   \n",
       "\n",
       "            last_rule last_sanction_datetime  \\\n",
       "0     IBT-M52-009-10A     2022-07-12 9:33:43   \n",
       "2260              NaN                    NaN   \n",
       "2261              NaN                    NaN   \n",
       "2262              NaN                    NaN   \n",
       "2268              NaN                    NaN   \n",
       "...               ...                    ...   \n",
       "2414              NaN                    NaN   \n",
       "836      IBT-M52-015A    2022-08-25 10:45:04   \n",
       "2416              NaN                    NaN   \n",
       "2417              NaN                    NaN   \n",
       "4126              NaN                    NaN   \n",
       "\n",
       "                                       outlet_photo_url  \\\n",
       "0     https://api.gobiz.co.id/v1/onboardings/data/SF...   \n",
       "2260  https://api.gobiz.co.id/v1/onboardings/data/SF...   \n",
       "2261  https://api.gobiz.co.id/v1/onboardings/data/SF...   \n",
       "2262  https://api.gobiz.co.id/v1/onboardings/data/SF...   \n",
       "2268  https://api.gobiz.co.id/v1/onboardings/data/SF...   \n",
       "...                                                 ...   \n",
       "2414  https://api.gobiz.co.id/v1/onboardings/data/SF...   \n",
       "836   https://api.midtrans.com/v1/onboardings/data/S...   \n",
       "2416  https://api.gobiz.co.id/v1/onboardings/data/SF...   \n",
       "2417  https://api.gobiz.co.id/v1/onboardings/data/SF...   \n",
       "4126  https://api.gobiz.co.id/v1/onboardings/data/SF...   \n",
       "\n",
       "                 bank_acc_name   bank_acc_no  cnt_diff_entity_shared_bank_acc  \\\n",
       "0               MOHAMAD RIDWAN  8.330079e+09                            302.0   \n",
       "2260                       NaN           NaN                              NaN   \n",
       "2261                       NaN           NaN                              NaN   \n",
       "2262                       NaN           NaN                              NaN   \n",
       "2268                       NaN           NaN                              NaN   \n",
       "...                        ...           ...                              ...   \n",
       "2414                       NaN           NaN                              NaN   \n",
       "836   CHANTIKA ALWA PUTRI HEDI  2.316349e+08                              4.0   \n",
       "2416                       NaN           NaN                              NaN   \n",
       "2417                       NaN           NaN                              NaN   \n",
       "4126                       NaN           NaN                              NaN   \n",
       "\n",
       "      ... restaurant_cart_inappropriateness_label    random   set  \\\n",
       "0     ...                                    True  0.904060  test   \n",
       "2260  ...                                   False  0.575984  test   \n",
       "2261  ...                                   False  0.575580  test   \n",
       "2262  ...                                   False  0.688902  test   \n",
       "2268  ...                                   False  0.916971  test   \n",
       "...   ...                                     ...       ...   ...   \n",
       "2414  ...                                   False  0.333878   val   \n",
       "836   ...                                   False  0.269292   val   \n",
       "2416  ...                                   False  0.260184   val   \n",
       "2417  ...                                   False  0.118239   val   \n",
       "4126  ...                                   False  0.052907   val   \n",
       "\n",
       "      restaurant_store_cart_false_positive  \\\n",
       "0                                      0.0   \n",
       "2260                                   0.0   \n",
       "2261                                   0.0   \n",
       "2262                                   0.0   \n",
       "2268                                   0.0   \n",
       "...                                    ...   \n",
       "2414                                   0.0   \n",
       "836                                    NaN   \n",
       "2416                                   0.0   \n",
       "2417                                   0.0   \n",
       "4126                                   0.0   \n",
       "\n",
       "     restaurant_store_cart_false_negative label prediction_score  \\\n",
       "0                                     0.0   NaN         0.000354   \n",
       "2260                                  1.0   NaN         0.999973   \n",
       "2261                                  1.0   NaN         0.996800   \n",
       "2262                                  1.0   NaN         0.999392   \n",
       "2268                                  0.0   NaN         0.999991   \n",
       "...                                   ...   ...              ...   \n",
       "2414                                  0.0   NaN         0.999969   \n",
       "836                                   NaN   NaN         0.759632   \n",
       "2416                                  1.0   NaN         0.992157   \n",
       "2417                                  1.0   NaN         0.999997   \n",
       "4126                                  0.0   NaN         0.999925   \n",
       "\n",
       "     victor_label_inappropriate_flag      group                        pred  \n",
       "0                                1.0       test           burial_chamber 69  \n",
       "2260                             0.0       test  kindergarden_classroom 202  \n",
       "2261                             0.0       test                      bar 39  \n",
       "2262                             1.0       test                 outdoor 256  \n",
       "2268                             0.0       test            ticket_booth 332  \n",
       "...                              ...        ...                         ...  \n",
       "2414                             0.0  val_train            ticket_booth 332  \n",
       "836                              1.0  val_train             living_room 215  \n",
       "2416                             1.0  val_train             roof_garden 290  \n",
       "2417                             0.0  val_train            loading_dock 216  \n",
       "4126                             0.0  val_train            fabric_store 137  \n",
       "\n",
       "[3980 rows x 38 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "victor_img_df = pd.read_csv('/Users/travistang/Documents/TorchScene/data/csv/fake_merchant_tagging_combined_set_result.csv',index_col = [0])\n",
    "victor_img_df = victor_img_df.query('outlet_photo_tagging!=\"Empty\"') # Removing empty images\n",
    "victor_img_df['restaurant_cart_inappropriateness_label'] = victor_img_df['prediction_score'] < 0.6\n",
    "\n",
    "# Replace Iter 1's labels with Iter 7's labels\n",
    "# victor_img_df['victor_label_inappropriate_flag'] = victor_img_df.apply(lambda row: 1 if row['outlet_photo_tagging'] == '1' else 0, axis=1) \n",
    "victor_img_df = victor_img_df.merge(datalabels_iter7['inappropriate_label_iter7'], how = 'left', left_on = 'saudagar_id', right_index=True)\n",
    "victor_img_df = victor_img_df.drop(columns=['victor_label_inappropriate_flag'])\n",
    "victor_img_df = victor_img_df.rename(columns={'inappropriate_label_iter7':'victor_label_inappropriate_flag'})\n",
    "# Note that outlet_photo_tagging == 1 are those that are tagged as bad by victor because they are fake. the rest are actually good labels\n",
    "\n",
    "# get group\n",
    "victor_img_df_val_set = pd.read_csv('/Users/travistang/Documents/TorchScene/result/intermediate/victor_img_tpot_df_result tpot_221109 122pm.csv')\n",
    "victor_img_df = victor_img_df.merge(victor_img_df_val_set[['saudagar_id','group']], how ='left', on ='saudagar_id')\n",
    "victor_img_df['group'] = victor_img_df['group'].fillna(victor_img_df['set'])\n",
    "\n",
    "# if a saudagar_id is in validation and test, keep it in validation and drop it from test\n",
    "victor_img_df = victor_img_df.sort_values('set',ascending=True).drop_duplicates(subset=['source','saudagar_id'],keep='last') \n",
    "\n",
    "df_prediction_result = pd.read_csv('/Users/travistang/Documents/TorchScene/result/csv/victor_set_resnet18.csv', index_col = [0])\n",
    "victor_img_df = victor_img_df.merge(df_prediction_result['pred'], how='inner', left_on = 'saudagar_id', right_index=True)\n",
    "\n",
    "victor_img_df = victor_img_df.dropna(subset=['victor_label_inappropriate_flag'])\n",
    "\n",
    "# Get the validation set only so I don't get biased\n",
    "victor_img_val_df = victor_img_df.query('set == \"val\"')\n",
    "\n",
    "victor_img_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Oct2022_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airfield 0</th>\n",
       "      <th>airplane_cabin 1</th>\n",
       "      <th>airport_terminal 2</th>\n",
       "      <th>alcove 3</th>\n",
       "      <th>alley 4</th>\n",
       "      <th>amphitheater 5</th>\n",
       "      <th>amusement_arcade 6</th>\n",
       "      <th>amusement_park 7</th>\n",
       "      <th>outdoor 8</th>\n",
       "      <th>aquarium 9</th>\n",
       "      <th>...</th>\n",
       "      <th>wet_bar 358</th>\n",
       "      <th>wheat_field 359</th>\n",
       "      <th>wind_farm 360</th>\n",
       "      <th>windmill 361</th>\n",
       "      <th>yard 362</th>\n",
       "      <th>youth_hostel 363</th>\n",
       "      <th>zen_garden 364</th>\n",
       "      <th>outlet_id</th>\n",
       "      <th>inappropriate_label</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25414.0</th>\n",
       "      <td>2.139274e-07</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>5.341184e-03</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>9.620219e-06</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.967058e-06</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>2.443199e-06</td>\n",
       "      <td>3.614401e-06</td>\n",
       "      <td>1.677299e-06</td>\n",
       "      <td>8.493458e-05</td>\n",
       "      <td>0.004273</td>\n",
       "      <td>3.606791e-06</td>\n",
       "      <td>G000007135</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8729.0</th>\n",
       "      <td>1.175332e-06</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>1.025874e-04</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>1.486519e-04</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>1.816568e-05</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>3.128750e-06</td>\n",
       "      <td>9.179776e-06</td>\n",
       "      <td>1.101525e-05</td>\n",
       "      <td>2.041509e-03</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>4.518936e-05</td>\n",
       "      <td>G000051136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15083.0</th>\n",
       "      <td>1.970256e-06</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>1.132516e-05</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>1.095202e-04</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>3.195454e-04</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>2.209334e-06</td>\n",
       "      <td>1.783030e-05</td>\n",
       "      <td>3.196685e-05</td>\n",
       "      <td>7.799471e-04</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>2.635096e-04</td>\n",
       "      <td>G000162899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26366.0</th>\n",
       "      <td>2.726324e-06</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>1.223479e-02</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>6.293109e-06</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>2.232212e-05</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>2.561831e-06</td>\n",
       "      <td>6.468579e-06</td>\n",
       "      <td>1.141056e-05</td>\n",
       "      <td>1.837652e-05</td>\n",
       "      <td>0.006582</td>\n",
       "      <td>1.709939e-04</td>\n",
       "      <td>G000224606</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207.0</th>\n",
       "      <td>2.137902e-08</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>9.194782e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>9.634322e-07</td>\n",
       "      <td>0.008203</td>\n",
       "      <td>0.001622</td>\n",
       "      <td>1.499786e-07</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>2.604203e-08</td>\n",
       "      <td>5.356325e-08</td>\n",
       "      <td>1.718631e-07</td>\n",
       "      <td>5.244693e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>8.652056e-08</td>\n",
       "      <td>G000224896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30517.0</th>\n",
       "      <td>4.026394e-06</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>8.751875e-03</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>1.261907e-05</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>1.577824e-05</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>2.119998e-05</td>\n",
       "      <td>2.131157e-05</td>\n",
       "      <td>1.032646e-05</td>\n",
       "      <td>1.803221e-04</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>1.103344e-03</td>\n",
       "      <td>G987336045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26012.0</th>\n",
       "      <td>1.040386e-06</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>1.985723e-04</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>3.115472e-06</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>2.270017e-06</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>5.551453e-07</td>\n",
       "      <td>6.444111e-07</td>\n",
       "      <td>5.649167e-07</td>\n",
       "      <td>1.306322e-05</td>\n",
       "      <td>0.001769</td>\n",
       "      <td>5.651703e-06</td>\n",
       "      <td>G991154114</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30648.0</th>\n",
       "      <td>4.006243e-04</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>8.886862e-04</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>8.098442e-05</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>4.211369e-05</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>1.206198e-03</td>\n",
       "      <td>2.263173e-03</td>\n",
       "      <td>1.173708e-03</td>\n",
       "      <td>2.118064e-04</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>1.086916e-03</td>\n",
       "      <td>G993559621</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30681.0</th>\n",
       "      <td>1.028183e-04</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>6.808520e-03</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>7.076355e-05</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>1.150000e-04</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>2.043070e-04</td>\n",
       "      <td>6.766088e-04</td>\n",
       "      <td>2.385151e-04</td>\n",
       "      <td>4.731342e-04</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>5.668707e-04</td>\n",
       "      <td>G996745489</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30696.0</th>\n",
       "      <td>5.126690e-04</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>6.616162e-03</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>5.307864e-05</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>1.164195e-04</td>\n",
       "      <td>0.004745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>4.602717e-03</td>\n",
       "      <td>9.164810e-03</td>\n",
       "      <td>3.649984e-03</td>\n",
       "      <td>4.080345e-04</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>5.874141e-04</td>\n",
       "      <td>G997665142</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30563 rows × 368 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           airfield 0  airplane_cabin 1  airport_terminal 2      alcove 3  \\\n",
       "25414.0  2.139274e-07          0.000009            0.000022  5.341184e-03   \n",
       "8729.0   1.175332e-06          0.000005            0.000076  1.025874e-04   \n",
       "15083.0  1.970256e-06          0.000023            0.000921  1.132516e-05   \n",
       "26366.0  2.726324e-06          0.000631            0.000017  1.223479e-02   \n",
       "2207.0   2.137902e-08          0.000001            0.000067  9.194782e-07   \n",
       "...               ...               ...                 ...           ...   \n",
       "30517.0  4.026394e-06          0.000781            0.000207  8.751875e-03   \n",
       "26012.0  1.040386e-06          0.000566            0.000361  1.985723e-04   \n",
       "30648.0  4.006243e-04          0.000021            0.000067  8.886862e-04   \n",
       "30681.0  1.028183e-04          0.000041            0.000122  6.808520e-03   \n",
       "30696.0  5.126690e-04          0.000129            0.000108  6.616162e-03   \n",
       "\n",
       "          alley 4  amphitheater 5  amusement_arcade 6  amusement_park 7  \\\n",
       "25414.0  0.000297    9.620219e-06            0.000250          0.000004   \n",
       "8729.0   0.000170    1.486519e-04            0.000595          0.001543   \n",
       "15083.0  0.001191    1.095202e-04            0.000144          0.010354   \n",
       "26366.0  0.000304    6.293109e-06            0.000534          0.000039   \n",
       "2207.0   0.000004    9.634322e-07            0.008203          0.001622   \n",
       "...           ...             ...                 ...               ...   \n",
       "30517.0  0.003511    1.261907e-05            0.000161          0.000054   \n",
       "26012.0  0.001025    3.115472e-06            0.001498          0.000154   \n",
       "30648.0  0.000014    8.098442e-05            0.000014          0.000221   \n",
       "30681.0  0.000256    7.076355e-05            0.000031          0.000144   \n",
       "30696.0  0.000047    5.307864e-05            0.000034          0.000242   \n",
       "\n",
       "            outdoor 8  aquarium 9  ...  wet_bar 358  wheat_field 359  \\\n",
       "25414.0  3.967058e-06    0.000024  ...     0.001111     2.443199e-06   \n",
       "8729.0   1.816568e-05    0.000050  ...     0.000060     3.128750e-06   \n",
       "15083.0  3.195454e-04    0.000720  ...     0.000061     2.209334e-06   \n",
       "26366.0  2.232212e-05    0.000116  ...     0.000529     2.561831e-06   \n",
       "2207.0   1.499786e-07    0.000023  ...     0.000015     2.604203e-08   \n",
       "...               ...         ...  ...          ...              ...   \n",
       "30517.0  1.577824e-05    0.001119  ...     0.001056     2.119998e-05   \n",
       "26012.0  2.270017e-06    0.000104  ...     0.000053     5.551453e-07   \n",
       "30648.0  4.211369e-05    0.000972  ...     0.000155     1.206198e-03   \n",
       "30681.0  1.150000e-04    0.000743  ...     0.000211     2.043070e-04   \n",
       "30696.0  1.164195e-04    0.004745  ...     0.000433     4.602717e-03   \n",
       "\n",
       "         wind_farm 360  windmill 361      yard 362  youth_hostel 363  \\\n",
       "25414.0   3.614401e-06  1.677299e-06  8.493458e-05          0.004273   \n",
       "8729.0    9.179776e-06  1.101525e-05  2.041509e-03          0.000012   \n",
       "15083.0   1.783030e-05  3.196685e-05  7.799471e-04          0.000025   \n",
       "26366.0   6.468579e-06  1.141056e-05  1.837652e-05          0.006582   \n",
       "2207.0    5.356325e-08  1.718631e-07  5.244693e-07          0.000004   \n",
       "...                ...           ...           ...               ...   \n",
       "30517.0   2.131157e-05  1.032646e-05  1.803221e-04          0.005164   \n",
       "26012.0   6.444111e-07  5.649167e-07  1.306322e-05          0.001769   \n",
       "30648.0   2.263173e-03  1.173708e-03  2.118064e-04          0.000106   \n",
       "30681.0   6.766088e-04  2.385151e-04  4.731342e-04          0.000295   \n",
       "30696.0   9.164810e-03  3.649984e-03  4.080345e-04          0.000265   \n",
       "\n",
       "         zen_garden 364   outlet_id  inappropriate_label  group  \n",
       "25414.0    3.606791e-06  G000007135                  1.0  train  \n",
       "8729.0     4.518936e-05  G000051136                  0.0  train  \n",
       "15083.0    2.635096e-04  G000162899                  0.0  train  \n",
       "26366.0    1.709939e-04  G000224606                  1.0  train  \n",
       "2207.0     8.652056e-08  G000224896                  0.0  train  \n",
       "...                 ...         ...                  ...    ...  \n",
       "30517.0    1.103344e-03  G987336045                  1.0  train  \n",
       "26012.0    5.651703e-06  G991154114                  1.0  train  \n",
       "30648.0    1.086916e-03  G993559621                  1.0  train  \n",
       "30681.0    5.668707e-04  G996745489                  1.0  train  \n",
       "30696.0    5.874141e-04  G997665142                  1.0  train  \n",
       "\n",
       "[30563 rows x 368 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read travis' labels from oct2022 set\n",
    "oct2022_df = pd.read_csv('/Users/travistang/Documents/TorchScene/data/labels/Oct2022_TravisLabel.csv')\n",
    "\n",
    "# # Preprocess victor's label\n",
    "# victor_new_df = pd.read_csv('/Users/travistang/Documents/TorchScene/data/labels/Travis Fake_Merchant_Tagging_2022 - Copy of ML training set addition 2.csv').drop(columns = ['random','set'])\n",
    "# victor_new_df['victor_label_inappropriate_flag'] = victor_new_df.apply(lambda row: 1 if row['victor_label_inappropriate_flag'] == '1' else 0, axis=1)  # Note that outlet_photo_tagging == 1 are those that are tagged as bad by victor because they are fake. the rest are actually good labels\n",
    "\n",
    "# # Get victor's label if travis has not labelled\n",
    "# oct2022_df = oct2022_df.merge(victor_new_df, how = 'left', on = 'restaurant_photo_url')\n",
    "# oct2022_df['travis_inappropriate_label'].fillna(oct2022_df['victor_label_inappropriate_flag'], inplace=True)\n",
    "# oct2022_df['inappropriate_label'] = oct2022_df['victor_label_inappropriate_flag'].combine_first(oct2022_df['travis_inappropriate_label'])\n",
    "\n",
    "# Replace Iter 1's labels with Iter 7's labels\n",
    "# victor_img_df['victor_label_inappropriate_flag'] = victor_img_df.apply(lambda row: 1 if row['outlet_photo_tagging'] == '1' else 0, axis=1) \n",
    "oct2022_df = oct2022_df.merge(datalabels_iter7['inappropriate_label_iter7'], how = 'left', left_on = 'outlet_id', right_index=True)\n",
    "oct2022_df = oct2022_df.drop(columns=['travis_inappropriate_label'])\n",
    "oct2022_df = oct2022_df.rename(columns={'inappropriate_label_iter7':'inappropriate_label'})\n",
    "\n",
    "# Get the embedding for oct2022 set\n",
    "df_prediction_result_oct2022_gooddata = pd.read_csv('/Users/travistang/Documents/TorchScene/result/intermediate/resnet18/oct2022_gooddata_resnet18.csv', index_col = [0])\n",
    "df_prediction_result_oct2022_baddata = pd.read_csv('/Users/travistang/Documents/TorchScene/result/intermediate/resnet18/oct2022_baddata_resnet18.csv', index_col = [0])\n",
    "\n",
    "df_prediction_result_oct2022 = pd.concat([df_prediction_result_oct2022_gooddata, df_prediction_result_oct2022_baddata])\n",
    "\n",
    "df_prediction_result_oct2022 = df_prediction_result_oct2022.merge(oct2022_df[['outlet_id','inappropriate_label','group']], \n",
    "                                    how = 'left', left_index=True,right_on='outlet_id')\n",
    "\n",
    "df_prediction_result_oct2022.set_index('outlet_id')\n",
    "\n",
    "# Drop images that have not been labelled\n",
    "df_prediction_result_oct2022.dropna(inplace=True)\n",
    "\n",
    "df_prediction_result_oct2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Baseline Performance of Restaurant Stall Cart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.98      0.80       802\n",
      "         1.0       0.96      0.47      0.63       714\n",
      "\n",
      "    accuracy                           0.74      1516\n",
      "   macro avg       0.82      0.73      0.72      1516\n",
      "weighted avg       0.81      0.74      0.72      1516\n",
      "\n",
      "Validation Set performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.98      0.80       265\n",
      "         1.0       0.96      0.48      0.64       239\n",
      "\n",
      "    accuracy                           0.74       504\n",
      "   macro avg       0.82      0.73      0.72       504\n",
      "weighted avg       0.81      0.74      0.72       504\n",
      "\n",
      "Test Set performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.98      0.78       987\n",
      "         1.0       0.96      0.46      0.62       973\n",
      "\n",
      "    accuracy                           0.72      1960\n",
      "   macro avg       0.80      0.72      0.70      1960\n",
      "weighted avg       0.80      0.72      0.70      1960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Set performance\")\n",
    "print(classification_report(victor_img_df.query(\"group == 'val_train'\")['victor_label_inappropriate_flag'],\n",
    "                            victor_img_df.query(\"group == 'val_train'\")['restaurant_cart_inappropriateness_label']))\n",
    "\n",
    "print(\"Validation Set performance\")\n",
    "print(classification_report(victor_img_df.query(\"group == 'val_test'\")['victor_label_inappropriate_flag'],\n",
    "                            victor_img_df.query(\"group == 'val_test'\")['restaurant_cart_inappropriateness_label']))\n",
    "\n",
    "\n",
    "print(\"Test Set performance\")\n",
    "print(classification_report(victor_img_df.query(\"group == 'test'\")['victor_label_inappropriate_flag'],\n",
    "                            victor_img_df.query(\"group == 'test'\")['restaurant_cart_inappropriateness_label']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay at 0x7f84777a3f40>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "PrecisionRecallDisplay.from_predictions(victor_img_df.query(\"group == 'test'\")['victor_label_inappropriate_flag'],\n",
    "                                        1- victor_img_df.query(\"group == 'test'\")['prediction_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "victor_label_inappropriate_flag                                       0.0   1.0\n",
      "pred                       restaurant_cart_inappropriateness_label             \n",
      "airplane_cabin 1           False                                      1.0   NaN\n",
      "alcove 3                   False                                      2.0   6.0\n",
      "                           True                                       1.0   5.0\n",
      "alley 4                    False                                      3.0   7.0\n",
      "amusement_arcade 6         False                                     39.0   NaN\n",
      "amusement_park 7           False                                      5.0   NaN\n",
      "aquarium 9                 True                                       NaN   8.0\n",
      "archive 14                 False                                      1.0   1.0\n",
      "                           True                                       NaN   7.0\n",
      "art_gallery 19             False                                      1.0   1.0\n",
      "art_school 20              False                                      2.0   1.0\n",
      "art_studio 21              False                                      8.0   4.0\n",
      "                           True                                       1.0   NaN\n",
      "artists_loft 22            False                                      3.0   2.0\n",
      "asia 330                   False                                      2.0   NaN\n",
      "attic 26                   False                                      2.0   4.0\n",
      "                           True                                       NaN   1.0\n",
      "auditorium 27              False                                      NaN   1.0\n",
      "                           True                                       NaN   3.0\n",
      "badlands 30                True                                       NaN   1.0\n",
      "ball_pit 34                False                                      2.0   NaN\n",
      "                           True                                       NaN   1.0\n",
      "bank_vault 37              False                                      2.0   2.0\n",
      "barn 40                    False                                      NaN   1.0\n",
      "barndoor 41                False                                      3.0  14.0\n",
      "                           True                                       2.0   5.0\n",
      "baseball 312               False                                      2.0   NaN\n",
      "basement 43                False                                      8.0  20.0\n",
      "                           True                                       NaN  31.0\n",
      "bathroom 45                False                                      1.0   2.0\n",
      "beach 48                   True                                       NaN   2.0\n",
      "beauty_salon 50            False                                      3.0   1.0\n",
      "bedchamber 51              False                                      1.0   1.0\n",
      "beer_hall 54               True                                       NaN   1.0\n",
      "berth 55                   False                                      NaN  10.0\n",
      "                           True                                       NaN   6.0\n",
      "boardwalk 57               False                                      NaN   2.0\n",
      "                           True                                       NaN   3.0\n",
      "boat_deck 58               False                                      1.0   1.0\n",
      "bookstore 60               False                                      1.0   NaN\n",
      "bowling_alley 64           False                                      1.0   NaN\n",
      "                           True                                       NaN   1.0\n",
      "bullring 68                False                                      NaN   1.0\n",
      "burial_chamber 69          True                                       NaN   9.0\n",
      "butchers_shop 72           False                                      6.0   NaN\n",
      "cafeteria 75               False                                      1.0   1.0\n",
      "campsite 76                False                                      1.0   1.0\n",
      "candy_store 80             False                                     20.0   NaN\n",
      "                           True                                       2.0   NaN\n",
      "carrousel 83               False                                      1.0   NaN\n",
      "catacomb 85                False                                      NaN   1.0\n",
      "                           True                                       1.0   9.0\n",
      "cemetery 86                False                                      1.0   NaN\n",
      "chalet 87                  False                                      NaN   4.0\n",
      "chemistry_lab 88           False                                      1.0   NaN\n",
      "childs_room 89             False                                      7.0   2.0\n",
      "classroom 92               False                                      5.0   4.0\n",
      "                           True                                       NaN   3.0\n",
      "clean_room 93              False                                      NaN   1.0\n",
      "closet 95                  False                                      NaN  13.0\n",
      "                           True                                       NaN  34.0\n",
      "clothing_store 96          False                                      1.0   2.0\n",
      "                           True                                       NaN   2.0\n",
      "cockpit 98                 False                                      NaN   1.0\n",
      "coffee_shop 99             False                                      7.0   1.0\n",
      "construction_site 103      False                                      1.0   NaN\n",
      "                           True                                       NaN   1.0\n",
      "corridor 106               False                                      NaN   4.0\n",
      "                           True                                       NaN   2.0\n",
      "courtyard 109              False                                      NaN   5.0\n",
      "crevasse 111               True                                       NaN   2.0\n",
      "crosswalk 112              False                                      1.0   NaN\n",
      "delicatessen 114           False                                      1.0   NaN\n",
      "department_store 115       False                                      1.0   NaN\n",
      "dining_hall 120            False                                      2.0   NaN\n",
      "dining_room 121            False                                      1.0   2.0\n",
      "discotheque 122            False                                      1.0   NaN\n",
      "                           True                                       1.0   NaN\n",
      "door 129                   False                                      3.0  16.0\n",
      "                           True                                       NaN  14.0\n",
      "dorm_room 124              False                                      5.0  16.0\n",
      "                           True                                       NaN   2.0\n",
      "dressing_room 126          False                                      NaN   2.0\n",
      "driveway 127               False                                      NaN   8.0\n",
      "                           True                                       NaN   6.0\n",
      "drugstore 128              False                                      2.0   NaN\n",
      "elevator_lobby 130         False                                      NaN   4.0\n",
      "elevator_shaft 131         False                                      4.0   4.0\n",
      "                           True                                       NaN  13.0\n",
      "embassy 132                False                                      1.0   NaN\n",
      "engine_room 133            False                                      2.0   1.0\n",
      "                           True                                       NaN   1.0\n",
      "excavation 136             False                                      1.0   NaN\n",
      "exterior 32                False                                      2.0   3.0\n",
      "fabric_store 137           False                                      3.0   1.0\n",
      "                           True                                       NaN   1.0\n",
      "fastfood_restaurant 139    False                                     81.0   NaN\n",
      "                           True                                       4.0   NaN\n",
      "fire_escape 143            False                                      4.0   2.0\n",
      "fire_station 144           False                                      4.0   NaN\n",
      "food_court 148             False                                      6.0   1.0\n",
      "football_field 149         False                                      1.0   NaN\n",
      "galley 155                 False                                      3.0   1.0\n",
      "gas_station 158            False                                      9.0   1.0\n",
      "grotto 167                 True                                       NaN   2.0\n",
      "home_office 176            False                                      2.0   NaN\n",
      "home_theater 177           False                                      3.0   NaN\n",
      "                           True                                       1.0   NaN\n",
      "hospital 178               False                                      1.0   NaN\n",
      "                           True                                       NaN   2.0\n",
      "hospital_room 179          False                                      NaN   3.0\n",
      "hot_spring 180             True                                       NaN   3.0\n",
      "house 183                  False                                      NaN   2.0\n",
      "ice_cream_parlor 185       False                                     26.0   1.0\n",
      "ice_floe 186               True                                       NaN   3.0\n",
      "igloo 191                  False                                      NaN   1.0\n",
      "                           True                                       NaN  17.0\n",
      "indoor 146                 False                                      5.0   NaN\n",
      "indoor 147                 False                                      1.0   2.0\n",
      "indoor 156                 False                                     21.0  21.0\n",
      "                           True                                       NaN   5.0\n",
      "indoor 160                 False                                      3.0   NaN\n",
      "indoor 165                 False                                      1.0   NaN\n",
      "                           True                                       NaN   2.0\n",
      "indoor 168                 False                                      NaN   1.0\n",
      "indoor 212                 False                                      2.0   NaN\n",
      "indoor 235                 False                                      1.0   3.0\n",
      "indoor 236                 False                                      1.0   NaN\n",
      "indoor 255                 False                                      3.0   3.0\n",
      "                           True                                       NaN   1.0\n",
      "indoor 315                 False                                      NaN   1.0\n",
      "indoor 325                 False                                      NaN   1.0\n",
      "                           True                                       NaN   2.0\n",
      "indoor 61                  False                                     44.0   NaN\n",
      "indoor 63                  False                                      NaN   6.0\n",
      "                           True                                       NaN   6.0\n",
      "indoor 71                  False                                      4.0   NaN\n",
      "industrial_area 192        False                                      1.0   NaN\n",
      "interior 33                False                                      NaN   5.0\n",
      "islet 194                  True                                       NaN   1.0\n",
      "jail_cell 196              False                                      NaN  18.0\n",
      "                           True                                       NaN   6.0\n",
      "jewelry_shop 198           False                                      1.0   NaN\n",
      "                           True                                       1.0   NaN\n",
      "junkyard 199               False                                      1.0   NaN\n",
      "kindergarden_classroom 202 False                                     13.0   NaN\n",
      "kitchen 203                False                                      2.0   5.0\n",
      "landfill 206               True                                       NaN   1.0\n",
      "laundromat 208             False                                      2.0   1.0\n",
      "living_room 215            False                                      NaN   3.0\n",
      "                           True                                       NaN   1.0\n",
      "loading_dock 216           False                                     26.0  15.0\n",
      "lobby 217                  False                                      1.0   NaN\n",
      "lock_chamber 218           False                                      1.0   NaN\n",
      "locker_room 219            False                                      4.0   6.0\n",
      "manufactured_home 221      False                                      NaN   1.0\n",
      "marsh 224                  True                                       NaN   2.0\n",
      "mausoleum 226              True                                       NaN   1.0\n",
      "medina 227                 False                                      1.0   3.0\n",
      "mezzanine 228              False                                      6.0   5.0\n",
      "motel 231                  False                                      5.0   1.0\n",
      "music_studio 238           False                                      3.0   1.0\n",
      "                           True                                       1.0   1.0\n",
      "natural 205                True                                       NaN   3.0\n",
      "natural_history_museum 239 False                                      1.0   1.0\n",
      "nursery 240                True                                       1.0   NaN\n",
      "ocean 243                  True                                       NaN   1.0\n",
      "ocean_deep 342             True                                       NaN   6.0\n",
      "office 244                 False                                      1.0   NaN\n",
      "office_building 245        True                                       NaN   2.0\n",
      "office_cubicles 246        False                                      4.0   NaN\n",
      "                           True                                       NaN   8.0\n",
      "outdoor 119                False                                     37.0   6.0\n",
      "outdoor 123                False                                      4.0  19.0\n",
      "outdoor 157                False                                      NaN   1.0\n",
      "outdoor 161                False                                     52.0   2.0\n",
      "outdoor 166                False                                      1.0   NaN\n",
      "outdoor 181                False                                      1.0   NaN\n",
      "outdoor 184                False                                      NaN   1.0\n",
      "outdoor 189                True                                       NaN   2.0\n",
      "outdoor 201                False                                      3.0  10.0\n",
      "                           True                                       NaN   1.0\n",
      "outdoor 213                False                                      NaN   1.0\n",
      "outdoor 223                False                                     12.0   NaN\n",
      "outdoor 237                False                                      1.0   NaN\n",
      "outdoor 256                False                                      3.0   1.0\n",
      "outdoor 326                False                                      NaN   1.0\n",
      "outdoor 351                False                                      1.0   NaN\n",
      "outdoor 47                 False                                      2.0   NaN\n",
      "outdoor 74                 False                                      2.0   1.0\n",
      "pantry 253                 False                                     14.0   NaN\n",
      "                           True                                       1.0   NaN\n",
      "parking_lot 257            False                                      2.0   2.0\n",
      "                           True                                       NaN   2.0\n",
      "patio 259                  False                                      8.0  18.0\n",
      "pavilion 260               False                                      1.0   NaN\n",
      "pet_shop 261               False                                     49.0   NaN\n",
      "pharmacy 262               False                                      3.0   NaN\n",
      "phone_booth 263            False                                     11.0   3.0\n",
      "picnic_area 265            False                                      NaN   1.0\n",
      "platform 320               False                                      2.0   1.0\n",
      "platform 337               False                                      1.0   NaN\n",
      "playground 268             False                                      1.0   1.0\n",
      "playroom 269               False                                     16.0   6.0\n",
      "porch 272                  False                                      5.0  34.0\n",
      "                           True                                       1.0   NaN\n",
      "public 25                  True                                       NaN   1.0\n",
      "raceway 276                True                                       NaN   1.0\n",
      "rainforest 279             True                                       NaN   1.0\n",
      "reception 280              False                                     11.0   3.0\n",
      "recreation_room 281        False                                      2.0   3.0\n",
      "repair_shop 282            False                                     11.0   8.0\n",
      "                           True                                       NaN   3.0\n",
      "restaurant 284             False                                      2.0   NaN\n",
      "restaurant_kitchen 285     False                                      1.0   NaN\n",
      "restaurant_patio 286       False                                     16.0   1.0\n",
      "rice_paddy 287             False                                      NaN   1.0\n",
      "rodeo 17                   False                                      1.0   NaN\n",
      "roof_garden 290            False                                      3.0   9.0\n",
      "ruin 292                   False                                      NaN   1.0\n",
      "sand 116                   True                                       NaN  78.0\n",
      "sandbox 294                False                                      NaN   1.0\n",
      "sauna 295                  False                                      NaN   1.0\n",
      "                           True                                       NaN   2.0\n",
      "science_museum 297         False                                      3.0   1.0\n",
      "server_room 298            False                                     12.0   7.0\n",
      "shed 299                   False                                      2.0   2.0\n",
      "shoe_shop 300              False                                      5.0   NaN\n",
      "                           True                                       NaN   1.0\n",
      "shop 31                    False                                      2.0   NaN\n",
      "shopfront 301              False                                     27.0   1.0\n",
      "shower 303                 True                                       NaN  30.0\n",
      "sky 306                    True                                       NaN  51.0\n",
      "slum 308                   False                                      8.0  11.0\n",
      "                           True                                       NaN   1.0\n",
      "snowfield 309              True                                       NaN  14.0\n",
      "stable 311                 False                                      NaN   4.0\n",
      "staircase 317              False                                      NaN   2.0\n",
      "                           True                                       NaN   2.0\n",
      "storage_room 318           False                                     19.0   3.0\n",
      "                           True                                       NaN   1.0\n",
      "supermarket 321            False                                      9.0   1.0\n",
      "                           True                                       2.0   NaN\n",
      "sushi_bar 322              False                                      8.0   1.0\n",
      "swimming_hole 324          True                                       NaN   1.0\n",
      "television_studio 329      False                                      5.0   1.0\n",
      "throne_room 331            False                                      6.0   NaN\n",
      "ticket_booth 332           False                                    167.0   8.0\n",
      "toyshop 335                False                                      6.0   NaN\n",
      "tree_house 339             False                                      2.0   6.0\n",
      "                           True                                       NaN   1.0\n",
      "trench 340                 False                                      NaN  10.0\n",
      "                           True                                       NaN   1.0\n",
      "utility_room 343           False                                      2.0   3.0\n",
      "volcano 350                True                                       NaN   1.0\n",
      "waiting_room 352           False                                      2.0   2.0\n",
      "                           True                                       NaN   1.0\n",
      "wet_bar 358                False                                      4.0   NaN\n",
      "wheat_field 359            True                                       NaN   2.0\n",
      "yard 362                   False                                      3.0   4.0\n",
      "youth_hostel 363           False                                      1.0   NaN\n",
      "                           True                                       NaN   1.0\n",
      "zen_garden 364             False                                      NaN   2.0\n",
      "                           True                                       NaN   4.0\n"
     ]
    }
   ],
   "source": [
    "# Finding categories that are highly correlated with inappropriate categories\n",
    "victor_img_val_explore_str = victor_img_val_df.pivot_table(index = ['pred','restaurant_cart_inappropriateness_label'], columns = 'victor_label_inappropriate_flag', aggfunc = len)['source']\n",
    "\n",
    "print(victor_img_val_explore_str.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TPOT to train a decision tree classifier for the 365-length vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating TPOT set for victor_img_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/travistang/opt/anaconda3/envs/torch-scene/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Creating a dataframe for tpot only\n",
    "oct2022_tpot_df = df_prediction_result_oct2022.copy()\n",
    "oct2022_tpot_df = oct2022_tpot_df.set_index('outlet_id')\n",
    "# oct2022_tpot_df = oct2022_tpot_df.rename(columns = {'travis_inappropriate_label':'inappropriate_flag'})\n",
    "\n",
    "target_col = 'inappropriate_label' \n",
    "\n",
    "# Making sure this is idempotent\n",
    "oct_2022_X_train = oct2022_tpot_df.query('group == \"train\"').drop(columns=[target_col,'group'])\n",
    "oct_2022_y_train = oct2022_tpot_df.query('group == \"train\"').drop(columns=['group'])[target_col]\n",
    "oct_2022_X_test = oct2022_tpot_df.query('group == \"val\"').drop(columns=[target_col,'group'])\n",
    "oct_2022_y_test = oct2022_tpot_df.query('group == \"val\"').drop(columns=['group'])[target_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating TPOT Set for Oct_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Creating a dataframe for tpot only\n",
    "victor_img_tpot_df = victor_img_df.merge(df_prediction_result.drop(columns=['pred']), how='left', left_on = 'saudagar_id', right_index=True)\n",
    "victor_img_tpot_df = victor_img_tpot_df.dropna(subset=['airfield 0']) \n",
    "victor_img_tpot_df = victor_img_tpot_df.set_index('saudagar_id')\n",
    "victor_img_tpot_df = victor_img_tpot_df.query('set == \"val\"')\n",
    "\n",
    "victor_img_tpot_df = victor_img_tpot_df.drop(columns = ['source', 'entity_id', 'last_action', 'last_rule',\n",
    "       'last_sanction_datetime', 'outlet_photo_url', 'bank_acc_name',\n",
    "       'bank_acc_no', 'cnt_diff_entity_shared_bank_acc',\n",
    "       'diff_entity_id_shared_bank_acc',\n",
    "       'cnt_diff_entity_outlet_shared_bank_acc',\n",
    "       'diff_entity_outlet_id_shared_bank_acc', 'gofood_id', 'cnt_all_order',\n",
    "       'sum_gmv_all_order', 'cnt_co', 'sum_gmv_co', 'cnt_maf_defect_order',\n",
    "       'sum_gmv_maf_defect_order', 'cnt_cadf', 'sum_gmv_cadf', 'percent_co',\n",
    "       'percent_good_order', 'percent_bad_order', 'photo',\n",
    "       'outlet_photo_tagging', 'flag_fake_merchant', 'prediction_score',\n",
    "       'restaurant_cart_inappropriateness_label',\n",
    "       'random','set',\n",
    "       'restaurant_store_cart_false_positive','restaurant_store_cart_false_negative','label','pred','group'])\n",
    "\n",
    "victor_img_tpot_df = victor_img_tpot_df.rename(columns = {'victor_label_inappropriate_flag': 'inappropriate_label'})\n",
    "\n",
    "target_col = 'inappropriate_label' #restaurant_store_cart_false_positive\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(victor_img_tpot_df.drop(columns=[target_col]), \n",
    "                                                    victor_img_tpot_df[target_col],\n",
    "                                                    train_size=0.75, \n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Making sure this is idempotent\n",
    "# victor_img_df_val_set = pd.read_csv('/Users/travistang/Documents/TorchScene/result/intemediate/victor_img_tpot_df_result tpot_221108 122pm.csv')\n",
    "# X_train = victor_img_df_val_set.query('group == \"val_train\"').set_index('saudagar_id').drop(columns=['victor_label_inappropriate_flag','pred','group','inappropriate_prob','outlet_photo_url','prediction_score'])\n",
    "# y_train = victor_img_df_val_set.query('group == \"val_train\"')['victor_label_inappropriate_flag']\n",
    "# X_test = victor_img_df_val_set.query('group == \"val_test\"').set_index('saudagar_id').drop(columns=['victor_label_inappropriate_flag','pred','group','inappropriate_prob','outlet_photo_url','prediction_score'])\n",
    "# y_test = victor_img_df_val_set.query('group == \"val_test\"')['victor_label_inappropriate_flag']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging all TPOT sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = pd.concat([X_train, oct_2022_X_train])\n",
    "y_train_full = pd.concat([y_train, oct_2022_y_train])\n",
    "X_test = pd.concat([X_test, oct_2022_X_test])\n",
    "y_test = pd.concat([y_test, oct_2022_y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define oversampling strategy\n",
    "sample = imblearn.over_sampling.SMOTE(random_state = 42)\n",
    "X_train, y_train = sample.fit_resample(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training for TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 operators have been imported by TPOT.\n",
      "                                                                              \n",
      "Generation 1 - Current Pareto front scores:\n",
      "                                                                               \n",
      "-1\t0.9866368431194557\tMLPClassifier(input_matrix, MLPClassifier__alpha=0.0001, MLPClassifier__learning_rate_init=0.001)\n",
      "                                                                               \n",
      "Generation 2 - Current Pareto front scores:\n",
      "                                                                               \n",
      "-1\t0.9866368431194557\tMLPClassifier(input_matrix, MLPClassifier__alpha=0.0001, MLPClassifier__learning_rate_init=0.001)\n",
      "                                                                               \n",
      "Generation 3 - Current Pareto front scores:\n",
      "                                                                               \n",
      "-1\t0.9866368431194557\tMLPClassifier(input_matrix, MLPClassifier__alpha=0.0001, MLPClassifier__learning_rate_init=0.001)\n",
      "                                                                               \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TPOTClassifier(config_dict={&#x27;sklearn.cluster.FeatureAgglomeration&#x27;: {&#x27;affinity&#x27;: [&#x27;euclidean&#x27;,\n",
       "                                                                                  &#x27;l1&#x27;,\n",
       "                                                                                  &#x27;l2&#x27;,\n",
       "                                                                                  &#x27;manhattan&#x27;,\n",
       "                                                                                  &#x27;cosine&#x27;],\n",
       "                                                                     &#x27;linkage&#x27;: [&#x27;ward&#x27;,\n",
       "                                                                                 &#x27;complete&#x27;,\n",
       "                                                                                 &#x27;average&#x27;]},\n",
       "                            &#x27;sklearn.decomposition.FastICA&#x27;: {&#x27;tol&#x27;: array([0.  , 0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 ,\n",
       "       0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 1.  ])},\n",
       "                            &#x27;sklearn.decomposition.PCA&#x27;: {&#x27;iterated_power...\n",
       "                            &#x27;sklearn.preprocessing.RobustScaler&#x27;: {},\n",
       "                            &#x27;sklearn.preprocessing.StandardScaler&#x27;: {},\n",
       "                            &#x27;tpot.builtins.OneHotEncoder&#x27;: {&#x27;minimum_fraction&#x27;: [0.05,\n",
       "                                                                                 0.1,\n",
       "                                                                                 0.15,\n",
       "                                                                                 0.2,\n",
       "                                                                                 0.25],\n",
       "                                                            &#x27;sparse&#x27;: [False],\n",
       "                                                            &#x27;threshold&#x27;: [10]},\n",
       "                            &#x27;tpot.builtins.ZeroCount&#x27;: {}},\n",
       "               generations=3, n_jobs=-1, population_size=6, random_state=35,\n",
       "               scoring=&#x27;roc_auc&#x27;, subsample=1, template=&#x27;Classifier&#x27;,\n",
       "               use_dask=True, verbosity=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TPOTClassifier</label><div class=\"sk-toggleable__content\"><pre>TPOTClassifier(config_dict={&#x27;sklearn.cluster.FeatureAgglomeration&#x27;: {&#x27;affinity&#x27;: [&#x27;euclidean&#x27;,\n",
       "                                                                                  &#x27;l1&#x27;,\n",
       "                                                                                  &#x27;l2&#x27;,\n",
       "                                                                                  &#x27;manhattan&#x27;,\n",
       "                                                                                  &#x27;cosine&#x27;],\n",
       "                                                                     &#x27;linkage&#x27;: [&#x27;ward&#x27;,\n",
       "                                                                                 &#x27;complete&#x27;,\n",
       "                                                                                 &#x27;average&#x27;]},\n",
       "                            &#x27;sklearn.decomposition.FastICA&#x27;: {&#x27;tol&#x27;: array([0.  , 0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 ,\n",
       "       0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 1.  ])},\n",
       "                            &#x27;sklearn.decomposition.PCA&#x27;: {&#x27;iterated_power...\n",
       "                            &#x27;sklearn.preprocessing.RobustScaler&#x27;: {},\n",
       "                            &#x27;sklearn.preprocessing.StandardScaler&#x27;: {},\n",
       "                            &#x27;tpot.builtins.OneHotEncoder&#x27;: {&#x27;minimum_fraction&#x27;: [0.05,\n",
       "                                                                                 0.1,\n",
       "                                                                                 0.15,\n",
       "                                                                                 0.2,\n",
       "                                                                                 0.25],\n",
       "                                                            &#x27;sparse&#x27;: [False],\n",
       "                                                            &#x27;threshold&#x27;: [10]},\n",
       "                            &#x27;tpot.builtins.ZeroCount&#x27;: {}},\n",
       "               generations=3, n_jobs=-1, population_size=6, random_state=35,\n",
       "               scoring=&#x27;roc_auc&#x27;, subsample=1, template=&#x27;Classifier&#x27;,\n",
       "               use_dask=True, verbosity=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TPOTClassifier(config_dict={'sklearn.cluster.FeatureAgglomeration': {'affinity': ['euclidean',\n",
       "                                                                                  'l1',\n",
       "                                                                                  'l2',\n",
       "                                                                                  'manhattan',\n",
       "                                                                                  'cosine'],\n",
       "                                                                     'linkage': ['ward',\n",
       "                                                                                 'complete',\n",
       "                                                                                 'average']},\n",
       "                            'sklearn.decomposition.FastICA': {'tol': array([0.  , 0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 ,\n",
       "       0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 1.  ])},\n",
       "                            'sklearn.decomposition.PCA': {'iterated_power...\n",
       "                            'sklearn.preprocessing.RobustScaler': {},\n",
       "                            'sklearn.preprocessing.StandardScaler': {},\n",
       "                            'tpot.builtins.OneHotEncoder': {'minimum_fraction': [0.05,\n",
       "                                                                                 0.1,\n",
       "                                                                                 0.15,\n",
       "                                                                                 0.2,\n",
       "                                                                                 0.25],\n",
       "                                                            'sparse': [False],\n",
       "                                                            'threshold': [10]},\n",
       "                            'tpot.builtins.ZeroCount': {}},\n",
       "               generations=3, n_jobs=-1, population_size=6, random_state=35,\n",
       "               scoring='roc_auc', subsample=1, template='Classifier',\n",
       "               use_dask=True, verbosity=3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot_config = {\n",
    "\n",
    "    # Classifiers\n",
    "    # 'sklearn.naive_bayes.GaussianNB': {\n",
    "    # },\n",
    "\n",
    "    # 'sklearn.naive_bayes.BernoulliNB': {\n",
    "    #     'alpha': [1e-3, 1e-2, 1e-1, 1., 10., 100.],\n",
    "    #     'fit_prior': [True, False]\n",
    "    # },\n",
    "\n",
    "    # 'sklearn.naive_bayes.MultinomialNB': {\n",
    "    #     'alpha': [1e-3, 1e-2, 1e-1, 1., 10., 100.],\n",
    "    #     'fit_prior': [True, False]\n",
    "    # },\n",
    "\n",
    "    # 'sklearn.tree.DecisionTreeClassifier': {\n",
    "    #     'criterion': [\"gini\", \"entropy\"],\n",
    "    #     'max_depth': range(1, 11),\n",
    "    #     'min_samples_split': range(2, 21),\n",
    "    #     'min_samples_leaf': range(1, 21)\n",
    "    # },\n",
    "\n",
    "    # 'sklearn.ensemble.ExtraTreesClassifier': {\n",
    "    #     'n_estimators': [100],\n",
    "    #     'criterion': [\"gini\", \"entropy\"],\n",
    "    #     'max_features': np.arange(0.05, 1.01, 0.05),\n",
    "    #     'min_samples_split': range(2, 21),\n",
    "    #     'min_samples_leaf': range(1, 21),\n",
    "    #     'bootstrap': [True, False]\n",
    "    # },\n",
    "\n",
    "    # 'sklearn.ensemble.RandomForestClassifier': {\n",
    "    #     'n_estimators': [100],\n",
    "    #     'criterion': [\"gini\", \"entropy\"],\n",
    "    #     'max_features': np.arange(0.05, 1.01, 0.05),\n",
    "    #     'min_samples_split': range(2, 21),\n",
    "    #     'min_samples_leaf':  range(1, 21),\n",
    "    #     'bootstrap': [True, False]\n",
    "    # },\n",
    "\n",
    "    # 'sklearn.ensemble.GradientBoostingClassifier': {\n",
    "    #     'n_estimators': [100],\n",
    "    #     'learning_rate': [1e-3, 1e-2, 1e-1, 0.5, 1.],\n",
    "    #     'max_depth': range(1, 11),\n",
    "    #     'min_samples_split': range(2, 21),\n",
    "    #     'min_samples_leaf': range(1, 21),\n",
    "    #     'subsample': np.arange(0.05, 1.01, 0.05),\n",
    "    #     'max_features': np.arange(0.05, 1.01, 0.05)\n",
    "    # },\n",
    "\n",
    "    # 'sklearn.neighbors.KNeighborsClassifier': {\n",
    "    #     'n_neighbors': range(1, 101),\n",
    "    #     'weights': [\"uniform\", \"distance\"],\n",
    "    #     'p': [1, 2]\n",
    "    # },\n",
    "\n",
    "    # 'sklearn.svm.LinearSVC': {\n",
    "    #     'penalty': [\"l1\", \"l2\"],\n",
    "    #     'loss': [\"hinge\", \"squared_hinge\"],\n",
    "    #     'dual': [True, False],\n",
    "    #     'tol': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1],\n",
    "    #     'C': [1e-4, 1e-3, 1e-2, 1e-1, 0.5, 1., 5., 10., 15., 20., 25.]\n",
    "    # },\n",
    "\n",
    "    # 'sklearn.linear_model.LogisticRegression': {\n",
    "    #     'penalty': [\"l1\", \"l2\"],\n",
    "    #     'C': [1e-4, 1e-3, 1e-2, 1e-1, 0.5, 1., 5., 10., 15., 20., 25.],\n",
    "    #     'dual': [True, False]\n",
    "    # },\n",
    "\n",
    "    # 'xgboost.XGBClassifier': {\n",
    "    #     'n_estimators': [100],\n",
    "    #     'max_depth': range(1, 11),\n",
    "    #     'learning_rate': [1e-3, 1e-2, 1e-1, 0.5, 1.],\n",
    "    #     'subsample': np.arange(0.05, 1.01, 0.05),\n",
    "    #     'min_child_weight': range(1, 21),\n",
    "    #     'n_jobs': [1],\n",
    "    #     'verbosity': [0]\n",
    "    # },\n",
    "\n",
    "    # 'sklearn.linear_model.SGDClassifier': {\n",
    "    #     'loss': ['log', 'hinge', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "    #     'penalty': ['elasticnet'],\n",
    "    #     'alpha': [0.0, 0.01, 0.001],\n",
    "    #     'learning_rate': ['invscaling', 'constant'],\n",
    "    #     'fit_intercept': [True, False],\n",
    "    #     'l1_ratio': [0.25, 0.0, 1.0, 0.75, 0.5],\n",
    "    #     'eta0': [0.1, 1.0, 0.01],\n",
    "    #     'power_t': [0.5, 0.0, 1.0, 0.1, 100.0, 10.0, 50.0]\n",
    "    # },\n",
    "\n",
    "    'sklearn.neural_network.MLPClassifier': {\n",
    "        'alpha': [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "        'learning_rate_init': [1e-3, 1e-2, 1e-1, 0.5, 1.]\n",
    "    },\n",
    "\n",
    "    # Preprocesssors\n",
    "    'sklearn.preprocessing.Binarizer': {\n",
    "        'threshold': np.arange(0.0, 1.01, 0.05)\n",
    "    },\n",
    "\n",
    "    'sklearn.decomposition.FastICA': {\n",
    "        'tol': np.arange(0.0, 1.01, 0.05)\n",
    "    },\n",
    "\n",
    "    'sklearn.cluster.FeatureAgglomeration': {\n",
    "        'linkage': ['ward', 'complete', 'average'],\n",
    "        'affinity': ['euclidean', 'l1', 'l2', 'manhattan', 'cosine']\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.MaxAbsScaler': {\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.MinMaxScaler': {\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.Normalizer': {\n",
    "        'norm': ['l1', 'l2', 'max']\n",
    "    },\n",
    "\n",
    "    'sklearn.kernel_approximation.Nystroem': {\n",
    "        'kernel': ['rbf', 'cosine', 'chi2', 'laplacian', 'polynomial', 'poly', 'linear', 'additive_chi2', 'sigmoid'],\n",
    "        'gamma': np.arange(0.0, 1.01, 0.05),\n",
    "        'n_components': range(1, 11)\n",
    "    },\n",
    "\n",
    "    'sklearn.decomposition.PCA': {\n",
    "        'svd_solver': ['randomized'],\n",
    "        'iterated_power': range(1, 11)\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.PolynomialFeatures': {\n",
    "        'degree': [2],\n",
    "        'include_bias': [False],\n",
    "        'interaction_only': [False]\n",
    "    },\n",
    "\n",
    "    'sklearn.kernel_approximation.RBFSampler': {\n",
    "        'gamma': np.arange(0.0, 1.01, 0.05)\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.RobustScaler': {\n",
    "    },\n",
    "\n",
    "    'sklearn.preprocessing.StandardScaler': {\n",
    "    },\n",
    "\n",
    "    'tpot.builtins.ZeroCount': {\n",
    "    },\n",
    "\n",
    "    'tpot.builtins.OneHotEncoder': {\n",
    "        'minimum_fraction': [0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "        'sparse': [False],\n",
    "        'threshold': [10]\n",
    "    },\n",
    "\n",
    "    # Selectors\n",
    "    'sklearn.feature_selection.SelectFwe': {\n",
    "        'alpha': np.arange(0, 0.05, 0.001),\n",
    "        'score_func': {\n",
    "            'sklearn.feature_selection.f_classif': None\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'sklearn.feature_selection.SelectPercentile': {\n",
    "        'percentile': range(1, 100),\n",
    "        'score_func': {\n",
    "            'sklearn.feature_selection.f_classif': None\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'sklearn.feature_selection.VarianceThreshold': {\n",
    "        'threshold': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.2]\n",
    "    },\n",
    "\n",
    "    'sklearn.feature_selection.RFE': {\n",
    "        'step': np.arange(0.05, 1.01, 0.05),\n",
    "        'estimator': {\n",
    "            'sklearn.ensemble.ExtraTreesClassifier': {\n",
    "                'n_estimators': [100],\n",
    "                'criterion': ['gini', 'entropy'],\n",
    "                'max_features': np.arange(0.05, 1.01, 0.05)\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'sklearn.feature_selection.SelectFromModel': {\n",
    "        'threshold': np.arange(0, 1.01, 0.05),\n",
    "        'estimator': {\n",
    "            'sklearn.ensemble.ExtraTreesClassifier': {\n",
    "                'n_estimators': [100],\n",
    "                'criterion': ['gini', 'entropy'],\n",
    "                'max_features': np.arange(0.05, 1.01, 0.05)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "tpot = TPOTClassifier(generations=3, \n",
    "                      population_size=6,  # if we set this to 20 it does not run\n",
    "                      verbosity=3,\n",
    "                      config_dict=tpot_config,\n",
    "                      max_eval_time_mins = 5,\n",
    "                      random_state=35,\n",
    "                      use_dask=True,\n",
    "                      subsample = 1,\n",
    "                      template = 'Classifier',\n",
    "                      scoring = 'roc_auc',\n",
    "                      n_jobs=-1) # to enusre that we optimize precision at certain points\n",
    "\n",
    "tpot.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9637330336301547\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# tpot = ExtraTreesClassifier(bootstrap=False, \n",
    "#                             criterion='gini', \n",
    "#                             max_features=0.5,\n",
    "#                             min_samples_leaf=15, \n",
    "#                             min_samples_split=12,\n",
    "#                             n_estimators=100,\n",
    "#                             random_state = 35)\n",
    "\n",
    "# tpot.fit(X_train, y_train)\n",
    "# print(tpot.score(X_train, y_train))\n",
    "\n",
    "# RandomForestClassifier(input_matrix, RandomForestClassifier__bootstrap=False, RandomForestClassifier__criterion=entropy, RandomForestClassifier__max_features=0.2, RandomForestClassifier__min_samples_leaf=20, RandomForestClassifier__min_samples_split=11, RandomForestClassifier__n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "try:\n",
    "    tpot.export(f'../tpot/{filename}.py')\n",
    "except:\n",
    "    with open(f'../tpot/{filename}.pkl', 'wb') as model_file:\n",
    "        pickle.dump(tpot, model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the final result dataset\n",
    "df_test = victor_img_df.merge(df_prediction_result.drop(columns=['pred']), how='left', left_on = 'saudagar_id', right_index=True)\n",
    "df_test = df_test.query('set == \"test\"')\n",
    "df_test = df_test.dropna(subset=['airfield 0']) \n",
    "df_test = df_test.set_index('saudagar_id')\n",
    "df_test = df_test.drop(columns = ['source', 'entity_id', 'last_action', 'last_rule',\n",
    "       'last_sanction_datetime', 'outlet_photo_url', 'bank_acc_name',\n",
    "       'bank_acc_no', 'cnt_diff_entity_shared_bank_acc',\n",
    "       'diff_entity_id_shared_bank_acc',\n",
    "       'cnt_diff_entity_outlet_shared_bank_acc',\n",
    "       'diff_entity_outlet_id_shared_bank_acc', 'gofood_id', 'cnt_all_order',\n",
    "       'sum_gmv_all_order', 'cnt_co', 'sum_gmv_co', 'cnt_maf_defect_order',\n",
    "       'sum_gmv_maf_defect_order', 'cnt_cadf', 'sum_gmv_cadf', 'percent_co',\n",
    "       'percent_good_order', 'percent_bad_order', 'photo',\n",
    "       'outlet_photo_tagging', 'flag_fake_merchant', 'prediction_score',\n",
    "       'restaurant_cart_inappropriateness_label',\n",
    "       'random','set',\n",
    "       'restaurant_store_cart_false_positive','restaurant_store_cart_false_negative','label','pred','set','group'])\n",
    "\n",
    "tpot_df = pd.concat([oct2022_tpot_df.drop(columns=['group']),victor_img_tpot_df,df_test.rename(columns = {'victor_label_inappropriate_flag':'inappropriate_label'})])\n",
    "\n",
    "# Making predictions on inappropriateness using classifier\n",
    "tpot_df['inappropriate_prob'] = tpot.predict_proba(tpot_df.drop(columns=['inappropriate_label']))[:,1]\n",
    "\n",
    "# assigning group\n",
    "tpot_df['group'] = ''\n",
    "tpot_df.loc[tpot_df.index.isin(victor_img_df_val_set.query('group == \"val_train\"').saudagar_id),'group']='train'\n",
    "tpot_df.loc[tpot_df.index.isin(victor_img_df_val_set.query('group == \"val_test\"').saudagar_id),'group']='val'\n",
    "tpot_df.loc[tpot_df.index.isin(oct_2022_X_train.index),'group']='train'\n",
    "tpot_df.loc[tpot_df.index.isin(oct_2022_X_test.index),'group']='val'\n",
    "tpot_df.loc[tpot_df.index.isin(victor_img_df.query('set == \"test\"').saudagar_id),'group']='test'\n",
    "\n",
    "# assigning source\n",
    "tpot_df['source'] = ''\n",
    "tpot_df.loc[tpot_df.index.isin(victor_img_df.query('source==\"data\"').saudagar_id),'source']='data'\n",
    "tpot_df.loc[tpot_df.index.isin(victor_img_df.query('source==\"good_photos\"').saudagar_id),'source']='good_photos'\n",
    "tpot_df.loc[tpot_df.index.isin(df_prediction_result_oct2022_gooddata.index),'source']='oct2022_gooddata'\n",
    "tpot_df.loc[tpot_df.index.isin(df_prediction_result_oct2022_baddata.index),'source']='oct2022_baddata'\n",
    "\n",
    "# assigning set\n",
    "tpot_df['set'] = ''\n",
    "tpot_df.loc[tpot_df.index.isin(victor_img_df.query('source==\"data\"').saudagar_id),'set']='victor'\n",
    "tpot_df.loc[tpot_df.index.isin(victor_img_df.query('source==\"good_photos\"').saudagar_id),'set']='victor'\n",
    "tpot_df.loc[tpot_df.index.isin(df_prediction_result_oct2022_gooddata.index),'set']='oct2022'\n",
    "tpot_df.loc[tpot_df.index.isin(df_prediction_result_oct2022_baddata.index),'set']='oct2022'\n",
    "\n",
    "# Merging results\n",
    "tpot_df = tpot_df.drop_duplicates()\n",
    "tpot_df[['inappropriate_prob']].to_csv(f'/Users/travistang/Documents/TorchScene/result/intermediate/{filename}/tpot_df.csv')\n",
    "\n",
    "# Generate a one-off dataset that contains the URL\n",
    "tpot_df = tpot_df.merge(victor_img_df[['saudagar_id','outlet_photo_url']], how='left',left_index = True, right_on = 'saudagar_id').set_index('saudagar_id')\n",
    "tpot_df = tpot_df.merge(oct2022_df[['outlet_id','restaurant_photo_url']], how='left',left_index = True, right_on = 'outlet_id')\n",
    "tpot_df['outlet_photo_url'] = tpot_df['outlet_photo_url'].fillna(tpot_df['restaurant_photo_url'])\n",
    "tpot_df = tpot_df.drop(columns = ['restaurant_photo_url'])\n",
    "\n",
    "tpot_df = tpot_df.set_index('outlet_id', drop=True)\n",
    "\n",
    "tpot_df = tpot_df.drop_duplicates()\n",
    "tpot_df[['outlet_photo_url','group','source','set','inappropriate_label']].to_csv(f'/Users/travistang/Documents/TorchScene/data/csv/oct2022+victor.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airfield 0</th>\n",
       "      <th>airplane_cabin 1</th>\n",
       "      <th>airport_terminal 2</th>\n",
       "      <th>alcove 3</th>\n",
       "      <th>alley 4</th>\n",
       "      <th>amphitheater 5</th>\n",
       "      <th>amusement_arcade 6</th>\n",
       "      <th>amusement_park 7</th>\n",
       "      <th>outdoor 8</th>\n",
       "      <th>aquarium 9</th>\n",
       "      <th>...</th>\n",
       "      <th>windmill 361</th>\n",
       "      <th>yard 362</th>\n",
       "      <th>youth_hostel 363</th>\n",
       "      <th>zen_garden 364</th>\n",
       "      <th>inappropriate_label</th>\n",
       "      <th>inappropriate_prob</th>\n",
       "      <th>group</th>\n",
       "      <th>source</th>\n",
       "      <th>set</th>\n",
       "      <th>outlet_photo_url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outlet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>G000007135</th>\n",
       "      <td>2.139274e-07</td>\n",
       "      <td>8.877712e-06</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>5.341184e-03</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>9.620219e-06</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.967058e-06</td>\n",
       "      <td>2.369832e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.677299e-06</td>\n",
       "      <td>8.493458e-05</td>\n",
       "      <td>0.004273</td>\n",
       "      <td>3.606791e-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.720853e-01</td>\n",
       "      <td>train</td>\n",
       "      <td>oct2022_gooddata</td>\n",
       "      <td>oct2022</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G000051136</th>\n",
       "      <td>1.175332e-06</td>\n",
       "      <td>5.057530e-06</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>1.025874e-04</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>1.486519e-04</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>1.816568e-05</td>\n",
       "      <td>5.027789e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.101525e-05</td>\n",
       "      <td>2.041509e-03</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>4.518936e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.455604e-03</td>\n",
       "      <td>train</td>\n",
       "      <td>oct2022_gooddata</td>\n",
       "      <td>oct2022</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G000162899</th>\n",
       "      <td>1.970256e-06</td>\n",
       "      <td>2.253714e-05</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>1.132516e-05</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>1.095202e-04</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>3.195454e-04</td>\n",
       "      <td>7.204539e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>3.196685e-05</td>\n",
       "      <td>7.799471e-04</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>2.635096e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.428664e-01</td>\n",
       "      <td>train</td>\n",
       "      <td>oct2022_gooddata</td>\n",
       "      <td>oct2022</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G000224606</th>\n",
       "      <td>2.726324e-06</td>\n",
       "      <td>6.312387e-04</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>1.223479e-02</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>6.293109e-06</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>2.232212e-05</td>\n",
       "      <td>1.159015e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.141056e-05</td>\n",
       "      <td>1.837652e-05</td>\n",
       "      <td>0.006582</td>\n",
       "      <td>1.709939e-04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.549897e-01</td>\n",
       "      <td>train</td>\n",
       "      <td>oct2022_gooddata</td>\n",
       "      <td>oct2022</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G000224896</th>\n",
       "      <td>2.137902e-08</td>\n",
       "      <td>1.091339e-06</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>9.194782e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>9.634322e-07</td>\n",
       "      <td>0.008203</td>\n",
       "      <td>0.001622</td>\n",
       "      <td>1.499786e-07</td>\n",
       "      <td>2.290889e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.718631e-07</td>\n",
       "      <td>5.244693e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>8.652056e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.189991e-21</td>\n",
       "      <td>train</td>\n",
       "      <td>oct2022_gooddata</td>\n",
       "      <td>oct2022</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G506427626</th>\n",
       "      <td>8.964552e-05</td>\n",
       "      <td>2.812791e-04</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>2.508922e-02</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>9.770808e-06</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>1.187956e-04</td>\n",
       "      <td>2.093857e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>6.131802e-04</td>\n",
       "      <td>1.581691e-04</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>4.262529e-04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.999838e-01</td>\n",
       "      <td>test</td>\n",
       "      <td>data</td>\n",
       "      <td>victor</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G050841328</th>\n",
       "      <td>2.620510e-06</td>\n",
       "      <td>2.401831e-05</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>3.385504e-02</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>7.213193e-06</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>1.453368e-05</td>\n",
       "      <td>1.549785e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>2.462671e-06</td>\n",
       "      <td>1.477298e-03</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>1.822124e-04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.283699e-02</td>\n",
       "      <td>test</td>\n",
       "      <td>data</td>\n",
       "      <td>victor</td>\n",
       "      <td>https://api.midtrans.com/v1/onboardings/data/S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G436006229</th>\n",
       "      <td>1.548531e-04</td>\n",
       "      <td>7.768250e-04</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>3.176613e-02</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>7.352784e-05</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>1.506499e-04</td>\n",
       "      <td>1.673141e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>4.613529e-03</td>\n",
       "      <td>1.266370e-04</td>\n",
       "      <td>0.012177</td>\n",
       "      <td>3.188663e-04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>test</td>\n",
       "      <td>data</td>\n",
       "      <td>victor</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G798587885</th>\n",
       "      <td>1.630283e-07</td>\n",
       "      <td>5.286926e-08</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.978975e-06</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>2.308064e-06</td>\n",
       "      <td>0.017740</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>5.921898e-07</td>\n",
       "      <td>8.824487e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>3.122195e-06</td>\n",
       "      <td>3.543960e-05</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.463043e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.434398e-24</td>\n",
       "      <td>test</td>\n",
       "      <td>data</td>\n",
       "      <td>victor</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G493893721</th>\n",
       "      <td>2.590220e-08</td>\n",
       "      <td>1.134038e-05</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>3.797090e-04</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>1.081675e-05</td>\n",
       "      <td>0.020451</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>1.046877e-06</td>\n",
       "      <td>2.551880e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>4.048332e-07</td>\n",
       "      <td>7.720412e-06</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.277067e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.930757e-04</td>\n",
       "      <td>test</td>\n",
       "      <td>data</td>\n",
       "      <td>victor</td>\n",
       "      <td>https://api.midtrans.com/v1/onboardings/data/S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34489 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              airfield 0  airplane_cabin 1  airport_terminal 2      alcove 3  \\\n",
       "outlet_id                                                                      \n",
       "G000007135  2.139274e-07      8.877712e-06            0.000022  5.341184e-03   \n",
       "G000051136  1.175332e-06      5.057530e-06            0.000076  1.025874e-04   \n",
       "G000162899  1.970256e-06      2.253714e-05            0.000921  1.132516e-05   \n",
       "G000224606  2.726324e-06      6.312387e-04            0.000017  1.223479e-02   \n",
       "G000224896  2.137902e-08      1.091339e-06            0.000067  9.194782e-07   \n",
       "...                  ...               ...                 ...           ...   \n",
       "G506427626  8.964552e-05      2.812791e-04            0.000127  2.508922e-02   \n",
       "G050841328  2.620510e-06      2.401831e-05            0.000058  3.385504e-02   \n",
       "G436006229  1.548531e-04      7.768250e-04            0.000342  3.176613e-02   \n",
       "G798587885  1.630283e-07      5.286926e-08            0.000007  1.978975e-06   \n",
       "G493893721  2.590220e-08      1.134038e-05            0.000008  3.797090e-04   \n",
       "\n",
       "             alley 4  amphitheater 5  amusement_arcade 6  amusement_park 7  \\\n",
       "outlet_id                                                                    \n",
       "G000007135  0.000297    9.620219e-06            0.000250          0.000004   \n",
       "G000051136  0.000170    1.486519e-04            0.000595          0.001543   \n",
       "G000162899  0.001191    1.095202e-04            0.000144          0.010354   \n",
       "G000224606  0.000304    6.293109e-06            0.000534          0.000039   \n",
       "G000224896  0.000004    9.634322e-07            0.008203          0.001622   \n",
       "...              ...             ...                 ...               ...   \n",
       "G506427626  0.000083    9.770808e-06            0.000157          0.000075   \n",
       "G050841328  0.000183    7.213193e-06            0.001122          0.000532   \n",
       "G436006229  0.000392    7.352784e-05            0.000043          0.000275   \n",
       "G798587885  0.000013    2.308064e-06            0.017740          0.000297   \n",
       "G493893721  0.000018    1.081675e-05            0.020451          0.000191   \n",
       "\n",
       "               outdoor 8    aquarium 9  ...  windmill 361      yard 362  \\\n",
       "outlet_id                               ...                               \n",
       "G000007135  3.967058e-06  2.369832e-05  ...  1.677299e-06  8.493458e-05   \n",
       "G000051136  1.816568e-05  5.027789e-05  ...  1.101525e-05  2.041509e-03   \n",
       "G000162899  3.195454e-04  7.204539e-04  ...  3.196685e-05  7.799471e-04   \n",
       "G000224606  2.232212e-05  1.159015e-04  ...  1.141056e-05  1.837652e-05   \n",
       "G000224896  1.499786e-07  2.290889e-05  ...  1.718631e-07  5.244693e-07   \n",
       "...                  ...           ...  ...           ...           ...   \n",
       "G506427626  1.187956e-04  2.093857e-03  ...  6.131802e-04  1.581691e-04   \n",
       "G050841328  1.453368e-05  1.549785e-03  ...  2.462671e-06  1.477298e-03   \n",
       "G436006229  1.506499e-04  1.673141e-03  ...  4.613529e-03  1.266370e-04   \n",
       "G798587885  5.921898e-07  8.824487e-07  ...  3.122195e-06  3.543960e-05   \n",
       "G493893721  1.046877e-06  2.551880e-04  ...  4.048332e-07  7.720412e-06   \n",
       "\n",
       "            youth_hostel 363  zen_garden 364  inappropriate_label  \\\n",
       "outlet_id                                                           \n",
       "G000007135          0.004273    3.606791e-06                  1.0   \n",
       "G000051136          0.000012    4.518936e-05                  0.0   \n",
       "G000162899          0.000025    2.635096e-04                  0.0   \n",
       "G000224606          0.006582    1.709939e-04                  1.0   \n",
       "G000224896          0.000004    8.652056e-08                  0.0   \n",
       "...                      ...             ...                  ...   \n",
       "G506427626          0.000889    4.262529e-04                  1.0   \n",
       "G050841328          0.000228    1.822124e-04                  1.0   \n",
       "G436006229          0.012177    3.188663e-04                  1.0   \n",
       "G798587885          0.000002    3.463043e-07                  0.0   \n",
       "G493893721          0.000001    1.277067e-06                  0.0   \n",
       "\n",
       "            inappropriate_prob  group            source      set  \\\n",
       "outlet_id                                                          \n",
       "G000007135        4.720853e-01  train  oct2022_gooddata  oct2022   \n",
       "G000051136        1.455604e-03  train  oct2022_gooddata  oct2022   \n",
       "G000162899        1.428664e-01  train  oct2022_gooddata  oct2022   \n",
       "G000224606        9.549897e-01  train  oct2022_gooddata  oct2022   \n",
       "G000224896        3.189991e-21  train  oct2022_gooddata  oct2022   \n",
       "...                        ...    ...               ...      ...   \n",
       "G506427626        9.999838e-01   test              data   victor   \n",
       "G050841328        1.283699e-02   test              data   victor   \n",
       "G436006229        1.000000e+00   test              data   victor   \n",
       "G798587885        1.434398e-24   test              data   victor   \n",
       "G493893721        1.930757e-04   test              data   victor   \n",
       "\n",
       "                                             outlet_photo_url  \n",
       "outlet_id                                                      \n",
       "G000007135  https://api.gobiz.co.id/v1/onboardings/data/SF...  \n",
       "G000051136  https://api.gobiz.co.id/v1/onboardings/data/SF...  \n",
       "G000162899  https://api.gobiz.co.id/v1/onboardings/data/SF...  \n",
       "G000224606  https://api.gobiz.co.id/v1/onboardings/data/SF...  \n",
       "G000224896  https://api.gobiz.co.id/v1/onboardings/data/SF...  \n",
       "...                                                       ...  \n",
       "G506427626  https://api.gobiz.co.id/v1/onboardings/data/SF...  \n",
       "G050841328  https://api.midtrans.com/v1/onboardings/data/S...  \n",
       "G436006229  https://api.gobiz.co.id/v1/onboardings/data/SF...  \n",
       "G798587885  https://api.gobiz.co.id/v1/onboardings/data/SF...  \n",
       "G493893721  https://api.midtrans.com/v1/onboardings/data/S...  \n",
       "\n",
       "[34489 rows x 371 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Victor+Oct2022\n",
      "the auc score is 0.9963289053709145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.995     0.973     0.984     23104\n",
      "         1.0      0.904     0.983     0.942      5928\n",
      "\n",
      "    accuracy                          0.975     29032\n",
      "   macro avg      0.950     0.978     0.963     29032\n",
      "weighted avg      0.977     0.975     0.976     29032\n",
      "\n",
      "Training: Victor+Oct2022+SMOTE Oversampled\n",
      "the auc score is 0.9980668397198355\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.995     0.974     0.984     23134\n",
      "         1.0      0.974     0.995     0.984     23134\n",
      "\n",
      "    accuracy                          0.984     46268\n",
      "   macro avg      0.984     0.984     0.984     46268\n",
      "weighted avg      0.984     0.984     0.984     46268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"Training: Victor+Oct2022\")\n",
    "y_true = tpot_df.query('group==\"train\"')['inappropriate_label']\n",
    "y_score = tpot_df.query('group==\"train\"')['inappropriate_prob']\n",
    "y_pred = y_score >= 0.5\n",
    "print(f'the auc score is {roc_auc_score(y_true,y_score)}')\n",
    "print(classification_report(y_true,y_pred, digits=3))\n",
    "\n",
    "print(\"Training: Victor+Oct2022+SMOTE Oversampled\")\n",
    "y_pred = tpot.predict(X_train)\n",
    "y_score = tpot.predict_proba(X_train)[:,1]\n",
    "print(f'the auc score is {roc_auc_score(y_train,y_score)}')\n",
    "print(classification_report(y_train,y_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Victor+Oct2022\n",
      "the auc score is 0.9782192458455676\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.973     0.946     0.959      2738\n",
      "         1.0      0.823     0.906     0.863       759\n",
      "\n",
      "    accuracy                          0.937      3497\n",
      "   macro avg      0.898     0.926     0.911      3497\n",
      "weighted avg      0.941     0.937     0.938      3497\n",
      "\n",
      "Validation: Victor set\n",
      "the auc score is 0.9929944922214707\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.984     0.966     0.975       262\n",
      "         1.0      0.963     0.983     0.973       237\n",
      "\n",
      "    accuracy                          0.974       499\n",
      "   macro avg      0.974     0.974     0.974       499\n",
      "weighted avg      0.974     0.974     0.974       499\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.4749499 , 0.47590361, 0.47686117, 0.47782258, 0.47878788,\n",
       "        0.47975709, 0.48073022, 0.48170732, 0.48268839, 0.48367347,\n",
       "        0.48466258, 0.48565574, 0.48665298, 0.48765432, 0.48865979,\n",
       "        0.48966942, 0.49068323, 0.49170124, 0.49272349, 0.49375   ,\n",
       "        0.49478079, 0.4958159 , 0.49685535, 0.49789916, 0.49894737,\n",
       "        0.5       , 0.50105708, 0.50211864, 0.50318471, 0.50425532,\n",
       "        0.50533049, 0.50641026, 0.50749465, 0.50858369, 0.50967742,\n",
       "        0.51077586, 0.51187905, 0.51298701, 0.51409978, 0.51521739,\n",
       "        0.51633987, 0.51746725, 0.51859956, 0.51973684, 0.52087912,\n",
       "        0.52202643, 0.52317881, 0.52433628, 0.52549889, 0.52666667,\n",
       "        0.52783964, 0.52901786, 0.53020134, 0.53139013, 0.53258427,\n",
       "        0.53378378, 0.53498871, 0.5361991 , 0.53741497, 0.53863636,\n",
       "        0.53986333, 0.54109589, 0.5423341 , 0.54357798, 0.54482759,\n",
       "        0.54608295, 0.54734411, 0.54861111, 0.54988399, 0.55116279,\n",
       "        0.55244755, 0.55373832, 0.55503513, 0.55633803, 0.55764706,\n",
       "        0.55896226, 0.56028369, 0.56161137, 0.56294537, 0.56428571,\n",
       "        0.56563246, 0.56698565, 0.56834532, 0.56971154, 0.57108434,\n",
       "        0.57246377, 0.57384988, 0.57524272, 0.57664234, 0.57804878,\n",
       "        0.5794621 , 0.58088235, 0.58230958, 0.58374384, 0.58518519,\n",
       "        0.58663366, 0.58808933, 0.58955224, 0.59102244, 0.5925    ,\n",
       "        0.59398496, 0.59547739, 0.59697733, 0.59848485, 0.6       ,\n",
       "        0.60152284, 0.60305344, 0.60459184, 0.60613811, 0.60769231,\n",
       "        0.6092545 , 0.61082474, 0.6124031 , 0.61398964, 0.61558442,\n",
       "        0.6171875 , 0.61879896, 0.62041885, 0.62204724, 0.62368421,\n",
       "        0.62532982, 0.62698413, 0.62864721, 0.63031915, 0.632     ,\n",
       "        0.63368984, 0.63538874, 0.63709677, 0.63881402, 0.64054054,\n",
       "        0.64227642, 0.64402174, 0.64577657, 0.64754098, 0.64931507,\n",
       "        0.6510989 , 0.65289256, 0.65469613, 0.6565097 , 0.65833333,\n",
       "        0.66016713, 0.66201117, 0.66386555, 0.66573034, 0.66760563,\n",
       "        0.66949153, 0.6713881 , 0.67329545, 0.67521368, 0.67714286,\n",
       "        0.67908309, 0.68103448, 0.68299712, 0.6849711 , 0.68695652,\n",
       "        0.68895349, 0.6909621 , 0.69298246, 0.69501466, 0.69705882,\n",
       "        0.69911504, 0.70118343, 0.70326409, 0.70535714, 0.70746269,\n",
       "        0.70958084, 0.71171171, 0.71385542, 0.71601208, 0.71818182,\n",
       "        0.72036474, 0.72256098, 0.72477064, 0.72699387, 0.72923077,\n",
       "        0.73148148, 0.73374613, 0.73602484, 0.73831776, 0.740625  ,\n",
       "        0.74294671, 0.74528302, 0.74763407, 0.75      , 0.75238095,\n",
       "        0.75477707, 0.7571885 , 0.75961538, 0.76205788, 0.76451613,\n",
       "        0.76699029, 0.76948052, 0.77198697, 0.7745098 , 0.77704918,\n",
       "        0.77960526, 0.78217822, 0.78476821, 0.78737542, 0.79      ,\n",
       "        0.79264214, 0.79530201, 0.7979798 , 0.80067568, 0.80338983,\n",
       "        0.80612245, 0.80887372, 0.81164384, 0.81443299, 0.81724138,\n",
       "        0.8200692 , 0.82291667, 0.82578397, 0.82867133, 0.83157895,\n",
       "        0.83450704, 0.83745583, 0.84042553, 0.84341637, 0.84642857,\n",
       "        0.84946237, 0.85251799, 0.85559567, 0.85869565, 0.86181818,\n",
       "        0.8649635 , 0.86813187, 0.87132353, 0.87453875, 0.87777778,\n",
       "        0.88104089, 0.88432836, 0.88764045, 0.89097744, 0.89433962,\n",
       "        0.89772727, 0.90114068, 0.90458015, 0.90804598, 0.91153846,\n",
       "        0.91505792, 0.91860465, 0.91828794, 0.921875  , 0.9254902 ,\n",
       "        0.92913386, 0.93280632, 0.93650794, 0.94023904, 0.944     ,\n",
       "        0.9437751 , 0.94758065, 0.951417  , 0.95528455, 0.95918367,\n",
       "        0.95901639, 0.95884774, 0.96280992, 0.9626556 , 0.96666667,\n",
       "        0.9707113 , 0.97058824, 0.97046414, 0.97033898, 0.97021277,\n",
       "        0.97435897, 0.97424893, 0.97413793, 0.97835498, 0.97826087,\n",
       "        0.97816594, 0.97807018, 0.97797357, 0.97787611, 0.97777778,\n",
       "        0.97767857, 0.97757848, 0.97747748, 0.97737557, 0.97727273,\n",
       "        0.97716895, 0.97706422, 0.97695853, 0.98148148, 0.98139535,\n",
       "        0.98130841, 0.98122066, 0.98113208, 0.98104265, 0.98095238,\n",
       "        0.98086124, 0.98076923, 0.98067633, 0.98058252, 0.9804878 ,\n",
       "        0.98039216, 0.98029557, 0.98019802, 0.9800995 , 0.98      ,\n",
       "        0.9798995 , 0.98484848, 0.98477157, 0.98469388, 0.98461538,\n",
       "        0.98453608, 0.98445596, 0.984375  , 0.98429319, 0.98421053,\n",
       "        0.98412698, 0.98404255, 0.98395722, 0.98387097, 0.98378378,\n",
       "        0.98369565, 0.98360656, 0.98351648, 0.98342541, 0.98333333,\n",
       "        0.98324022, 0.98314607, 0.98305085, 0.98295455, 0.98285714,\n",
       "        0.98275862, 0.98265896, 0.98255814, 0.98245614, 0.98235294,\n",
       "        0.98224852, 0.98214286, 0.98203593, 0.98192771, 0.98181818,\n",
       "        0.98170732, 0.98159509, 0.98148148, 0.98136646, 0.98125   ,\n",
       "        0.98113208, 0.98734177, 0.98726115, 0.98717949, 0.98709677,\n",
       "        0.98701299, 0.9869281 , 0.98684211, 0.98675497, 0.98666667,\n",
       "        0.98657718, 0.98648649, 0.98639456, 0.98630137, 0.9862069 ,\n",
       "        0.98611111, 0.98601399, 0.98591549, 0.9858156 , 0.99285714,\n",
       "        0.99280576, 0.99275362, 0.99270073, 0.99264706, 0.99259259,\n",
       "        0.99253731, 0.9924812 , 0.99242424, 0.99236641, 0.99230769,\n",
       "        0.99224806, 0.9921875 , 0.99212598, 0.99206349, 0.992     ,\n",
       "        0.99193548, 0.99186992, 0.99180328, 0.99173554, 0.99166667,\n",
       "        0.99159664, 0.99152542, 0.99145299, 0.99137931, 0.99130435,\n",
       "        0.99122807, 0.99115044, 0.99107143, 0.99099099, 0.99090909,\n",
       "        0.99082569, 0.99074074, 0.99065421, 0.99056604, 0.99047619,\n",
       "        0.99038462, 0.99029126, 0.99019608, 0.99009901, 0.99      ,\n",
       "        0.98989899, 0.98979592, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        ]),\n",
       " array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.99578059, 0.99578059, 0.99578059,\n",
       "        0.99578059, 0.99578059, 0.99578059, 0.99578059, 0.99578059,\n",
       "        0.99156118, 0.99156118, 0.99156118, 0.99156118, 0.99156118,\n",
       "        0.98734177, 0.98312236, 0.98312236, 0.97890295, 0.97890295,\n",
       "        0.97890295, 0.97468354, 0.97046414, 0.96624473, 0.96202532,\n",
       "        0.96202532, 0.95780591, 0.9535865 , 0.9535865 , 0.94936709,\n",
       "        0.94514768, 0.94092827, 0.93670886, 0.93248945, 0.92827004,\n",
       "        0.92405063, 0.91983122, 0.91561181, 0.91139241, 0.907173  ,\n",
       "        0.90295359, 0.89873418, 0.89451477, 0.89451477, 0.89029536,\n",
       "        0.88607595, 0.88185654, 0.87763713, 0.87341772, 0.86919831,\n",
       "        0.8649789 , 0.86075949, 0.85654008, 0.85232068, 0.84810127,\n",
       "        0.84388186, 0.83966245, 0.83544304, 0.83122363, 0.82700422,\n",
       "        0.82278481, 0.82278481, 0.8185654 , 0.81434599, 0.81012658,\n",
       "        0.80590717, 0.80168776, 0.79746835, 0.79324895, 0.78902954,\n",
       "        0.78481013, 0.78059072, 0.77637131, 0.7721519 , 0.76793249,\n",
       "        0.76371308, 0.75949367, 0.75527426, 0.75105485, 0.74683544,\n",
       "        0.74261603, 0.73839662, 0.73417722, 0.72995781, 0.7257384 ,\n",
       "        0.72151899, 0.71729958, 0.71308017, 0.70886076, 0.70464135,\n",
       "        0.70042194, 0.69620253, 0.69198312, 0.68776371, 0.6835443 ,\n",
       "        0.67932489, 0.67510549, 0.67088608, 0.66666667, 0.66244726,\n",
       "        0.65822785, 0.65822785, 0.65400844, 0.64978903, 0.64556962,\n",
       "        0.64135021, 0.6371308 , 0.63291139, 0.62869198, 0.62447257,\n",
       "        0.62025316, 0.61603376, 0.61181435, 0.60759494, 0.60337553,\n",
       "        0.59915612, 0.59493671, 0.5907173 , 0.58649789, 0.58649789,\n",
       "        0.58227848, 0.57805907, 0.57383966, 0.56962025, 0.56540084,\n",
       "        0.56118143, 0.55696203, 0.55274262, 0.54852321, 0.5443038 ,\n",
       "        0.54008439, 0.53586498, 0.53164557, 0.52742616, 0.52320675,\n",
       "        0.51898734, 0.51476793, 0.51054852, 0.50632911, 0.5021097 ,\n",
       "        0.4978903 , 0.49367089, 0.48945148, 0.48523207, 0.48101266,\n",
       "        0.47679325, 0.47257384, 0.46835443, 0.46413502, 0.45991561,\n",
       "        0.4556962 , 0.45147679, 0.44725738, 0.44303797, 0.43881857,\n",
       "        0.43459916, 0.43037975, 0.42616034, 0.42194093, 0.41772152,\n",
       "        0.41350211, 0.4092827 , 0.4092827 , 0.40506329, 0.40084388,\n",
       "        0.39662447, 0.39240506, 0.38818565, 0.38396624, 0.37974684,\n",
       "        0.37552743, 0.37130802, 0.36708861, 0.3628692 , 0.35864979,\n",
       "        0.35443038, 0.35021097, 0.34599156, 0.34177215, 0.33755274,\n",
       "        0.33333333, 0.32911392, 0.32489451, 0.32067511, 0.3164557 ,\n",
       "        0.31223629, 0.30801688, 0.30379747, 0.29957806, 0.29535865,\n",
       "        0.29113924, 0.28691983, 0.28270042, 0.27848101, 0.2742616 ,\n",
       "        0.27004219, 0.26582278, 0.26160338, 0.25738397, 0.25316456,\n",
       "        0.24894515, 0.24472574, 0.24050633, 0.23628692, 0.23206751,\n",
       "        0.2278481 , 0.22362869, 0.21940928, 0.21518987, 0.21097046,\n",
       "        0.20675105, 0.20253165, 0.19831224, 0.19409283, 0.18987342,\n",
       "        0.18565401, 0.1814346 , 0.17721519, 0.17299578, 0.16877637,\n",
       "        0.16455696, 0.16033755, 0.15611814, 0.15189873, 0.14767932,\n",
       "        0.14345992, 0.13924051, 0.1350211 , 0.13080169, 0.12658228,\n",
       "        0.12236287, 0.11814346, 0.11392405, 0.10970464, 0.10548523,\n",
       "        0.10126582, 0.09704641, 0.092827  , 0.08860759, 0.08438819,\n",
       "        0.08016878, 0.07594937, 0.07172996, 0.06751055, 0.06329114,\n",
       "        0.05907173, 0.05485232, 0.05063291, 0.0464135 , 0.04219409,\n",
       "        0.        ]),\n",
       " array([1.01492558e-25, 6.24689881e-25, 2.93270310e-24, 1.40514608e-23,\n",
       "        2.53992800e-19, 6.18555731e-19, 2.13505314e-18, 1.07482434e-17,\n",
       "        1.33438736e-16, 1.15792431e-15, 1.71550239e-15, 1.50870420e-14,\n",
       "        3.12090140e-14, 4.80640317e-14, 7.73025354e-14, 8.12732940e-14,\n",
       "        1.14462614e-13, 1.91902113e-13, 1.93441142e-13, 7.13533698e-13,\n",
       "        8.76017413e-13, 1.02302441e-12, 1.15336138e-12, 1.31438780e-12,\n",
       "        1.37439303e-12, 1.50929005e-12, 1.71275590e-12, 2.35586141e-12,\n",
       "        2.46832098e-12, 4.74908918e-12, 5.16249442e-12, 6.24455827e-12,\n",
       "        6.28278524e-12, 6.50935167e-12, 7.06084744e-12, 7.48141721e-12,\n",
       "        7.87597980e-12, 1.11143362e-11, 1.85954736e-11, 2.04429976e-11,\n",
       "        2.57682606e-11, 2.75824633e-11, 2.94673534e-11, 3.21296824e-11,\n",
       "        3.91086979e-11, 4.06660834e-11, 4.95661992e-11, 5.92748896e-11,\n",
       "        6.86566066e-11, 1.10314217e-10, 1.49819849e-10, 1.53435493e-10,\n",
       "        2.22231532e-10, 3.06803111e-10, 3.99469151e-10, 5.88938904e-10,\n",
       "        9.49834377e-10, 1.22343198e-09, 1.43701877e-09, 1.57816926e-09,\n",
       "        1.94713903e-09, 2.77070470e-09, 3.00680195e-09, 3.62018965e-09,\n",
       "        3.64223193e-09, 3.67213624e-09, 4.19140506e-09, 6.18208110e-09,\n",
       "        7.81999911e-09, 1.89172053e-08, 1.92192241e-08, 2.09005980e-08,\n",
       "        2.09364452e-08, 2.51714019e-08, 2.53684804e-08, 3.47856966e-08,\n",
       "        4.27452711e-08, 4.64158035e-08, 4.66957350e-08, 4.93876261e-08,\n",
       "        6.37661544e-08, 7.76125998e-08, 8.64576995e-08, 9.15321009e-08,\n",
       "        9.82677077e-08, 1.31179629e-07, 1.46876521e-07, 1.55997927e-07,\n",
       "        1.86292591e-07, 1.90174969e-07, 1.97530107e-07, 2.12448529e-07,\n",
       "        2.23302377e-07, 2.46796152e-07, 3.06865655e-07, 3.89001937e-07,\n",
       "        5.43473483e-07, 5.88008309e-07, 6.17313394e-07, 6.19286805e-07,\n",
       "        7.39441256e-07, 7.94325056e-07, 8.12732160e-07, 8.30724492e-07,\n",
       "        9.08487228e-07, 1.05301646e-06, 1.07432486e-06, 1.13991076e-06,\n",
       "        1.18901987e-06, 1.21369179e-06, 1.73032309e-06, 1.78084898e-06,\n",
       "        1.94252023e-06, 2.02783954e-06, 2.53548086e-06, 2.55496669e-06,\n",
       "        2.63128806e-06, 3.13250153e-06, 3.20735876e-06, 3.51840113e-06,\n",
       "        3.61636723e-06, 3.67851931e-06, 4.15097694e-06, 4.15661119e-06,\n",
       "        4.49461024e-06, 4.57044693e-06, 4.59953328e-06, 4.68454851e-06,\n",
       "        4.71075196e-06, 4.93531027e-06, 7.23362446e-06, 7.82441744e-06,\n",
       "        8.22201402e-06, 9.44623624e-06, 1.10021937e-05, 1.11190304e-05,\n",
       "        1.12739374e-05, 1.17236112e-05, 1.18228787e-05, 1.19520985e-05,\n",
       "        1.28838072e-05, 1.45751088e-05, 1.58984313e-05, 1.60456673e-05,\n",
       "        1.62039812e-05, 2.44994964e-05, 2.50765768e-05, 2.62374413e-05,\n",
       "        2.73646276e-05, 2.90177266e-05, 2.93687171e-05, 3.44566782e-05,\n",
       "        3.47068175e-05, 3.80337952e-05, 4.11430850e-05, 4.15313015e-05,\n",
       "        4.29540798e-05, 5.12379383e-05, 5.13377728e-05, 5.84438244e-05,\n",
       "        6.09388806e-05, 7.28777342e-05, 7.29282098e-05, 8.43121848e-05,\n",
       "        8.94283137e-05, 1.00373381e-04, 1.02187690e-04, 1.04611275e-04,\n",
       "        1.15392828e-04, 1.29734399e-04, 1.33441993e-04, 1.39089916e-04,\n",
       "        1.59853579e-04, 1.81207441e-04, 1.89944913e-04, 1.90725897e-04,\n",
       "        2.36952226e-04, 2.63548886e-04, 2.75621375e-04, 2.91293084e-04,\n",
       "        3.05059833e-04, 3.22811866e-04, 3.41630634e-04, 3.44068038e-04,\n",
       "        3.54067012e-04, 4.23305220e-04, 4.35472101e-04, 5.97304989e-04,\n",
       "        7.08260492e-04, 7.32218911e-04, 7.94092812e-04, 8.08280019e-04,\n",
       "        8.50623419e-04, 8.83279303e-04, 1.14398813e-03, 1.56021623e-03,\n",
       "        1.58964355e-03, 1.59278227e-03, 1.61448453e-03, 1.70361043e-03,\n",
       "        1.72377118e-03, 1.77965270e-03, 1.79582903e-03, 1.98406538e-03,\n",
       "        2.02018402e-03, 2.19001794e-03, 2.60093419e-03, 2.85694203e-03,\n",
       "        2.89065439e-03, 3.60652568e-03, 3.71802765e-03, 4.40309930e-03,\n",
       "        5.05109581e-03, 5.40231404e-03, 5.55831929e-03, 7.29876610e-03,\n",
       "        8.31368694e-03, 8.87586743e-03, 9.92513019e-03, 9.98373773e-03,\n",
       "        1.04784884e-02, 1.07782699e-02, 1.40490702e-02, 1.50470290e-02,\n",
       "        1.54907924e-02, 1.78876880e-02, 1.78996659e-02, 2.45519886e-02,\n",
       "        2.63407189e-02, 2.90403780e-02, 3.41616553e-02, 3.62304320e-02,\n",
       "        5.27875181e-02, 5.28501158e-02, 5.29650396e-02, 5.40239908e-02,\n",
       "        6.39149498e-02, 6.67771971e-02, 7.78833800e-02, 8.80371106e-02,\n",
       "        9.17797823e-02, 1.00387809e-01, 1.14682661e-01, 1.38978894e-01,\n",
       "        1.52984177e-01, 1.61159294e-01, 1.74098852e-01, 1.75871878e-01,\n",
       "        1.78723013e-01, 2.29535320e-01, 2.79264415e-01, 2.95089240e-01,\n",
       "        3.35715944e-01, 3.51231251e-01, 3.98914799e-01, 4.84727679e-01,\n",
       "        4.89574241e-01, 5.22982368e-01, 5.81113507e-01, 6.00604025e-01,\n",
       "        6.08068366e-01, 6.11894107e-01, 6.15289124e-01, 6.30881166e-01,\n",
       "        6.77935251e-01, 6.82156543e-01, 7.42910926e-01, 7.53513603e-01,\n",
       "        7.54499078e-01, 7.65030931e-01, 7.82739383e-01, 7.85670963e-01,\n",
       "        7.86842629e-01, 8.19580450e-01, 8.48487320e-01, 8.56673016e-01,\n",
       "        8.58022658e-01, 8.60064568e-01, 8.85117905e-01, 8.86063118e-01,\n",
       "        8.86298398e-01, 9.01153593e-01, 9.03117845e-01, 9.08591225e-01,\n",
       "        9.08915467e-01, 9.09095429e-01, 9.16178642e-01, 9.17337217e-01,\n",
       "        9.17932636e-01, 9.18189772e-01, 9.22706810e-01, 9.24810200e-01,\n",
       "        9.31649687e-01, 9.32365490e-01, 9.36549448e-01, 9.43408623e-01,\n",
       "        9.46710158e-01, 9.51681684e-01, 9.55532504e-01, 9.55613762e-01,\n",
       "        9.57790261e-01, 9.58220918e-01, 9.58625785e-01, 9.60531134e-01,\n",
       "        9.61981726e-01, 9.65718992e-01, 9.67202612e-01, 9.67284726e-01,\n",
       "        9.70621661e-01, 9.71295676e-01, 9.71861909e-01, 9.72935500e-01,\n",
       "        9.73277331e-01, 9.74304187e-01, 9.77625549e-01, 9.77902772e-01,\n",
       "        9.78328681e-01, 9.79614926e-01, 9.80732614e-01, 9.80948683e-01,\n",
       "        9.81118511e-01, 9.81145637e-01, 9.81425845e-01, 9.81892959e-01,\n",
       "        9.82262893e-01, 9.83094145e-01, 9.83663513e-01, 9.84091399e-01,\n",
       "        9.84937628e-01, 9.85634479e-01, 9.85720591e-01, 9.85962940e-01,\n",
       "        9.86415810e-01, 9.86744918e-01, 9.86878442e-01, 9.87149977e-01,\n",
       "        9.88740293e-01, 9.89540253e-01, 9.89667680e-01, 9.90151570e-01,\n",
       "        9.90398114e-01, 9.91001221e-01, 9.91112049e-01, 9.91418231e-01,\n",
       "        9.91690905e-01, 9.92097135e-01, 9.92197729e-01, 9.92314652e-01,\n",
       "        9.92494137e-01, 9.92734452e-01, 9.93822901e-01, 9.93866647e-01,\n",
       "        9.93870266e-01, 9.93948369e-01, 9.93991918e-01, 9.94646944e-01,\n",
       "        9.95408803e-01, 9.95798940e-01, 9.95806131e-01, 9.96105971e-01,\n",
       "        9.96172300e-01, 9.96227948e-01, 9.96455533e-01, 9.96587758e-01,\n",
       "        9.96659029e-01, 9.96865918e-01, 9.96917273e-01, 9.96981367e-01,\n",
       "        9.97284745e-01, 9.97561495e-01, 9.97776033e-01, 9.97785107e-01,\n",
       "        9.97858205e-01, 9.97904494e-01, 9.97943749e-01, 9.97967981e-01,\n",
       "        9.97982369e-01, 9.98316079e-01, 9.98595705e-01, 9.98667514e-01,\n",
       "        9.98862316e-01, 9.98930143e-01, 9.99053092e-01, 9.99132279e-01,\n",
       "        9.99288536e-01, 9.99399266e-01, 9.99428954e-01, 9.99446698e-01,\n",
       "        9.99468622e-01, 9.99472065e-01, 9.99480362e-01, 9.99492338e-01,\n",
       "        9.99553473e-01, 9.99558598e-01, 9.99572585e-01, 9.99623491e-01,\n",
       "        9.99642896e-01, 9.99706004e-01, 9.99711587e-01, 9.99761010e-01,\n",
       "        9.99762333e-01, 9.99776622e-01, 9.99781745e-01, 9.99783213e-01,\n",
       "        9.99785418e-01, 9.99787508e-01, 9.99802066e-01, 9.99815260e-01,\n",
       "        9.99820305e-01, 9.99822691e-01, 9.99823451e-01, 9.99848911e-01,\n",
       "        9.99873790e-01, 9.99923137e-01, 9.99937544e-01, 9.99941185e-01,\n",
       "        9.99957972e-01, 9.99960022e-01, 9.99961414e-01, 9.99963118e-01,\n",
       "        9.99965440e-01, 9.99967553e-01, 9.99972729e-01, 9.99975486e-01,\n",
       "        9.99979977e-01, 9.99980171e-01, 9.99980564e-01, 9.99980657e-01,\n",
       "        9.99985044e-01, 9.99990195e-01, 9.99990223e-01, 9.99990820e-01,\n",
       "        9.99992266e-01, 9.99995962e-01, 9.99996124e-01, 9.99996161e-01,\n",
       "        9.99997144e-01, 9.99997595e-01, 9.99998854e-01, 9.99999103e-01,\n",
       "        9.99999359e-01, 9.99999566e-01, 9.99999568e-01, 9.99999746e-01,\n",
       "        9.99999770e-01, 9.99999854e-01, 9.99999865e-01, 9.99999884e-01,\n",
       "        9.99999905e-01, 9.99999914e-01, 9.99999922e-01, 9.99999936e-01,\n",
       "        9.99999936e-01, 9.99999963e-01, 9.99999972e-01, 9.99999980e-01,\n",
       "        9.99999983e-01, 9.99999986e-01, 9.99999989e-01, 9.99999989e-01,\n",
       "        9.99999992e-01, 9.99999993e-01, 9.99999996e-01, 9.99999996e-01,\n",
       "        9.99999997e-01, 9.99999997e-01, 9.99999998e-01, 9.99999998e-01,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHL0lEQVR4nO3deXhMZ/8/8PckMpOJbMgmESL2KLE90URLtdFU+lCqpaRESiy1p9ZSUVu6KtWQVhF8tdSuaJRYKmi1IoqglhBLElv2RNb794efeTqymJPMZJLj/bquuS5zn+0zt8S83ec+5yiEEAJEREREMmFi7AKIiIiI9InhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZKWWsQuoasXFxbh9+zasrKygUCiMXQ4RERHpQAiBzMxMODs7w8Sk/LGZZy7c3L59G66ursYug4iIiCrgxo0baNCgQbnrPHPhxsrKCsCjzrG2tjZyNURERKSLjIwMuLq6ar7Hy/PMhZvHp6Ksra0ZboiIiGoYXaaUcEIxERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyYpRw81vv/2GXr16wdnZGQqFAtu3b3/qNocOHUKHDh2gUqnQtGlTREZGGrxOIiIiqjmMGm6ys7Ph6emJ8PBwndZPSEjA66+/ju7duyMuLg4TJ07E8OHDsXfvXgNXSkRERDWFUR+c2bNnT/Ts2VPn9SMiItC4cWN8+eWXAIBWrVohJiYGX331Ffz8/AxVpk6EEMgtKDJqDUSGpjYz1emhdURExlSjngp+/Phx+Pr6arX5+flh4sSJZW6Tl5eHvLw8zfuMjAyD1JZbUASP2RxBInnr1KgONo3yZsAhomqtRk0oTk5OhqOjo1abo6MjMjIykJubW+o2YWFhsLGx0bxcXV2rolQiWfrreipHKImo2qtRIzcVMWPGDISEhGjeZ2RkGCTgqM1MET/XuKfGiAwlJ78InebvN3YZREQ6qVHhxsnJCSkpKVptKSkpsLa2hlqtLnUblUoFlUpl8NoUCgUslDWqO4moCvx7Ph7nLBFVjRr1bezt7Y09e/Zote3btw/e3t5GqoiIqkJNnbAvBPB2xHHEJz2a68c5S0RVw6jhJisrC5cvX9a8T0hIQFxcHOrWrYuGDRtixowZuHXrFtauXQsAGDVqFL755htMnToV7733Hg4cOICffvoJu3fvNtZHIHrm5ORXbch4MiDUZI/nLHGUl8iwjPob9tdff6F79+6a94/nxgQGBiIyMhJJSUlITEzULG/cuDF2796NSZMmYcmSJWjQoAG+//57o18GTvQs4dwb6Rrb1UbCvWxjl0H0zFAIIYSxi6hKGRkZsLGxQXp6OqytrY1dDlGNIITA2xHH8df1VKPV4FHf+v+f0jFaCRUmBNA69NGtIuLn+lVo5EZfp+Y474dqKinf3xwbJaKnUigU2DTK26jzXmryl3JOfuG//iy9D/V5ao7zfuhZwHBDRDrhFYH6YezTetV93k91mTxek8M0MdwQERmc2swUnRrVqfRpvcqcmpN6ryJjhIzqNHmcI1w1G8MNEZGB6eu0nr5GE552aqw6hQxjKWuEq6pCH0eOKofhhoioClSn03rGPjX2NMacPP7vEa4nQ2BVhj6OHFVO9fhNIyIig6rIqTFjhYzqMmphzBD475EjQ48WVZf+1ieGGyKiZ0BFTo3J8UvvaXQJgYYMfU+OHFXFaJEcR4kYboiInhHV6dRYdaVLCKyq0FdVI0d/XU/F/ex8WChNAcgj1PKnnIiI6F+MGQLLGjkyxGjRv0eJ/h2k5DCSw3BDRERUTZQ1cmSI0ZSyglR1vxeSLmpu5URERDJUVSNHTwap8q4Ue6ymnLJiuCEiInpGlRWkyprvU1NOWZkYuwAiIiIyvsenqcrz+JRVdceRGyIiIir3SjGpj+8wNoYbIiIiAiCf2wXwtBQRERHp7NHNBYWxyygXww0RERHprNP8/Xg74ni1DjgMN0RERFSuJycbP76rcU5+IXLyC6td0FGI6laRgWVkZMDGxgbp6emwtrY2djlEREQ1ghAC97PzS51YXBWXiEv5/ubIDRERET2VQqFAvdrKUi8Xr26XiNf8KdFERERUJcq7q3F1wnBDREREOqsJl4vztBQRERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREVVadXrmFMMNERERVVp1euYUww0RERFVSGnPnKoOdypmuCEiIqIKeXzH4r9m+Rq7FC0MN0RERFRhj+5YbGrsMrQw3BAREZGsMNwQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcEBERkd7k5BdBCGHUGhhuiIiISG86zd+PtyOOGzXgMNwQERFRpajNTNGpUR3N+7+upyK3oMho9TDcEBERUaUoFApsGuWNv2b5GrsUAAw3REREpAcKhQIWSlNjlwGA4YaIiIhkhuGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZMXo4SY8PBxubm4wNzdH586dceLEiTLXLSgowNy5c9GkSROYm5vD09MTUVFRVVgtERERVXdGDTcbN25ESEgIQkNDERsbC09PT/j5+eHOnTulrj9r1ix8++23WLp0KeLj4zFq1Cj07dsXp06dquLKiYiIqLoyarhZtGgRgoODERQUBA8PD0RERMDCwgKrVq0qdf1169bhww8/hL+/P9zd3TF69Gj4+/vjyy+/rOLKiYiIqLoyWrjJz8/HyZMn4ev7v7sZmpiYwNfXF8ePHy91m7y8PJibm2u1qdVqxMTElHmcvLw8ZGRkaL2IiIhIvowWbu7du4eioiI4OjpqtTs6OiI5ObnUbfz8/LBo0SJcunQJxcXF2LdvH7Zu3YqkpKQyjxMWFgYbGxvNy9XVVa+fg4iIiKoXo08olmLJkiVo1qwZWrZsCaVSibFjxyIoKAgmJmV/jBkzZiA9PV3zunHjRhVWTERERFXNaOHGzs4OpqamSElJ0WpPSUmBk5NTqdvY29tj+/btyM7OxvXr13HhwgVYWlrC3d29zOOoVCpYW1trvYiIiEi+jBZulEolOnbsiOjoaE1bcXExoqOj4e3tXe625ubmcHFxQWFhIbZs2YI33njD0OUSERFRDVHLmAcPCQlBYGAgOnXqBC8vLyxevBjZ2dkICgoCAAwZMgQuLi4ICwsDAPzxxx+4desW2rVrh1u3bmHOnDkoLi7G1KlTjfkxiIiIqBoxargZMGAA7t69i9mzZyM5ORnt2rVDVFSUZpJxYmKi1nyahw8fYtasWbh69SosLS3h7++PdevWwdbW1kifgIiIiKobhRBCGLuIqpSRkQEbGxukp6dz/g0REZEe5eQXwmP2XgBA/Fw/WCj1N4Yi5fu7Rl0tRURERPQ0DDdEREQkKww3REREJCsMN0RERCQrDDdEREQkKww3REREJCuSr9HKy8vDH3/8gevXryMnJwf29vZo3749GjdubIj6iIiIiCTROdwcPXoUS5Yswc8//4yCggLY2NhArVbjwYMHyMvLg7u7O0aMGIFRo0bBysrKkDUTERERlUmn01K9e/fGgAED4Obmhl9//RWZmZm4f/8+bt68iZycHFy6dAmzZs1CdHQ0mjdvjn379hm6biIiIqJS6TRy8/rrr2PLli0wMzMrdbm7uzvc3d0RGBiI+Ph4JCUl6bVIIiIiIl3pFG5Gjhyp8w49PDzg4eFR4YKIiIiIKoNXSxEREZGs6C3cnD59GqampvraHREREVGF6HXk5hl7wDgRERFVQzpfCv7mm2+Wuzw9PR0KhaLSBRERERFVhs7h5ueff0aPHj3g6OhY6vKioiK9FUVERERUUTqHm1atWqFfv34YNmxYqcvj4uKwa9cuvRVGREREVBE6z7np2LEjYmNjy1yuUqnQsGFDvRRFREREVFE6j9xERESUe+qpVatWSEhI0EtRRERERBWlc7hRqVSGrIOIiIhIL3gTPyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSlQqFm7Vr12LHjh1abTt27MDatWv1UhQRERFRRVUo3AwdOhQzZszQaps2bRqCgoL0UhQRERFRRel8n5t/Ky4uLtF24cKFShdDREREVFmcc0NERESyotPITUZGhs47tLa2rnAxRERERJWlU7ixtbWFQqEodx0hBBQKRbnPnyIiIiIyNJ3CzcGDBw1dBxEREZFe6BRuunXrZug6iIiIiPSiQhOKjxw5gnfffRc+Pj64desWAGDdunWIiYnRa3FEREREUkkON1u2bIGfnx/UajViY2ORl5cHAEhPT8fChQv1XiARERGRFJLDzfz58xEREYEVK1bAzMxM096lSxfExsbqtTgiIiIiqSSHm4sXL6Jr164l2m1sbJCWlqaPmoiIiIgqTHK4cXJywuXLl0u0x8TEwN3dXS9FEREREVWU5HATHByMCRMm4I8//oBCocDt27exfv16TJ48GaNHjzZEjUREREQ6k/xsqenTp6O4uBivvPIKcnJy0LVrV6hUKkyePBnjxo0zRI1EREREOpMcbhQKBWbOnIkpU6bg8uXLyMrKgoeHBywtLQ1RHxEREZEkFXoqOAAolUpYWVnBysqKwYaIiIiqDclzbgoLC/HRRx/BxsYGbm5ucHNzg42NDWbNmoWCggJD1EhERESkM8kjN+PGjcPWrVvx2WefwdvbGwBw/PhxzJkzB/fv38fy5cv1XiQRERGRriSHmx9++AEbNmxAz549NW1t27aFq6srBg4cyHBDRERERiX5tJRKpYKbm1uJ9saNG0OpVOqjJiIiIqIKkxxuxo4di3nz5mmeKQUAeXl5WLBgAcaOHavX4oiIiIik0um01Jtvvqn1fv/+/WjQoAE8PT0BAKdPn0Z+fj5eeeUV/VdIREREJIFO4cbGxkbrfb9+/bTeu7q66q8iIiIiokrQKdysXr3a0HUQERER6YXkOTdERERE1VmF7lC8efNm/PTTT0hMTER+fr7WstjYWL0URkRERFQRkkduvv76awQFBcHR0RGnTp2Cl5cX6tWrh6tXr2rd+4aIiIjIGCSHm2XLluG7777D0qVLoVQqMXXqVOzbtw/jx49Henq65ALCw8Ph5uYGc3NzdO7cGSdOnCh3/cWLF6NFixZQq9VwdXXFpEmT8PDhQ8nHJSIiInmSHG4SExPh4+MDAFCr1cjMzAQADB48GD/++KOkfW3cuBEhISEIDQ1FbGwsPD094efnhzt37pS6/g8//IDp06cjNDQU58+fx8qVK7Fx40Z8+OGHUj8GERERyZTkcOPk5IQHDx4AABo2bIjff/8dAJCQkAAhhKR9LVq0CMHBwQgKCoKHhwciIiJgYWGBVatWlbr+sWPH0KVLFwwaNAhubm549dVXMXDgwKeO9hAREdGzQ3K4efnll7Fz504AQFBQECZNmoQePXpgwIAB6Nu3r877yc/Px8mTJ+Hr6/u/YkxM4Ovri+PHj5e6jY+PD06ePKkJM1evXsWePXvg7+9f5nHy8vKQkZGh9SIiIiL5kny11HfffYfi4mIAwJgxY1CvXj0cO3YMvXv3xsiRI3Xez71791BUVARHR0etdkdHR1y4cKHUbQYNGoR79+7hhRdegBAChYWFGDVqVLmnpcLCwvDxxx/rXBcRERHVbJJHbkxMTFCr1v8y0TvvvIOvv/4a48aNM/iDMw8dOoSFCxdi2bJliI2NxdatW7F7927MmzevzG1mzJiB9PR0zevGjRsGrZGIiIiMS6eRm7///lvnHbZt21an9ezs7GBqaoqUlBSt9pSUFDg5OZW6zUcffYTBgwdj+PDhAIA2bdogOzsbI0aMwMyZM2FiUjKrqVQqqFQqnesnIiKimk2ncNOuXTsoFIqnThhWKBQoKirS6cBKpRIdO3ZEdHQ0+vTpAwAoLi5GdHR0mU8Xz8nJKRFgTE1NAUDyZGYiIiKSJ53CTUJCgkEOHhISgsDAQHTq1AleXl5YvHgxsrOzERQUBAAYMmQIXFxcEBYWBgDo1asXFi1ahPbt26Nz5864fPkyPvroI/Tq1UsTcoiIiOjZplO4adSokUEOPmDAANy9exezZ89GcnIy2rVrh6ioKM0k48TERK2RmlmzZkGhUGDWrFm4desW7O3t0atXLyxYsMAg9REREVHNoxDP2PmcjIwM2NjYID09HdbW1sYuh4iISDZy8gvhMXsvACB+rh8slBV6hGWppHx/86ngREREJCsMN0RERCQrDDdEREQkKxUKN2lpafj+++8xY8YMzXOmYmNjcevWLb0WR0RERCSV5Jk+f//9N3x9fWFjY4Nr164hODgYdevWxdatW5GYmIi1a9caok4iIiIinUgeuQkJCcHQoUNx6dIlmJuba9r9/f3x22+/6bU4IiIiIqkkh5s///yz1Adkuri4IDk5WS9FEREREVWU5HCjUqmQkZFRov2ff/6Bvb29XooiIiIiqijJ4aZ3796YO3cuCgoKADx6nlRiYiKmTZuGfv366b1AIiIiIikkh5svv/wSWVlZcHBwQG5uLrp164amTZvCysqKj0EgIiIio5N8tZSNjQ327duHmJgY/P3338jKykKHDh3g6+triPqIiIiIJJEcbm7cuAFXV1e88MILeOGFFwxRExEREVGFST4t5ebmhm7dumHFihVITU01RE1EREREFSY53Pz111/w8vLC3LlzUb9+ffTp0webN29GXl6eIeojIiIikkRyuGnfvj0+//xzJCYm4pdffoG9vT1GjBgBR0dHvPfee4aokYiIiEhnFX5wpkKhQPfu3bFixQrs378fjRs3xpo1a/RZGxEREZFkFQ43N2/exGeffYZ27drBy8sLlpaWCA8P12dtRERERJJJvlrq22+/xQ8//ICjR4+iZcuWCAgIwI4dO9CoUSND1EdEREQkieRwM3/+fAwcOBBff/01PD09DVETERERUYVJDjeJiYlQKBSGqIWIiIio0nQKN3///Teee+45mJiY4MyZM+Wu27ZtW70URkRERFQROoWbdu3aITk5GQ4ODmjXrh0UCgWEEJrlj98rFAoUFRUZrFgiIiKip9Ep3CQkJMDe3l7zZyIiIqLqSqdw8+8roa5fvw4fHx/UqqW9aWFhIY4dO8arpoiIiMioJN/npnv37njw4EGJ9vT0dHTv3l0vRRERERFVlORw83huzZPu37+P2rVr66UoIiIioorS+VLwN998E8CjycNDhw6FSqXSLCsqKsLff/8NHx8f/VdIREREJIHO4cbGxgbAo5EbKysrqNVqzTKlUonnn38ewcHB+q+QiIiISAKdw83q1asBAG5ubpg8eTJPQREREVG1JPkOxaGhoYaog4iIiEgvdAo3HTp0QHR0NOrUqYP27duX+/iF2NhYvRVHREREJJVO4eaNN97QTCDu06ePIeshIiIiqhSdws2/T0XxtBQRERFVZ5Lvc3Pjxg3cvHlT8/7EiROYOHEivvvuO70WRkRERFQRksPNoEGDcPDgQQBAcnIyfH19ceLECcycORNz587Ve4FEREREUkgON2fPnoWXlxcA4KeffkKbNm1w7NgxrF+/HpGRkfquj4iIiEgSyeGmoKBAM7l4//796N27NwCgZcuWSEpK0m91RERERBJJDjetW7dGREQEjhw5gn379uG1114DANy+fRv16tXTe4FEREREUkgON59++im+/fZbvPTSSxg4cCA8PT0BADt37tScriIiIiIyFsl3KH7ppZdw7949ZGRkoE6dOpr2ESNGwMLCQq/FEREREUklOdwAgKmpKQoLCxETEwMAaNGiBdzc3PRZFxEREVGFSD4tlZ2djffeew/169dH165d0bVrVzg7O2PYsGHIyckxRI1EREREOpMcbkJCQnD48GH8/PPPSEtLQ1paGnbs2IHDhw/jgw8+MESNRERERDqTfFpqy5Yt2Lx5M1566SVNm7+/P9RqNfr374/ly5frsz4iIiIiSSSP3OTk5MDR0bFEu4ODA09LERERkdFJDjfe3t4IDQ3Fw4cPNW25ubn4+OOP4e3trdfiiIiIiKSSfFpq8eLF8PPzQ4MGDTT3uDl9+jTMzc2xd+9evRdIREREJIXkcNOmTRtcvnwZP/zwA86fPw8AGDhwIAICAqBWq/VeIBEREZEUksLN77//jp9//hn5+fl4+eWXMXz4cEPVRURERFQhOoebzZs3Y8CAAVCr1TAzM8OiRYvw6aefYvLkyYasj4iIiEgSnScUh4WFITg4GOnp6UhNTcX8+fOxcOFCQ9ZGREREJJnO4ebixYuYPHkyTE1NAQAffPABMjMzcefOHYMVR0RERCSVzuEmJycH1tbWmvdKpRLm5ubIysoySGFEREREFSFpQvH3338PS0tLzfvCwkJERkbCzs5O0zZ+/HjJRYSHh+Pzzz9HcnIyPD09sXTpUnh5eZW67ksvvYTDhw+XaPf398fu3bslH5uIiIjkRedw07BhQ6xYsUKrzcnJCevWrdO8VygUksPNxo0bERISgoiICHTu3FlzH52LFy/CwcGhxPpbt25Ffn6+5v39+/fh6emJt99+W9JxiYiISJ50DjfXrl0zSAGLFi1CcHAwgoKCAAARERHYvXs3Vq1ahenTp5dYv27dulrvN2zYAAsLC4YbIiIiAlCBxy/oU35+Pk6ePAlfX19Nm4mJCXx9fXH8+HGd9rFy5Uq88847qF27dqnL8/LykJGRofUiIiIi+dIp3GzYsEHnHd64cQNHjx7Vad179+6hqKioxIM4HR0dkZyc/NTtT5w4gbNnz5Z7M8GwsDDY2NhoXq6urjrVRkRERDWTTuFm+fLlaNWqFT777DPNIxf+LT09HXv27MGgQYPQoUMH3L9/X++FlmblypVo06ZNmZOPAWDGjBlIT0/XvG7cuFEltREREZFx6DTn5vDhw9i5cyeWLl2KGTNmoHbt2nB0dIS5uTlSU1ORnJwMOzs7DB06FGfPni0xElMWOzs7mJqaIiUlRas9JSUFTk5O5W6bnZ2NDRs2YO7cueWup1KpoFKpdKqHiIiIaj6dJxT37t0bvXv3xr179xATE4Pr168jNzcXdnZ2aN++Pdq3bw8TE2lTeJRKJTp27Ijo6Gj06dMHAFBcXIzo6GiMHTu23G03bdqEvLw8vPvuu5KOSURERPIm+angdnZ2miCiDyEhIQgMDESnTp3g5eWFxYsXIzs7W3P11JAhQ+Di4oKwsDCt7VauXIk+ffqgXr16equFiIiIaj7J4UbfBgwYgLt372L27NlITk5Gu3btEBUVpTm1lZiYWGJE6OLFi4iJicGvv/5qjJKJiIioGlMIIYSxi6hKGRkZsLGxQXp6utbjJIiIiKhycvIL4TF7LwAgfq4fLJT6G0OR8v1t1PvcEBEREekbww0RERHJCsMNERERyYrkk2FFRUWIjIxEdHQ07ty5g+LiYq3lBw4c0FtxRERERFJJDjcTJkxAZGQkXn/9dTz33HNQKBSGqIuIiIioQiSHmw0bNuCnn36Cv7+/IeohIiIiqhTJc26USiWaNm1qiFqIiIiIKk1yuPnggw+wZMkSPGO3xyEiIqIaQvJpqZiYGBw8eBC//PILWrduDTMzM63lW7du1VtxRERERFJJDje2trbo27evIWohIiIiqjTJ4Wb16tWGqIOIiIhILyr80Ie7d+/i4sWLAIAWLVrA3t5eb0URERERVZTkCcXZ2dl47733UL9+fXTt2hVdu3aFs7Mzhg0bhpycHEPUSERERKQzyeEmJCQEhw8fxs8//4y0tDSkpaVhx44dOHz4MD744AND1EhERESkM8mnpbZs2YLNmzfjpZde0rT5+/tDrVajf//+WL58uT7rIyIiIpJE8shNTk4OHB0dS7Q7ODjwtBQREREZneRw4+3tjdDQUDx8+FDTlpubi48//hje3t56LY6IiIhIKsmnpZYsWQI/Pz80aNAAnp6eAIDTp0/D3Nwce/fu1XuBRERERFJIDjfPPfccLl26hPXr1+PChQsAgIEDByIgIABqtVrvBRIRERFJUaH73FhYWCA4OFjftRARERFVmk7hZufOnejZsyfMzMywc+fOctft3bu3XgojIiIiqgidwk2fPn2QnJwMBwcH9OnTp8z1FAoFioqK9FUbERERkWQ6hZvi4uJS/0xERERU3Ui+FLw0aWlp+tgNERERUaVJDjeffvopNm7cqHn/9ttvo27dunBxccHp06f1WhwRERGRVJLDTUREBFxdXQEA+/btw/79+xEVFYWePXtiypQpei+QiIiISArJl4InJydrws2uXbvQv39/vPrqq3Bzc0Pnzp31XiARERGRFJJHburUqYMbN24AAKKiouDr6wsAEELwSikiIiIyOskjN2+++SYGDRqEZs2a4f79++jZsycA4NSpU2jatKneCyQiIiKSQnK4+eqrr+Dm5oYbN27gs88+g6WlJQAgKSkJ77//vt4LJCIiIpJCcrgxMzPD5MmTS7RPmjRJLwURERERVQYfv0BERESywscvEBERkazw8QtEREQkK3p5/AIRERFRdSE53IwfPx5ff/11ifZvvvkGEydO1EdNRERERBUmOdxs2bIFXbp0KdHu4+ODzZs366UoIiIiooqSHG7u378PGxubEu3W1ta4d++eXooiIiIiqijJ4aZp06aIiooq0f7LL7/A3d1dL0URERERVZTkm/iFhIRg7NixuHv3Ll5++WUAQHR0NL788kssXrxY3/URERERSSI53Lz33nvIy8vDggULMG/ePACAm5sbli9fjiFDhui9QCIiIiIpJIcbABg9ejRGjx6Nu3fvQq1Wa54vRURERGRsFbrPTWFhIfbv34+tW7dCCAEAuH37NrKysvRaHBEREZFUkkdurl+/jtdeew2JiYnIy8tDjx49YGVlhU8//RR5eXmIiIgwRJ1EREREOpE8cjNhwgR06tQJqampUKvVmva+ffsiOjpar8URERERSSV55ObIkSM4duwYlEqlVrubmxtu3bqlt8KIiIiIKkLyyE1xcXGpT/6+efMmrKys9FIUERERUUVJDjevvvqq1v1sFAoFsrKyEBoaCn9/f33WRkRERCSZ5NNSX3zxBV577TV4eHjg4cOHGDRoEC5dugQ7Ozv8+OOPhqiRiIiISGeSw42rqytOnz6NjRs34vTp08jKysKwYcMQEBCgNcGYiIiIyBgkhZuCggK0bNkSu3btQkBAAAICAgxVFxEREVGFSJpzY2ZmhocPHxqqFiIiIqJKkzyheMyYMfj0009RWFhoiHqIiIiIKkVyuPnzzz+xdetWNGzYEH5+fnjzzTe1XlKFh4fDzc0N5ubm6Ny5M06cOFHu+mlpaRgzZgzq168PlUqF5s2bY8+ePZKPS0RERPIkeUKxra0t+vXrp5eDb9y4ESEhIYiIiEDnzp2xePFi+Pn54eLFi3BwcCixfn5+Pnr06AEHBwds3rwZLi4uuH79OmxtbfVSDxEREdV8ksPN6tWr9XbwRYsWITg4GEFBQQCAiIgI7N69G6tWrcL06dNLrL9q1So8ePAAx44dg5mZGYBHd0YmIiIiekzn01LFxcX49NNP0aVLF/znP//B9OnTkZubW+ED5+fn4+TJk/D19f1fMSYm8PX1xfHjx0vdZufOnfD29saYMWPg6OiI5557DgsXLiz1jsmP5eXlISMjQ+tFRERE8qVzuFmwYAE+/PBDWFpawsXFBUuWLMGYMWMqfOB79+6hqKgIjo6OWu2Ojo5ITk4udZurV69i8+bNKCoqwp49e/DRRx/hyy+/xPz588s8TlhYGGxsbDQvV1fXCtdMRERE1Z/O4Wbt2rVYtmwZ9u7di+3bt+Pnn3/G+vXrUVxcbMj6tBQXF8PBwQHfffcdOnbsiAEDBmDmzJmIiIgoc5sZM2YgPT1d87px40aV1UtERERVT+c5N4mJiVrPjvL19YVCocDt27fRoEEDyQe2s7ODqakpUlJStNpTUlLg5ORU6jb169eHmZkZTE1NNW2tWrVCcnIy8vPzSzypHABUKhVUKpXk+oiIiKhm0nnkprCwEObm5lptZmZmKCgoqNCBlUolOnbsiOjoaE1bcXExoqOj4e3tXeo2Xbp0weXLl7VGi/755x/Ur1+/1GBDREREzx6dR26EEBg6dKjWKMjDhw8xatQo1K5dW9O2detWnQ8eEhKCwMBAdOrUCV5eXli8eDGys7M1V08NGTIELi4uCAsLAwCMHj0a33zzDSZMmIBx48bh0qVLWLhwIcaPH6/zMYmIiEjedA43gYGBJdrefffdSh18wIABuHv3LmbPno3k5GS0a9cOUVFRmknGiYmJMDH53+CSq6sr9u7di0mTJqFt27ZwcXHBhAkTMG3atErVQURERPKhEEIIYxdRlTIyMmBjY4P09HRYW1sbuxwiIiLZyMkvhMfsvQCA+Ll+sFBKvp1emaR8f0t+/AIRERFRdcZwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLJSLcJNeHg43NzcYG5ujs6dO+PEiRNlrhsZGQmFQqH1Mjc3r8JqiYiIqDozerjZuHEjQkJCEBoaitjYWHh6esLPzw937twpcxtra2skJSVpXtevX6/CiomIiKg6M3q4WbRoEYKDgxEUFAQPDw9ERETAwsICq1atKnMbhUIBJycnzcvR0bEKKyYiIqLqzKjhJj8/HydPnoSvr6+mzcTEBL6+vjh+/HiZ22VlZaFRo0ZwdXXFG2+8gXPnzpW5bl5eHjIyMrReREREJF+1jHnwe/fuoaioqMTIi6OjIy5cuFDqNi1atMCqVavQtm1bpKen44svvoCPjw/OnTuHBg0alFg/LCwMH3/8saS6hBAoLCxEUVGRpO2I5MbU1BS1atWCQqEwdilERDozaripCG9vb3h7e2ve+/j4oFWrVvj2228xb968EuvPmDEDISEhmvcZGRlwdXUtc//5+flISkpCTk6OfgsnqqEsLCxQv359KJVKY5dCRKQTo4YbOzs7mJqaIiUlRas9JSUFTk5OOu3DzMwM7du3x+XLl0tdrlKpoFKpdNpXcXExEhISYGpqCmdnZyiVSv6PlZ5ZQgjk5+fj7t27SEhIQLNmzWBiYvRpekRET2XUcKNUKtGxY0dER0ejT58+AB4FjOjoaIwdO1anfRQVFeHMmTPw9/evdD35+fkoLi6Gq6srLCwsKr0/oppOrVbDzMwM169fR35+Pm+7QEQ1gtFPS4WEhCAwMBCdOnWCl5cXFi9ejOzsbAQFBQEAhgwZAhcXF4SFhQEA5s6di+effx5NmzZFWloaPv/8c1y/fh3Dhw/XW0383ynR//D3gYhqGqOHmwEDBuDu3buYPXs2kpOT0a5dO0RFRWkmGScmJmr945qamorg4GAkJyejTp066NixI44dOwYPDw9jfQQiIiKqRhRCCGHsIqpSRkYGbGxskJ6eDmtra61lDx8+REJCAho3bszhd6L/j78XRKSrnPxCeMzeCwCIn+sHC6X+xlDK+/5+EsebiYiISFYYbp4xCoUC27dvN/hxDh06BIVCgbS0NE3b9u3b0bRpU5iammLixImIjIyEra2twWq4ePEinJyckJmZabBj1HTx8fFo0KABsrOzjV0KEZHeMNzISHJyMsaNGwd3d3eoVCq4urqiV69eiI6OrvJafHx8kJSUBBsbG03byJEj8dZbb+HGjRuYN28eBgwYgH/++cdgNcyYMQPjxo2DlZVViWUtW7aESqVCcnJyiWUvvfSS1kNZPTw8sGzZMoPVCQAPHjxAQEAArK2tYWtri2HDhiErK6vcba5cuYK+ffvC3t4e1tbW6N+/f4nbKsTGxqJHjx6wtbVFvXr1MGLECK39enh44Pnnn8eiRYsM8rmIiIyB4eYphBDIyS80ykvKdKhr166hY8eOOHDgAD7//HOcOXMGUVFR6N69O8aMGWPAHiqdUqmEk5OT5j5BWVlZuHPnDvz8/ODs7AwrKyuo1Wo4ODhU6jgFBQWlticmJmLXrl0YOnRoiWUxMTHIzc3FW2+9hTVr1pS6fXBwMJKSkhAfH4/+/ftjzJgx+PHHHytVa3kCAgJw7tw57Nu3D7t27cJvv/2GESNGlLl+dnY2Xn31VSgUChw4cABHjx5Ffn4+evXqheLiYgDA7du34evri6ZNm+KPP/5AVFQUzp07V6JPgoKCsHz5chQWFhrs8xERVSWjXy1V3eUWFGkmR1U1KZOx3n//fSgUCpw4cQK1a9fWtLdu3RrvvfdemdtNmzYN27Ztw82bN+Hk5ISAgADMnj0bZmZmAIDTp09j4sSJ+Ouvv6BQKNCsWTN8++236NSpE65fv46xY8ciJiYG+fn5cHNzw+effw5/f38cOnQI3bt3R2pqKuLi4tC9e3cAwMsvvwwAOHjwIK5du4aJEydqnbrasWMHPv74Y8THx8PZ2RmBgYGYOXMmatV61A8KhQLLli3DL7/8gujoaEyZMgVz5swp8bl++ukneHp6wsXFpcSylStXYtCgQejWrRsmTJiAadOmlVjHwsJCcyPJOXPm4IcffsDOnTsxcODAp/xNSHf+/HlERUXhzz//RKdOnQAAS5cuhb+/P7744gs4OzuX2Obo0aO4du0aTp06pZlYt2bNGtSpUwcHDhyAr68vdu3aBTMzM4SHh2uuOIyIiEDbtm1x+fJlNG3aFADQo0cPPHjwAIcPH8Yrr7yi989HRFTVOHIjAw8ePEBUVBTGjBmjFWweK29ei5WVFSIjIxEfH48lS5ZgxYoV+OqrrzTLAwIC0KBBA/z55584efIkpk+frgk+Y8aMQV5eHn777TecOXMGn376KSwtLUscw8fHBxcvXgQAbNmyBUlJSfDx8Smx3pEjRzBkyBBMmDAB8fHx+PbbbxEZGYkFCxZorTdnzhz07dsXZ86cKTO4HTlyRBMU/i0zMxObNm3Cu+++ix49eiA9PR1Hjhwps38eU6vVyM/PL3N569atYWlpWearZ8+eZW57/Phx2NraatXr6+sLExMT/PHHH6Vuk5eXB4VCoXX3bXNzc5iYmCAmJkazjlKp1LqVglqtBgDNOsCjUbZ27drp1A9ERDUBR26eQm1mivi5fkY7ti4uX74MIQRatmwp+RizZs3S/NnNzQ2TJ0/Ghg0bMHXqVACPTu9MmTJFs+9mzZpp1k9MTES/fv3Qpk0bAIC7u3upx1AqlZrTT3Xr1i3z0Roff/wxpk+fjsDAQM3+5s2bh6lTpyI0NFSz3qBBgzQ3eSzL9evXSw03GzZsQLNmzdC6dWsAwDvvvIOVK1fixRdfLHU/RUVF+PHHH/H333+Xe5poz549ZZ4iA/4XKkqTnJxc4vRcrVq1ULdu3VLnBAHA888/j9q1a2PatGlYuHAhhBCYPn06ioqKkJSUBODRKFlISAg+//xzTJgwAdnZ2Zg+fToAaNZ5zNnZGdevXy+zRiKimoTh5ikUCoVer9M3hMrcqmjjxo34+uuvceXKFWRlZaGwsFDr/gEhISEYPnw41q1bB19fX7z99tto0qQJAGD8+PEYPXo0fv31V/j6+qJfv35o27ZthWs5ffo0jh49qjVSU1RUhIcPHyInJ0fzSIzSQsuTcnNzS70ny6pVq/Duu+9q3r/77rvo1q0bli5dqjXxeNmyZfj++++Rn58PU1NTTJo0CaNHjy7zeI0aNdLpM+qLvb09Nm3ahNGjR+Prr7+GiYkJBg4ciA4dOmhGalq3bo01a9YgJCQEM2bMgKmpKcaPHw9HR8cSdx1Wq9V8WCwRyQZPS8lAs2bNoFAocOHCBUnbHT9+HAEBAfD398euXbtw6tQpzJw5U+v0y5w5c3Du3Dm8/vrrOHDgADw8PLBt2zYAwPDhw3H16lUMHjwYZ86cQadOnbB06dIKf46srCx8/PHHiIuL07zOnDmDS5cuaQWV0k69PcnOzg6pqalabfHx8fj9998xdepU1KpVC7Vq1cLzzz+PnJwcbNiwQWvdgIAAxMXFISEhAdnZ2Vi0aFG5jyGozGkpJycn3LlzR6utsLAQDx48KPcBsq+++iquXLmCO3fu4N69e1i3bh1u3bqlNYI2aNAgJCcn49atW7h//z7mzJmDu3fvlhhle/DgAezt7cs8FhFRTVK9hyRIJ3Xr1oWfnx/Cw8Mxfvz4El/+aWlppc67OXbsGBo1aoSZM2dq2ko7NdG8eXM0b94ckyZNwsCBA7F69Wr07dsXAODq6opRo0Zh1KhRmDFjBlasWIFx48ZV6HN06NABFy9e1Ex0rYz27dsjPj5eq23lypXo2rUrwsPDtdpXr16NlStXIjg4WNNmY2MjqY7KnJby9vZGWloaTp48iY4dOwIADhw4gOLiYnTu3Pmpx7azs9Nsc+fOHfTu3bvEOo8fZ7Jq1SqYm5ujR48eWsvPnj2Lt95666nHIiKqCRhuZCI8PBxdunSBl5cX5s6di7Zt26KwsBD79u3D8uXLcf78+RLbNGvWDImJidiwYQP+85//YPfu3ZpRGeDRqZ0pU6bgrbfeQuPGjXHz5k38+eef6NevHwBg4sSJ6NmzJ5o3b47U1FQcPHgQrVq1qvBnmD17Nv773/+iYcOGeOutt2BiYoLTp0/j7NmzmD9/vqR9+fn5Yfjw4SgqKoKpqSkKCgqwbt06zJ07F88995zWusOHD8eiRYtw7tw5zVwcqSpzWqpVq1Z47bXXEBwcjIiICBQUFGDs2LF45513NFdK3bp1C6+88grWrl0LLy8vAI9CWatWrWBvb4/jx49jwoQJmDRpElq0aKHZ9zfffAMfHx9YWlpi3759mDJlCj755BOtsHvt2jXcunULvr6+Ff4MRESA9jxVXeeNGoR4xqSnpwsAIj09vcSy3NxcER8fL3Jzc41QWeXdvn1bjBkzRjRq1EgolUrh4uIievfuLQ4ePKhZB4DYtm2b5v2UKVNEvXr1hKWlpRgwYID46quvhI2NjRBCiLy8PPHOO+8IV1dXoVQqhbOzsxg7dqymf8aOHSuaNGkiVCqVsLe3F4MHDxb37t0TQghx8OBBAUCkpqYKIYRITU0VALRqWb16teZYj0VFRQkfHx+hVquFtbW18PLyEt99912Z9ZeloKBAODs7i6ioKCGEEJs3bxYmJiYiOTm51PVbtWolJk2aJIQQolu3bmLChAlPPYY+3b9/XwwcOFBYWloKa2trERQUJDIzMzXLExISSvTftGnThKOjozAzMxPNmjUTX375pSguLtba7+DBg0XdunWFUqkUbdu2FWvXri1x7IULFwo/P78ya6vpvxdEJA/lfX8/iQ/O/Bc+IFBewsPDsXPnTuzda5z7FNUE+fn5aNasGX744Qd06dKl1HX4e0FE1YGUB2fytBTJ1siRI5GWlobMzMxSH8FAjy7n//DDD8sMNkRENRHDDclWrVq1tCZLU0lNmzbVywRuIqLqhJeCExERkaww3JTiGZuGRFQu/j4QUU3DcPMvj5+ZxDu1Ev3P49+Hx78fRETVHefc/IupqSlsbW01d4u1sLCAQqEwclVExiGEQE5ODu7cuQNbW1uYmhrxnhVERBIw3Dzh8e3un7wdPtGzytbWttzHQBARVTcMN09QKBSoX78+HBwcyr2dPtGzwMzMjCM2RFTjMNyUwdTUlP+oExER1UCcUExERESywnBDREREssJwQ0RERLLyzM25eXxDsoyMDCNXQkRERLp6/L2ty41Fn7lwk5mZCQBwdXU1ciVEREQkVWZmJmxsbMpdRyGesXurFxcX4/bt27CystL7DfoyMjLg6uqKGzduPPVx7FRx7OeqwX6uGuznqsO+rhqG6mchBDIzM+Hs7AwTk/Jn1TxzIzcmJiZo0KCBQY9hbW3NX5wqwH6uGuznqsF+rjrs66phiH5+2ojNY5xQTERERLLCcENERESywnCjRyqVCqGhoVCpVMYuRdbYz1WD/Vw12M9Vh31dNapDPz9zE4qJiIhI3jhyQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcCNReHg43NzcYG5ujs6dO+PEiRPlrr9p0ya0bNkS5ubmaNOmDfbs2VNFldZsUvp5xYoVePHFF1GnTh3UqVMHvr6+T/17oUek/jw/tmHDBigUCvTp08ewBcqE1H5OS0vDmDFjUL9+fahUKjRv3pz/duhAaj8vXrwYLVq0gFqthqurKyZNmoSHDx9WUbU102+//YZevXrB2dkZCoUC27dvf+o2hw4dQocOHaBSqdC0aVNERkYavE4I0tmGDRuEUqkUq1atEufOnRPBwcHC1tZWpKSklLr+0aNHhampqfjss89EfHy8mDVrljAzMxNnzpyp4sprFqn9PGjQIBEeHi5OnTolzp8/L4YOHSpsbGzEzZs3q7jymkVqPz+WkJAgXFxcxIsvvijeeOONqim2BpPaz3l5eaJTp07C399fxMTEiISEBHHo0CERFxdXxZXXLFL7ef369UKlUon169eLhIQEsXfvXlG/fn0xadKkKq68ZtmzZ4+YOXOm2Lp1qwAgtm3bVu76V69eFRYWFiIkJETEx8eLpUuXClNTUxEVFWXQOhluJPDy8hJjxozRvC8qKhLOzs4iLCys1PX79+8vXn/9da22zp07i5EjRxq0zppOaj8/qbCwUFhZWYk1a9YYqkRZqEg/FxYWCh8fH/H999+LwMBAhhsdSO3n5cuXC3d3d5Gfn19VJcqC1H4eM2aMePnll7XaQkJCRJcuXQxap5zoEm6mTp0qWrdurdU2YMAA4efnZ8DKhOBpKR3l5+fj5MmT8PX11bSZmJjA19cXx48fL3Wb48ePa60PAH5+fmWuTxXr5yfl5OSgoKAAdevWNVSZNV5F+3nu3LlwcHDAsGHDqqLMGq8i/bxz5054e3tjzJgxcHR0xHPPPYeFCxeiqKioqsqucSrSzz4+Pjh58qTm1NXVq1exZ88e+Pv7V0nNzwpjfQ8+cw/OrKh79+6hqKgIjo6OWu2Ojo64cOFCqdskJyeXun5ycrLB6qzpKtLPT5o2bRqcnZ1L/ELR/1Skn2NiYrBy5UrExcVVQYXyUJF+vnr1Kg4cOICAgADs2bMHly9fxvvvv4+CggKEhoZWRdk1TkX6edCgQbh37x5eeOEFCCFQWFiIUaNG4cMPP6yKkp8ZZX0PZmRkIDc3F2q12iDH5cgNyconn3yCDRs2YNu2bTA3Nzd2ObKRmZmJwYMHY8WKFbCzszN2ObJWXFwMBwcHfPfdd+jYsSMGDBiAmTNnIiIiwtilycqhQ4ewcOFCLFu2DLGxsdi6dSt2796NefPmGbs00gOO3OjIzs4OpqamSElJ0WpPSUmBk5NTqds4OTlJWp8q1s+PffHFF/jkk0+wf/9+tG3b1pBl1nhS+/nKlSu4du0aevXqpWkrLi4GANSqVQsXL15EkyZNDFt0DVSRn+f69evDzMwMpqammrZWrVohOTkZ+fn5UCqVBq25JqpIP3/00UcYPHgwhg8fDgBo06YNsrOzMWLECMycORMmJvy/vz6U9T1obW1tsFEbgCM3OlMqlejYsSOio6M1bcXFxYiOjoa3t3ep23h7e2utDwD79u0rc32qWD8DwGeffYZ58+YhKioKnTp1qopSazSp/dyyZUucOXMGcXFxmlfv3r3RvXt3xMXFwdXVtSrLrzEq8vPcpUsXXL58WRMeAeCff/5B/fr1GWzKUJF+zsnJKRFgHgdKwUcu6o3RvgcNOl1ZZjZs2CBUKpWIjIwU8fHxYsSIEcLW1lYkJycLIYQYPHiwmD59umb9o0ePilq1aokvvvhCnD9/XoSGhvJScB1I7edPPvlEKJVKsXnzZpGUlKR5ZWZmGusj1AhS+/lJvFpKN1L7OTExUVhZWYmxY8eKixcvil27dgkHBwcxf/58Y32EGkFqP4eGhgorKyvx448/iqtXr4pff/1VNGnSRPTv399YH6FGyMzMFKdOnRKnTp0SAMSiRYvEqVOnxPXr14UQQkyfPl0MHjxYs/7jS8GnTJkizp8/L8LDw3kpeHW0dOlS0bBhQ6FUKoWXl5f4/fffNcu6desmAgMDtdb/6aefRPPmzYVSqRStW7cWu3fvruKKayYp/dyoUSMBoMQrNDS06guvYaT+PP8bw43upPbzsWPHROfOnYVKpRLu7u5iwYIForCwsIqrrnmk9HNBQYGYM2eOaNKkiTA3Nxeurq7i/fffF6mpqVVfeA1y8ODBUv+9fdy3gYGBolu3biW2adeunVAqlcLd3V2sXr3a4HUqhOD4GxEREckH59wQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcEBERkaww3BCRFoVCge3btwMArl27BoVCgbi4uHK3uXjxIpycnJCZmWn4AgG4ublh8eLF5a4zZ84ctGvXzqB1VOQY/+7fiho6dCj69OlTqX2U5vnnn8eWLVv0vl+iqsZwQ1RNDB06FAqFAgqFAmZmZmjcuDGmTp2Khw8fGru0p5oxYwbGjRsHKysrAMChQ4c0n0WhUMDR0RH9+vXD1atX9XK8P//8EyNGjNC8Ly0wTJ48ucQD+55lv/32G3r16gVnZ+cyA9asWbMwffp0rYd2EtVEDDdE1chrr72GpKQkXL16FV999RW+/fZbhIaGGrusciUmJmLXrl0YOnRoiWUXL17E7du3sWnTJpw7dw69evVCUVFRpY9pb28PCwuLctextLREvXr1Kn0sucjOzoanpyfCw8PLXKdnz57IzMzEL7/8UoWVEekfww1RNaJSqeDk5ARXV1f06dMHvr6+2Ldvn2Z5cXExwsLC0LhxY6jVanh6emLz5s1a+zh37hz++9//wtraGlZWVnjxxRdx5coVAI9GPHr06AE7OzvY2NigW7duiI2NrVTNP/30Ezw9PeHi4lJimYODA+rXr4+uXbti9uzZiI+Px+XLlwEAy5cvR5MmTaBUKtGiRQusW7dOs50QAnPmzEHDhg2hUqng7OyM8ePHa5b/+7SUm5sbAKBv375QKBSa9/8+ZfTrr7/C3NwcaWlpWvVNmDABL7/8suZ9TEwMXnzxRajVari6umL8+PHIzs7WuS907d+kpCT07NkTarUa7u7uJf4Ob9y4gf79+8PW1hZ169bFG2+8gWvXrulcR2l69uyJ+fPno2/fvmWuY2pqCn9/f2zYsKFSxyIyNoYbomrq7NmzOHbsGJRKpaYtLCwMa9euRUREBM6dO4dJkybh3XffxeHDhwEAt27dQteuXaFSqXDgwAGcPHkS7733HgoLCwEAmZmZCAwMRExMDH7//Xc0a9YM/v7+lZorc+TIEXTq1Omp66nVagBAfn4+tm3bhgkTJuCDDz7A2bNnMXLkSAQFBeHgwYMAgC1btmhGri5duoTt27ejTZs2pe73zz//BACsXr0aSUlJmvf/9sorr8DW1lZrPklRURE2btyIgIAAAMCVK1fw2muvoV+/fvj777+xceNGxMTEYOzYsTr3ha79+9FHH6Ffv344ffo0AgIC8M477+D8+fMAgIKCAvj5+cHKygpHjhzB0aNHYWlpiddeew35+fmlHjcyMhIKhULnOsvj5eWFI0eO6GVfREZj8OeOE5FOAgMDhampqahdu7ZQqVQCgDAxMRGbN28WQgjx8OFDYWFhIY4dO6a13bBhw8TAgQOFEELMmDFDNG7cWOTn5+t0zKKiImFlZSV+/vlnTRsAsW3bNiGEEAkJCQKAOHXqVJn78PT0FHPnztVqO3jwoAAgUlNThRBC3L59W/j4+AgXFxeRl5cnfHx8RHBwsNY2b7/9tvD39xdCCPHll1+K5s2bl/k5GjVqJL766qtSa34sNDRUeHp6at5PmDBBvPzyy5r3e/fuFSqVSlPjsGHDxIgRI7T2ceTIEWFiYiJyc3NLrePJYzyprP4dNWqU1nqdO3cWo0ePFkIIsW7dOtGiRQtRXFysWZ6XlyfUarXYu3evEOLRz8obb7yhWb5161bRokWLMut4Umn99diOHTuEiYmJKCoq0nl/RNUNR26IqpHu3bsjLi4Of/zxBwIDAxEUFIR+/foBAC5fvoycnBz06NEDlpaWmtfatWs1p53i4uLw4osvwszMrNT9p6SkIDg4GM2aNYONjQ2sra2RlZWFxMTECtecm5sLc3PzUpc1aNAAtWvXhrOzM7Kzs7FlyxYolUqcP38eXbp00Vq3S5cumtGLt99+G7m5uXB3d0dwcDC2bdumGX2qqICAABw6dAi3b98GAKxfvx6vv/46bG1tAQCnT59GZGSkVt/6+fmhuLgYCQkJOh1D1/719vYu8f7xZz99+jQuX74MKysrTR1169bFw4cPNX/PT+rbty8uXLggpTvKpFarUVxcjLy8PL3sj8gYahm7ACL6n9q1a6Np06YAgFWrVsHT0xMrV67EsGHDkJWVBQDYvXt3ifktKpUKwP9O/ZQlMDAQ9+/fx5IlS9CoUSOoVCp4e3uXebpDF3Z2dkhNTS112ZEjR2BtbQ0HBwfNlVS6cHV1xcWLF7F//37s27cP77//Pj7//HMcPny4zOD2NP/5z3/QpEkTbNiwAaNHj8a2bdsQGRmpWZ6VlYWRI0dqze15rGHDhjodQx/9m5WVhY4dO2L9+vUlltnb2+u8n4p68OABateu/dSfJaLqjOGGqJoyMTHBhx9+iJCQEAwaNAgeHh5QqVRITExEt27dSt2mbdu2WLNmDQoKCkoNAUePHsWyZcvg7+8P4NHE1Xv37lWqzvbt2yM+Pr7UZY0bN9aMjPxbq1atcPToUQQGBmrV5uHhoXmvVqvRq1cv9OrVC2PGjEHLli1x5swZdOjQocT+zMzMdLoKKyAgAOvXr0eDBg1gYmKC119/XbOsQ4cOiI+P14TLitC1f3///XcMGTJE63379u01dWzcuBEODg6wtraucC0VdfbsWU0tRDUVT0sRVWNvv/02TE1NER4eDisrK0yePBmTJk3CmjVrcOXKFcTGxmLp0qVYs2YNAGDs2LHIyMjAO++8g7/++guXLl3CunXrcPHiRQBAs2bNsG7dOpw/fx5//PEHAgICKv0/dD8/Pxw/flzSJd5TpkxBZGQkli9fjkuXLmHRokXYunUrJk+eDODRBNmVK1fi7NmzuHr1Kv7v//4ParUajRo1KnV/bm5uiI6ORnJycpmjSMCjcBMbG4sFCxbgrbfe0ox4AcC0adNw7NgxjB07FnFxcbh06RJ27NghaUKxrv27adMmrFq1Cv/88w9CQ0Nx4sQJzXECAgJgZ2eHN954A0eOHEFCQgIOHTqE8ePH4+bNm6Ued9u2bWjZsmW5tWVlZSEuLk5zQ8aEhATExcWVOGV25MgRvPrqqzp/ZqJqydiTfojokScniT4WFhYm7O3tRVZWliguLhaLFy8WLVq0EGZmZsLe3l74+fmJw4cPa9Y/ffq0ePXVV4WFhYWwsrISL774orhy5YoQQojY2FjRqVMnYW5uLpo1ayY2bdpU7uRcXSYUFxQUCGdnZxEVFaVpe3JCcWmWLVsm3N3dhZmZmWjevLlYu3atZtm2bdtE586dhbW1tahdu7Z4/vnnxf79+zXLn6x5586domnTpqJWrVqiUaNGQoiyJ/t6eXkJAOLAgQMllp04cUL06NFDWFpaitq1a4u2bduKBQsWlPkZnjyGrv0bHh4uevToIVQqlXBzcxMbN27U2m9SUpIYMmSIsLOzEyqVSri7u4vg4GCRnp4uhCj5s7J69WrxtH/OH/+dPPkKDAzUrHPz5k1hZmYmbty4Ue6+iKo7hRBCGClXEZFMhIeHY+fOndi7d6+xS6FKmDZtGlJTU/Hdd98ZuxSiSuGcGyKqtJEjRyItLQ2ZmZmSJg5T9eLg4ICQkBBjl0FUaRy5ISIiIlnhhGIiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpIVhhsiIiKSFYYbIiIikhWGGyIiIpKV/wcUFzWwXTnB9wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, PrecisionRecallDisplay, precision_recall_curve\n",
    "print(\"Validation: Victor+Oct2022\")\n",
    "y_true = tpot_df.query('group==\"val\"')['inappropriate_label']\n",
    "y_score = tpot_df.query('group==\"val\"')['inappropriate_prob']\n",
    "y_pred = y_score >= 0.5\n",
    "print(f'the auc score is {roc_auc_score(y_true,y_score)}')\n",
    "print(classification_report(y_true,y_pred, digits=3))\n",
    "\n",
    "print(\"Validation: Victor set\")\n",
    "y_true = tpot_df.query('group==\"val\" & set == \"victor\"')['inappropriate_label']\n",
    "y_score = tpot_df.query('group==\"val\" & set == \"victor\"')['inappropriate_prob']\n",
    "y_pred = y_score >= 0.5\n",
    "print(f'the auc score is {roc_auc_score(y_true,y_score)}')\n",
    "print(classification_report(y_true,y_pred, digits=3))\n",
    "\n",
    "PrecisionRecallDisplay.from_predictions(y_true, y_score)\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, y_score)\n",
    "precision, recall, thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Victor set\n",
      "the auc score is 0.9712292692984127\n",
      "Classification report when threshold is 0.3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.891     0.937     0.914       987\n",
      "         1.0      0.933     0.884     0.908       973\n",
      "\n",
      "    accuracy                          0.911      1960\n",
      "   macro avg      0.912     0.911     0.911      1960\n",
      "weighted avg      0.912     0.911     0.911      1960\n",
      "\n",
      "Classification report when threshold is 0.3075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.891     0.937     0.914       987\n",
      "         1.0      0.933     0.884     0.908       973\n",
      "\n",
      "    accuracy                          0.911      1960\n",
      "   macro avg      0.912     0.911     0.911      1960\n",
      "weighted avg      0.912     0.911     0.911      1960\n",
      "\n",
      "Classification report when threshold is 0.315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.891     0.937     0.914       987\n",
      "         1.0      0.933     0.884     0.908       973\n",
      "\n",
      "    accuracy                          0.911      1960\n",
      "   macro avg      0.912     0.911     0.911      1960\n",
      "weighted avg      0.912     0.911     0.911      1960\n",
      "\n",
      "Classification report when threshold is 0.3225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.891     0.937     0.914       987\n",
      "         1.0      0.933     0.884     0.908       973\n",
      "\n",
      "    accuracy                          0.911      1960\n",
      "   macro avg      0.912     0.911     0.911      1960\n",
      "weighted avg      0.912     0.911     0.911      1960\n",
      "\n",
      "Classification report when threshold is 0.33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.889     0.937     0.913       987\n",
      "         1.0      0.933     0.882     0.906       973\n",
      "\n",
      "    accuracy                          0.910      1960\n",
      "   macro avg      0.911     0.909     0.910      1960\n",
      "weighted avg      0.911     0.910     0.910      1960\n",
      "\n",
      "Classification report when threshold is 0.3375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.889     0.937     0.913       987\n",
      "         1.0      0.933     0.882     0.906       973\n",
      "\n",
      "    accuracy                          0.910      1960\n",
      "   macro avg      0.911     0.909     0.910      1960\n",
      "weighted avg      0.911     0.910     0.910      1960\n",
      "\n",
      "Classification report when threshold is 0.34500000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.889     0.937     0.912       987\n",
      "         1.0      0.933     0.881     0.906       973\n",
      "\n",
      "    accuracy                          0.909      1960\n",
      "   macro avg      0.911     0.909     0.909      1960\n",
      "weighted avg      0.910     0.909     0.909      1960\n",
      "\n",
      "Classification report when threshold is 0.35250000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.888     0.937     0.912       987\n",
      "         1.0      0.932     0.880     0.905       973\n",
      "\n",
      "    accuracy                          0.909      1960\n",
      "   macro avg      0.910     0.908     0.909      1960\n",
      "weighted avg      0.910     0.909     0.909      1960\n",
      "\n",
      "Classification report when threshold is 0.36000000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.887     0.937     0.911       987\n",
      "         1.0      0.932     0.879     0.905       973\n",
      "\n",
      "    accuracy                          0.908      1960\n",
      "   macro avg      0.910     0.908     0.908      1960\n",
      "weighted avg      0.909     0.908     0.908      1960\n",
      "\n",
      "Classification report when threshold is 0.36750000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.886     0.937     0.911       987\n",
      "         1.0      0.932     0.878     0.904       973\n",
      "\n",
      "    accuracy                          0.908      1960\n",
      "   macro avg      0.909     0.907     0.908      1960\n",
      "weighted avg      0.909     0.908     0.908      1960\n",
      "\n",
      "Classification report when threshold is 0.37500000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.884     0.938     0.911       987\n",
      "         1.0      0.933     0.876     0.903       973\n",
      "\n",
      "    accuracy                          0.907      1960\n",
      "   macro avg      0.909     0.907     0.907      1960\n",
      "weighted avg      0.909     0.907     0.907      1960\n",
      "\n",
      "Classification report when threshold is 0.38250000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.884     0.938     0.910       987\n",
      "         1.0      0.933     0.875     0.903       973\n",
      "\n",
      "    accuracy                          0.907      1960\n",
      "   macro avg      0.908     0.906     0.906      1960\n",
      "weighted avg      0.908     0.907     0.907      1960\n",
      "\n",
      "Classification report when threshold is 0.39000000000000007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.881     0.939     0.909       987\n",
      "         1.0      0.934     0.872     0.902       973\n",
      "\n",
      "    accuracy                          0.906      1960\n",
      "   macro avg      0.908     0.905     0.905      1960\n",
      "weighted avg      0.907     0.906     0.905      1960\n",
      "\n",
      "Classification report when threshold is 0.3975000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.881     0.939     0.909       987\n",
      "         1.0      0.934     0.872     0.902       973\n",
      "\n",
      "    accuracy                          0.906      1960\n",
      "   macro avg      0.908     0.905     0.905      1960\n",
      "weighted avg      0.907     0.906     0.905      1960\n",
      "\n",
      "Classification report when threshold is 0.4050000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.881     0.939     0.909       987\n",
      "         1.0      0.934     0.872     0.902       973\n",
      "\n",
      "    accuracy                          0.906      1960\n",
      "   macro avg      0.908     0.905     0.905      1960\n",
      "weighted avg      0.907     0.906     0.905      1960\n",
      "\n",
      "Classification report when threshold is 0.4125000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.880     0.939     0.909       987\n",
      "         1.0      0.934     0.871     0.901       973\n",
      "\n",
      "    accuracy                          0.905      1960\n",
      "   macro avg      0.907     0.905     0.905      1960\n",
      "weighted avg      0.907     0.905     0.905      1960\n",
      "\n",
      "Classification report when threshold is 0.4200000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.880     0.940     0.909       987\n",
      "         1.0      0.935     0.869     0.901       973\n",
      "\n",
      "    accuracy                          0.905      1960\n",
      "   macro avg      0.907     0.905     0.905      1960\n",
      "weighted avg      0.907     0.905     0.905      1960\n",
      "\n",
      "Classification report when threshold is 0.4275000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.878     0.942     0.909       987\n",
      "         1.0      0.937     0.867     0.901       973\n",
      "\n",
      "    accuracy                          0.905      1960\n",
      "   macro avg      0.907     0.905     0.905      1960\n",
      "weighted avg      0.907     0.905     0.905      1960\n",
      "\n",
      "Classification report when threshold is 0.4350000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.877     0.942     0.909       987\n",
      "         1.0      0.937     0.866     0.900       973\n",
      "\n",
      "    accuracy                          0.905      1960\n",
      "   macro avg      0.907     0.904     0.904      1960\n",
      "weighted avg      0.907     0.905     0.904      1960\n",
      "\n",
      "Classification report when threshold is 0.4425000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.877     0.942     0.908       987\n",
      "         1.0      0.937     0.865     0.900       973\n",
      "\n",
      "    accuracy                          0.904      1960\n",
      "   macro avg      0.907     0.904     0.904      1960\n",
      "weighted avg      0.906     0.904     0.904      1960\n",
      "\n",
      "Classification report when threshold is 0.4500000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.874     0.942     0.907       987\n",
      "         1.0      0.936     0.862     0.898       973\n",
      "\n",
      "    accuracy                          0.903      1960\n",
      "   macro avg      0.905     0.902     0.902      1960\n",
      "weighted avg      0.905     0.903     0.902      1960\n",
      "\n",
      "Classification report when threshold is 0.45750000000000013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.874     0.944     0.908       987\n",
      "         1.0      0.938     0.862     0.899       973\n",
      "\n",
      "    accuracy                          0.904      1960\n",
      "   macro avg      0.906     0.903     0.903      1960\n",
      "weighted avg      0.906     0.904     0.903      1960\n",
      "\n",
      "Classification report when threshold is 0.46500000000000014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.874     0.945     0.908       987\n",
      "         1.0      0.940     0.862     0.899       973\n",
      "\n",
      "    accuracy                          0.904      1960\n",
      "   macro avg      0.907     0.904     0.904      1960\n",
      "weighted avg      0.907     0.904     0.904      1960\n",
      "\n",
      "Classification report when threshold is 0.47250000000000014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.875     0.947     0.910       987\n",
      "         1.0      0.942     0.862     0.900       973\n",
      "\n",
      "    accuracy                          0.905      1960\n",
      "   macro avg      0.908     0.905     0.905      1960\n",
      "weighted avg      0.908     0.905     0.905      1960\n",
      "\n",
      "Classification report when threshold is 0.48000000000000015\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.875     0.948     0.910       987\n",
      "         1.0      0.943     0.862     0.901       973\n",
      "\n",
      "    accuracy                          0.906      1960\n",
      "   macro avg      0.909     0.905     0.905      1960\n",
      "weighted avg      0.908     0.906     0.905      1960\n",
      "\n",
      "Classification report when threshold is 0.48750000000000016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.875     0.949     0.911       987\n",
      "         1.0      0.944     0.862     0.901       973\n",
      "\n",
      "    accuracy                          0.906      1960\n",
      "   macro avg      0.909     0.906     0.906      1960\n",
      "weighted avg      0.909     0.906     0.906      1960\n",
      "\n",
      "Classification report when threshold is 0.49500000000000016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.874     0.949     0.910       987\n",
      "         1.0      0.944     0.861     0.901       973\n",
      "\n",
      "    accuracy                          0.906      1960\n",
      "   macro avg      0.909     0.905     0.905      1960\n",
      "weighted avg      0.909     0.906     0.905      1960\n",
      "\n",
      "Classification report when threshold is 0.5025000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.874     0.949     0.910       987\n",
      "         1.0      0.944     0.861     0.901       973\n",
      "\n",
      "    accuracy                          0.906      1960\n",
      "   macro avg      0.909     0.905     0.905      1960\n",
      "weighted avg      0.909     0.906     0.905      1960\n",
      "\n",
      "Classification report when threshold is 0.5100000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.873     0.951     0.911       987\n",
      "         1.0      0.946     0.860     0.901       973\n",
      "\n",
      "    accuracy                          0.906      1960\n",
      "   macro avg      0.910     0.906     0.906      1960\n",
      "weighted avg      0.909     0.906     0.906      1960\n",
      "\n",
      "Classification report when threshold is 0.5175000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.873     0.951     0.910       987\n",
      "         1.0      0.946     0.859     0.900       973\n",
      "\n",
      "    accuracy                          0.906      1960\n",
      "   macro avg      0.909     0.905     0.905      1960\n",
      "weighted avg      0.909     0.906     0.905      1960\n",
      "\n",
      "Classification report when threshold is 0.5250000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.873     0.953     0.911       987\n",
      "         1.0      0.948     0.859     0.901       973\n",
      "\n",
      "    accuracy                          0.907      1960\n",
      "   macro avg      0.910     0.906     0.906      1960\n",
      "weighted avg      0.910     0.907     0.906      1960\n",
      "\n",
      "Classification report when threshold is 0.5325000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.873     0.953     0.911       987\n",
      "         1.0      0.948     0.859     0.901       973\n",
      "\n",
      "    accuracy                          0.907      1960\n",
      "   macro avg      0.910     0.906     0.906      1960\n",
      "weighted avg      0.910     0.907     0.906      1960\n",
      "\n",
      "Classification report when threshold is 0.5400000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.872     0.955     0.912       987\n",
      "         1.0      0.950     0.857     0.901       973\n",
      "\n",
      "    accuracy                          0.907      1960\n",
      "   macro avg      0.911     0.906     0.906      1960\n",
      "weighted avg      0.910     0.907     0.906      1960\n",
      "\n",
      "Classification report when threshold is 0.5475000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.870     0.957     0.912       987\n",
      "         1.0      0.952     0.855     0.901       973\n",
      "\n",
      "    accuracy                          0.907      1960\n",
      "   macro avg      0.911     0.906     0.906      1960\n",
      "weighted avg      0.911     0.907     0.906      1960\n",
      "\n",
      "Classification report when threshold is 0.5550000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.869     0.957     0.911       987\n",
      "         1.0      0.952     0.854     0.900       973\n",
      "\n",
      "    accuracy                          0.906      1960\n",
      "   macro avg      0.911     0.906     0.906      1960\n",
      "weighted avg      0.910     0.906     0.906      1960\n",
      "\n",
      "Classification report when threshold is 0.5625000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.869     0.957     0.911       987\n",
      "         1.0      0.952     0.853     0.900       973\n",
      "\n",
      "    accuracy                          0.906      1960\n",
      "   macro avg      0.910     0.905     0.905      1960\n",
      "weighted avg      0.910     0.906     0.905      1960\n",
      "\n",
      "Classification report when threshold is 0.5700000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.868     0.957     0.910       987\n",
      "         1.0      0.952     0.852     0.899       973\n",
      "\n",
      "    accuracy                          0.905      1960\n",
      "   macro avg      0.910     0.905     0.905      1960\n",
      "weighted avg      0.909     0.905     0.905      1960\n",
      "\n",
      "Classification report when threshold is 0.5775000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.867     0.957     0.910       987\n",
      "         1.0      0.952     0.851     0.899       973\n",
      "\n",
      "    accuracy                          0.905      1960\n",
      "   macro avg      0.909     0.904     0.904      1960\n",
      "weighted avg      0.909     0.905     0.904      1960\n",
      "\n",
      "Classification report when threshold is 0.5850000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.865     0.957     0.909       987\n",
      "         1.0      0.952     0.849     0.897       973\n",
      "\n",
      "    accuracy                          0.904      1960\n",
      "   macro avg      0.908     0.903     0.903      1960\n",
      "weighted avg      0.908     0.904     0.903      1960\n",
      "\n",
      "Classification report when threshold is 0.5925000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.865     0.957     0.909       987\n",
      "         1.0      0.952     0.848     0.897       973\n",
      "\n",
      "    accuracy                          0.903      1960\n",
      "   macro avg      0.908     0.903     0.903      1960\n",
      "weighted avg      0.908     0.903     0.903      1960\n",
      "\n",
      "Classification report when threshold is 0.6000000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.865     0.957     0.909       987\n",
      "         1.0      0.952     0.848     0.897       973\n",
      "\n",
      "    accuracy                          0.903      1960\n",
      "   macro avg      0.908     0.903     0.903      1960\n",
      "weighted avg      0.908     0.903     0.903      1960\n",
      "\n",
      "Classification report when threshold is 0.6075000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.864     0.957     0.908       987\n",
      "         1.0      0.952     0.847     0.896       973\n",
      "\n",
      "    accuracy                          0.903      1960\n",
      "   macro avg      0.908     0.902     0.902      1960\n",
      "weighted avg      0.907     0.903     0.902      1960\n",
      "\n",
      "Classification report when threshold is 0.6150000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.864     0.957     0.908       987\n",
      "         1.0      0.952     0.847     0.896       973\n",
      "\n",
      "    accuracy                          0.903      1960\n",
      "   macro avg      0.908     0.902     0.902      1960\n",
      "weighted avg      0.907     0.903     0.902      1960\n",
      "\n",
      "Classification report when threshold is 0.6225000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.863     0.957     0.908       987\n",
      "         1.0      0.951     0.846     0.896       973\n",
      "\n",
      "    accuracy                          0.902      1960\n",
      "   macro avg      0.907     0.902     0.902      1960\n",
      "weighted avg      0.907     0.902     0.902      1960\n",
      "\n",
      "Classification report when threshold is 0.6300000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.860     0.957     0.906       987\n",
      "         1.0      0.951     0.842     0.893       973\n",
      "\n",
      "    accuracy                          0.900      1960\n",
      "   macro avg      0.906     0.900     0.900      1960\n",
      "weighted avg      0.905     0.900     0.900      1960\n",
      "\n",
      "Classification report when threshold is 0.6375000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.860     0.957     0.906       987\n",
      "         1.0      0.951     0.842     0.893       973\n",
      "\n",
      "    accuracy                          0.900      1960\n",
      "   macro avg      0.906     0.900     0.900      1960\n",
      "weighted avg      0.905     0.900     0.900      1960\n",
      "\n",
      "Classification report when threshold is 0.6450000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.860     0.957     0.906       987\n",
      "         1.0      0.951     0.842     0.893       973\n",
      "\n",
      "    accuracy                          0.900      1960\n",
      "   macro avg      0.906     0.900     0.900      1960\n",
      "weighted avg      0.905     0.900     0.900      1960\n",
      "\n",
      "Classification report when threshold is 0.6525000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.860     0.958     0.907       987\n",
      "         1.0      0.952     0.842     0.894       973\n",
      "\n",
      "    accuracy                          0.901      1960\n",
      "   macro avg      0.906     0.900     0.900      1960\n",
      "weighted avg      0.906     0.901     0.900      1960\n",
      "\n",
      "Classification report when threshold is 0.6600000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.860     0.959     0.907       987\n",
      "         1.0      0.953     0.842     0.894       973\n",
      "\n",
      "    accuracy                          0.901      1960\n",
      "   macro avg      0.907     0.901     0.901      1960\n",
      "weighted avg      0.906     0.901     0.901      1960\n",
      "\n",
      "Classification report when threshold is 0.6675000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.860     0.961     0.908       987\n",
      "         1.0      0.956     0.841     0.894       973\n",
      "\n",
      "    accuracy                          0.902      1960\n",
      "   macro avg      0.908     0.901     0.901      1960\n",
      "weighted avg      0.907     0.902     0.901      1960\n",
      "\n",
      "Classification report when threshold is 0.6750000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.857     0.963     0.907       987\n",
      "         1.0      0.957     0.838     0.893       973\n",
      "\n",
      "    accuracy                          0.901      1960\n",
      "   macro avg      0.907     0.900     0.900      1960\n",
      "weighted avg      0.907     0.901     0.900      1960\n",
      "\n",
      "Classification report when threshold is 0.6825000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.857     0.963     0.906       987\n",
      "         1.0      0.957     0.837     0.893       973\n",
      "\n",
      "    accuracy                          0.900      1960\n",
      "   macro avg      0.907     0.900     0.900      1960\n",
      "weighted avg      0.906     0.900     0.900      1960\n",
      "\n",
      "Classification report when threshold is 0.6900000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.856     0.963     0.906       987\n",
      "         1.0      0.956     0.836     0.892       973\n",
      "\n",
      "    accuracy                          0.899      1960\n",
      "   macro avg      0.906     0.899     0.899      1960\n",
      "weighted avg      0.906     0.899     0.899      1960\n",
      "\n",
      "Classification report when threshold is 0.6975000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.855     0.965     0.906       987\n",
      "         1.0      0.959     0.834     0.892       973\n",
      "\n",
      "    accuracy                          0.899      1960\n",
      "   macro avg      0.907     0.899     0.899      1960\n",
      "weighted avg      0.906     0.899     0.899      1960\n",
      "\n",
      "Classification report when threshold is 0.7050000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.852     0.966     0.905       987\n",
      "         1.0      0.960     0.829     0.890       973\n",
      "\n",
      "    accuracy                          0.898      1960\n",
      "   macro avg      0.906     0.897     0.897      1960\n",
      "weighted avg      0.905     0.898     0.897      1960\n",
      "\n",
      "Classification report when threshold is 0.7125000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.852     0.966     0.905       987\n",
      "         1.0      0.960     0.829     0.890       973\n",
      "\n",
      "    accuracy                          0.898      1960\n",
      "   macro avg      0.906     0.897     0.897      1960\n",
      "weighted avg      0.905     0.898     0.897      1960\n",
      "\n",
      "Classification report when threshold is 0.7200000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.851     0.967     0.905       987\n",
      "         1.0      0.961     0.828     0.890       973\n",
      "\n",
      "    accuracy                          0.898      1960\n",
      "   macro avg      0.906     0.897     0.897      1960\n",
      "weighted avg      0.905     0.898     0.897      1960\n",
      "\n",
      "Classification report when threshold is 0.7275000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.851     0.967     0.905       987\n",
      "         1.0      0.961     0.828     0.890       973\n",
      "\n",
      "    accuracy                          0.898      1960\n",
      "   macro avg      0.906     0.897     0.897      1960\n",
      "weighted avg      0.905     0.898     0.897      1960\n",
      "\n",
      "Classification report when threshold is 0.7350000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.850     0.967     0.905       987\n",
      "         1.0      0.961     0.827     0.889       973\n",
      "\n",
      "    accuracy                          0.897      1960\n",
      "   macro avg      0.905     0.897     0.897      1960\n",
      "weighted avg      0.905     0.897     0.897      1960\n",
      "\n",
      "Classification report when threshold is 0.7425000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.850     0.967     0.905       987\n",
      "         1.0      0.961     0.827     0.889       973\n",
      "\n",
      "    accuracy                          0.897      1960\n",
      "   macro avg      0.905     0.897     0.897      1960\n",
      "weighted avg      0.905     0.897     0.897      1960\n",
      "\n",
      "Classification report when threshold is 0.7500000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.849     0.967     0.904       987\n",
      "         1.0      0.961     0.825     0.888       973\n",
      "\n",
      "    accuracy                          0.896      1960\n",
      "   macro avg      0.905     0.896     0.896      1960\n",
      "weighted avg      0.904     0.896     0.896      1960\n",
      "\n",
      "Classification report when threshold is 0.7575000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.849     0.968     0.904       987\n",
      "         1.0      0.962     0.825     0.888       973\n",
      "\n",
      "    accuracy                          0.897      1960\n",
      "   macro avg      0.905     0.896     0.896      1960\n",
      "weighted avg      0.905     0.897     0.896      1960\n",
      "\n",
      "Classification report when threshold is 0.7650000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.846     0.969     0.903       987\n",
      "         1.0      0.963     0.821     0.886       973\n",
      "\n",
      "    accuracy                          0.895      1960\n",
      "   macro avg      0.904     0.895     0.895      1960\n",
      "weighted avg      0.904     0.895     0.895      1960\n",
      "\n",
      "Classification report when threshold is 0.7725000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.842     0.969     0.901       987\n",
      "         1.0      0.962     0.815     0.883       973\n",
      "\n",
      "    accuracy                          0.892      1960\n",
      "   macro avg      0.902     0.892     0.892      1960\n",
      "weighted avg      0.902     0.892     0.892      1960\n",
      "\n",
      "Classification report when threshold is 0.7800000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.840     0.969     0.900       987\n",
      "         1.0      0.962     0.813     0.881       973\n",
      "\n",
      "    accuracy                          0.891      1960\n",
      "   macro avg      0.901     0.891     0.891      1960\n",
      "weighted avg      0.901     0.891     0.891      1960\n",
      "\n",
      "Classification report when threshold is 0.7875000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.839     0.969     0.899       987\n",
      "         1.0      0.962     0.811     0.880       973\n",
      "\n",
      "    accuracy                          0.890      1960\n",
      "   macro avg      0.900     0.890     0.890      1960\n",
      "weighted avg      0.900     0.890     0.890      1960\n",
      "\n",
      "Classification report when threshold is 0.7950000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.838     0.970     0.899       987\n",
      "         1.0      0.963     0.810     0.880       973\n",
      "\n",
      "    accuracy                          0.890      1960\n",
      "   macro avg      0.901     0.890     0.889      1960\n",
      "weighted avg      0.900     0.890     0.890      1960\n",
      "\n",
      "Classification report when threshold is 0.8025000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.836     0.970     0.898       987\n",
      "         1.0      0.963     0.807     0.878       973\n",
      "\n",
      "    accuracy                          0.889      1960\n",
      "   macro avg      0.899     0.888     0.888      1960\n",
      "weighted avg      0.899     0.889     0.888      1960\n",
      "\n",
      "Classification report when threshold is 0.8100000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.834     0.971     0.897       987\n",
      "         1.0      0.964     0.804     0.877       973\n",
      "\n",
      "    accuracy                          0.888      1960\n",
      "   macro avg      0.899     0.887     0.887      1960\n",
      "weighted avg      0.899     0.888     0.887      1960\n",
      "\n",
      "Classification report when threshold is 0.8175000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.831     0.971     0.895       987\n",
      "         1.0      0.964     0.800     0.874       973\n",
      "\n",
      "    accuracy                          0.886      1960\n",
      "   macro avg      0.897     0.885     0.885      1960\n",
      "weighted avg      0.897     0.886     0.885      1960\n",
      "\n",
      "Classification report when threshold is 0.8250000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.831     0.972     0.896       987\n",
      "         1.0      0.965     0.800     0.875       973\n",
      "\n",
      "    accuracy                          0.886      1960\n",
      "   macro avg      0.898     0.886     0.885      1960\n",
      "weighted avg      0.898     0.886     0.885      1960\n",
      "\n",
      "Classification report when threshold is 0.8325000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.830     0.972     0.895       987\n",
      "         1.0      0.965     0.798     0.873       973\n",
      "\n",
      "    accuracy                          0.885      1960\n",
      "   macro avg      0.897     0.885     0.884      1960\n",
      "weighted avg      0.897     0.885     0.884      1960\n",
      "\n",
      "Classification report when threshold is 0.8400000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.828     0.974     0.895       987\n",
      "         1.0      0.967     0.794     0.872       973\n",
      "\n",
      "    accuracy                          0.885      1960\n",
      "   macro avg      0.898     0.884     0.884      1960\n",
      "weighted avg      0.897     0.885     0.884      1960\n",
      "\n",
      "Classification report when threshold is 0.8475000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.824     0.976     0.893       987\n",
      "         1.0      0.970     0.788     0.870       973\n",
      "\n",
      "    accuracy                          0.883      1960\n",
      "   macro avg      0.897     0.882     0.881      1960\n",
      "weighted avg      0.896     0.883     0.882      1960\n",
      "\n",
      "Classification report when threshold is 0.8550000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.822     0.977     0.893       987\n",
      "         1.0      0.971     0.785     0.868       973\n",
      "\n",
      "    accuracy                          0.882      1960\n",
      "   macro avg      0.896     0.881     0.880      1960\n",
      "weighted avg      0.896     0.882     0.880      1960\n",
      "\n",
      "Classification report when threshold is 0.8625000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.819     0.978     0.891       987\n",
      "         1.0      0.972     0.781     0.866       973\n",
      "\n",
      "    accuracy                          0.880      1960\n",
      "   macro avg      0.896     0.879     0.879      1960\n",
      "weighted avg      0.895     0.880     0.879      1960\n",
      "\n",
      "Classification report when threshold is 0.8700000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.818     0.978     0.891       987\n",
      "         1.0      0.972     0.780     0.865       973\n",
      "\n",
      "    accuracy                          0.880      1960\n",
      "   macro avg      0.895     0.879     0.878      1960\n",
      "weighted avg      0.895     0.880     0.878      1960\n",
      "\n",
      "Classification report when threshold is 0.8775000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.817     0.978     0.890       987\n",
      "         1.0      0.972     0.778     0.864       973\n",
      "\n",
      "    accuracy                          0.879      1960\n",
      "   macro avg      0.894     0.878     0.877      1960\n",
      "weighted avg      0.894     0.879     0.877      1960\n",
      "\n",
      "Classification report when threshold is 0.8850000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.814     0.978     0.889       987\n",
      "         1.0      0.972     0.774     0.862       973\n",
      "\n",
      "    accuracy                          0.877      1960\n",
      "   macro avg      0.893     0.876     0.875      1960\n",
      "weighted avg      0.892     0.877     0.875      1960\n",
      "\n",
      "Classification report when threshold is 0.8925000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.812     0.978     0.887       987\n",
      "         1.0      0.972     0.771     0.860       973\n",
      "\n",
      "    accuracy                          0.875      1960\n",
      "   macro avg      0.892     0.874     0.873      1960\n",
      "weighted avg      0.891     0.875     0.874      1960\n",
      "\n",
      "Classification report when threshold is 0.9000000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.808     0.978     0.885       987\n",
      "         1.0      0.971     0.765     0.856       973\n",
      "\n",
      "    accuracy                          0.872      1960\n",
      "   macro avg      0.890     0.871     0.870      1960\n",
      "weighted avg      0.889     0.872     0.870      1960\n",
      "\n",
      "Classification report when threshold is 0.9075000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.807     0.978     0.884       987\n",
      "         1.0      0.971     0.763     0.854       973\n",
      "\n",
      "    accuracy                          0.871      1960\n",
      "   macro avg      0.889     0.870     0.869      1960\n",
      "weighted avg      0.888     0.871     0.869      1960\n",
      "\n",
      "Classification report when threshold is 0.9150000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.803     0.979     0.882       987\n",
      "         1.0      0.972     0.756     0.851       973\n",
      "\n",
      "    accuracy                          0.868      1960\n",
      "   macro avg      0.888     0.868     0.867      1960\n",
      "weighted avg      0.887     0.868     0.867      1960\n",
      "\n",
      "Classification report when threshold is 0.9225000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.801     0.981     0.882       987\n",
      "         1.0      0.975     0.753     0.850       973\n",
      "\n",
      "    accuracy                          0.868      1960\n",
      "   macro avg      0.888     0.867     0.866      1960\n",
      "weighted avg      0.887     0.868     0.866      1960\n",
      "\n",
      "Classification report when threshold is 0.9300000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.800     0.982     0.881       987\n",
      "         1.0      0.976     0.750     0.848       973\n",
      "\n",
      "    accuracy                          0.867      1960\n",
      "   macro avg      0.888     0.866     0.865      1960\n",
      "weighted avg      0.887     0.867     0.865      1960\n",
      "\n",
      "Classification report when threshold is 0.9375000000000007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.795     0.982     0.879       987\n",
      "         1.0      0.976     0.743     0.844       973\n",
      "\n",
      "    accuracy                          0.863      1960\n",
      "   macro avg      0.885     0.862     0.861      1960\n",
      "weighted avg      0.885     0.863     0.861      1960\n",
      "\n",
      "Classification report when threshold is 0.9450000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.787     0.982     0.874       987\n",
      "         1.0      0.975     0.731     0.835       973\n",
      "\n",
      "    accuracy                          0.857      1960\n",
      "   macro avg      0.881     0.856     0.855      1960\n",
      "weighted avg      0.881     0.857     0.855      1960\n",
      "\n",
      "Classification report when threshold is 0.9525000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.781     0.985     0.871       987\n",
      "         1.0      0.979     0.719     0.829       973\n",
      "\n",
      "    accuracy                          0.853      1960\n",
      "   macro avg      0.880     0.852     0.850      1960\n",
      "weighted avg      0.879     0.853     0.850      1960\n",
      "\n",
      "Classification report when threshold is 0.9600000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.773     0.986     0.866       987\n",
      "         1.0      0.980     0.706     0.821       973\n",
      "\n",
      "    accuracy                          0.847      1960\n",
      "   macro avg      0.876     0.846     0.844      1960\n",
      "weighted avg      0.876     0.847     0.844      1960\n",
      "\n",
      "Classification report when threshold is 0.9675000000000007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.765     0.988     0.862       987\n",
      "         1.0      0.983     0.693     0.813       973\n",
      "\n",
      "    accuracy                          0.841      1960\n",
      "   macro avg      0.874     0.840     0.837      1960\n",
      "weighted avg      0.873     0.841     0.838      1960\n",
      "\n",
      "Classification report when threshold is 0.9750000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.752     0.989     0.854       987\n",
      "         1.0      0.983     0.669     0.796       973\n",
      "\n",
      "    accuracy                          0.830      1960\n",
      "   macro avg      0.868     0.829     0.825      1960\n",
      "weighted avg      0.867     0.830     0.826      1960\n",
      "\n",
      "Classification report when threshold is 0.9825000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.741     0.991     0.848       987\n",
      "         1.0      0.986     0.650     0.783       973\n",
      "\n",
      "    accuracy                          0.821      1960\n",
      "   macro avg      0.864     0.820     0.816      1960\n",
      "weighted avg      0.863     0.821     0.816      1960\n",
      "\n",
      "Classification report when threshold is 0.9900000000000007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.715     0.992     0.831       987\n",
      "         1.0      0.986     0.599     0.746       973\n",
      "\n",
      "    accuracy                          0.797      1960\n",
      "   macro avg      0.851     0.796     0.788      1960\n",
      "weighted avg      0.850     0.797     0.789      1960\n",
      "\n",
      "Classification report when threshold is 0.9975000000000007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.672     0.998     0.803       987\n",
      "         1.0      0.996     0.506     0.671       973\n",
      "\n",
      "    accuracy                          0.754      1960\n",
      "   macro avg      0.834     0.752     0.737      1960\n",
      "weighted avg      0.833     0.754     0.737      1960\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.49642857, 0.49668198, 0.49693565, ..., 1.        , 1.        ,\n",
       "        1.        ]),\n",
       " array([1.        , 1.        , 1.        , ..., 0.05344296, 0.05035971,\n",
       "        0.        ]),\n",
       " array([2.35642542e-29, 3.52636199e-28, 1.98752276e-27, ...,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "print(\"Test: Victor set\")\n",
    "# drop_cols = ['group','source','set','inappropriate_prob','outlet_photo_url']\n",
    "y_true = tpot_df.query('group==\"test\"')['inappropriate_label']\n",
    "y_score = tpot_df.query('group==\"test\"')['inappropriate_prob']\n",
    "\n",
    "print(f'the auc score is {roc_auc_score(y_true,y_score)}')\n",
    "\n",
    "for thres in np.arange(0.3,1,0.0075):\n",
    "       print(f\"Classification report when threshold is {thres}\")\n",
    "       print(classification_report(y_true,y_score > thres, digits = 3))\n",
    "\n",
    "PrecisionRecallDisplay.from_predictions(y_true, y_score)\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, y_score)\n",
    "\n",
    "precision, recall, thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('torch-scene')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4cecc1edad2a69be17f78d8ff657e79a52ecac530560caa02874b10846fd4e2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
