{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this notebook uses the model from Iter 6 (tpot_221116 514pm Tree More Regularizer) and evaluate it on new labels (called Iter7labels.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'tpot_221116 514pm Tree+TrainedIter1Data+EvalIter7Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get new labels\n",
    "datalabels_iter7 = pd.read_csv('/Users/travistang/Documents/TorchScene/data/labels/INCA Outlet Image Dataset - oct2022+victor iter7label.csv',index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Victor_img_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>entity_id</th>\n",
       "      <th>saudagar_id</th>\n",
       "      <th>last_action</th>\n",
       "      <th>last_rule</th>\n",
       "      <th>last_sanction_datetime</th>\n",
       "      <th>outlet_photo_url</th>\n",
       "      <th>bank_acc_name</th>\n",
       "      <th>bank_acc_no</th>\n",
       "      <th>cnt_diff_entity_shared_bank_acc</th>\n",
       "      <th>...</th>\n",
       "      <th>restaurant_cart_inappropriateness_label</th>\n",
       "      <th>random</th>\n",
       "      <th>set</th>\n",
       "      <th>restaurant_store_cart_false_positive</th>\n",
       "      <th>restaurant_store_cart_false_negative</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction_score</th>\n",
       "      <th>victor_label_inappropriate_flag</th>\n",
       "      <th>group</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data</td>\n",
       "      <td>0012s00000NXGa6AAH</td>\n",
       "      <td>G285231232</td>\n",
       "      <td>SuspendMerchantPayout</td>\n",
       "      <td>IBT-M52-009-10A</td>\n",
       "      <td>2022-07-12 9:33:43</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "      <td>MOHAMAD RIDWAN</td>\n",
       "      <td>8.330079e+09</td>\n",
       "      <td>302.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.904060</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>1.0</td>\n",
       "      <td>test</td>\n",
       "      <td>burial_chamber 69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260</th>\n",
       "      <td>good_photos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G805388509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.575984</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>test</td>\n",
       "      <td>kindergarden_classroom 202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>good_photos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G024140195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.575580</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>test</td>\n",
       "      <td>bar 39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>good_photos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G268180486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.688902</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999392</td>\n",
       "      <td>1.0</td>\n",
       "      <td>test</td>\n",
       "      <td>outdoor 256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>good_photos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G290852858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.916971</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>test</td>\n",
       "      <td>ticket_booth 332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2414</th>\n",
       "      <td>good_photos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G318439890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.333878</td>\n",
       "      <td>val</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>val_train</td>\n",
       "      <td>ticket_booth 332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>data</td>\n",
       "      <td>0012s00000L6Dq9AAF</td>\n",
       "      <td>G559142822</td>\n",
       "      <td>SuspendMerchantGoResto</td>\n",
       "      <td>IBT-M52-015A</td>\n",
       "      <td>2022-08-25 10:45:04</td>\n",
       "      <td>https://api.midtrans.com/v1/onboardings/data/S...</td>\n",
       "      <td>CHANTIKA ALWA PUTRI HEDI</td>\n",
       "      <td>2.316349e+08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.269292</td>\n",
       "      <td>val</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.759632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>val_train</td>\n",
       "      <td>living_room 215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2416</th>\n",
       "      <td>good_photos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G854199120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.260184</td>\n",
       "      <td>val</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>1.0</td>\n",
       "      <td>val_train</td>\n",
       "      <td>roof_garden 290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417</th>\n",
       "      <td>good_photos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G028282079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.118239</td>\n",
       "      <td>val</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>val_train</td>\n",
       "      <td>loading_dock 216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4126</th>\n",
       "      <td>good_photos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G546012445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.052907</td>\n",
       "      <td>val</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>val_train</td>\n",
       "      <td>fabric_store 137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3980 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           source           entity_id saudagar_id             last_action  \\\n",
       "0            data  0012s00000NXGa6AAH  G285231232   SuspendMerchantPayout   \n",
       "2260  good_photos                 NaN  G805388509                     NaN   \n",
       "2261  good_photos                 NaN  G024140195                     NaN   \n",
       "2262  good_photos                 NaN  G268180486                     NaN   \n",
       "2268  good_photos                 NaN  G290852858                     NaN   \n",
       "...           ...                 ...         ...                     ...   \n",
       "2414  good_photos                 NaN  G318439890                     NaN   \n",
       "836          data  0012s00000L6Dq9AAF  G559142822  SuspendMerchantGoResto   \n",
       "2416  good_photos                 NaN  G854199120                     NaN   \n",
       "2417  good_photos                 NaN  G028282079                     NaN   \n",
       "4126  good_photos                 NaN  G546012445                     NaN   \n",
       "\n",
       "            last_rule last_sanction_datetime  \\\n",
       "0     IBT-M52-009-10A     2022-07-12 9:33:43   \n",
       "2260              NaN                    NaN   \n",
       "2261              NaN                    NaN   \n",
       "2262              NaN                    NaN   \n",
       "2268              NaN                    NaN   \n",
       "...               ...                    ...   \n",
       "2414              NaN                    NaN   \n",
       "836      IBT-M52-015A    2022-08-25 10:45:04   \n",
       "2416              NaN                    NaN   \n",
       "2417              NaN                    NaN   \n",
       "4126              NaN                    NaN   \n",
       "\n",
       "                                       outlet_photo_url  \\\n",
       "0     https://api.gobiz.co.id/v1/onboardings/data/SF...   \n",
       "2260  https://api.gobiz.co.id/v1/onboardings/data/SF...   \n",
       "2261  https://api.gobiz.co.id/v1/onboardings/data/SF...   \n",
       "2262  https://api.gobiz.co.id/v1/onboardings/data/SF...   \n",
       "2268  https://api.gobiz.co.id/v1/onboardings/data/SF...   \n",
       "...                                                 ...   \n",
       "2414  https://api.gobiz.co.id/v1/onboardings/data/SF...   \n",
       "836   https://api.midtrans.com/v1/onboardings/data/S...   \n",
       "2416  https://api.gobiz.co.id/v1/onboardings/data/SF...   \n",
       "2417  https://api.gobiz.co.id/v1/onboardings/data/SF...   \n",
       "4126  https://api.gobiz.co.id/v1/onboardings/data/SF...   \n",
       "\n",
       "                 bank_acc_name   bank_acc_no  cnt_diff_entity_shared_bank_acc  \\\n",
       "0               MOHAMAD RIDWAN  8.330079e+09                            302.0   \n",
       "2260                       NaN           NaN                              NaN   \n",
       "2261                       NaN           NaN                              NaN   \n",
       "2262                       NaN           NaN                              NaN   \n",
       "2268                       NaN           NaN                              NaN   \n",
       "...                        ...           ...                              ...   \n",
       "2414                       NaN           NaN                              NaN   \n",
       "836   CHANTIKA ALWA PUTRI HEDI  2.316349e+08                              4.0   \n",
       "2416                       NaN           NaN                              NaN   \n",
       "2417                       NaN           NaN                              NaN   \n",
       "4126                       NaN           NaN                              NaN   \n",
       "\n",
       "      ... restaurant_cart_inappropriateness_label    random   set  \\\n",
       "0     ...                                    True  0.904060  test   \n",
       "2260  ...                                   False  0.575984  test   \n",
       "2261  ...                                   False  0.575580  test   \n",
       "2262  ...                                   False  0.688902  test   \n",
       "2268  ...                                   False  0.916971  test   \n",
       "...   ...                                     ...       ...   ...   \n",
       "2414  ...                                   False  0.333878   val   \n",
       "836   ...                                   False  0.269292   val   \n",
       "2416  ...                                   False  0.260184   val   \n",
       "2417  ...                                   False  0.118239   val   \n",
       "4126  ...                                   False  0.052907   val   \n",
       "\n",
       "      restaurant_store_cart_false_positive  \\\n",
       "0                                      0.0   \n",
       "2260                                   0.0   \n",
       "2261                                   0.0   \n",
       "2262                                   0.0   \n",
       "2268                                   0.0   \n",
       "...                                    ...   \n",
       "2414                                   0.0   \n",
       "836                                    NaN   \n",
       "2416                                   0.0   \n",
       "2417                                   0.0   \n",
       "4126                                   0.0   \n",
       "\n",
       "     restaurant_store_cart_false_negative label prediction_score  \\\n",
       "0                                     0.0   NaN         0.000354   \n",
       "2260                                  1.0   NaN         0.999973   \n",
       "2261                                  1.0   NaN         0.996800   \n",
       "2262                                  1.0   NaN         0.999392   \n",
       "2268                                  0.0   NaN         0.999991   \n",
       "...                                   ...   ...              ...   \n",
       "2414                                  0.0   NaN         0.999969   \n",
       "836                                   NaN   NaN         0.759632   \n",
       "2416                                  1.0   NaN         0.992157   \n",
       "2417                                  1.0   NaN         0.999997   \n",
       "4126                                  0.0   NaN         0.999925   \n",
       "\n",
       "     victor_label_inappropriate_flag      group                        pred  \n",
       "0                                1.0       test           burial_chamber 69  \n",
       "2260                             0.0       test  kindergarden_classroom 202  \n",
       "2261                             0.0       test                      bar 39  \n",
       "2262                             1.0       test                 outdoor 256  \n",
       "2268                             0.0       test            ticket_booth 332  \n",
       "...                              ...        ...                         ...  \n",
       "2414                             0.0  val_train            ticket_booth 332  \n",
       "836                              1.0  val_train             living_room 215  \n",
       "2416                             1.0  val_train             roof_garden 290  \n",
       "2417                             0.0  val_train            loading_dock 216  \n",
       "4126                             0.0  val_train            fabric_store 137  \n",
       "\n",
       "[3980 rows x 38 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "victor_img_df = pd.read_csv('/Users/travistang/Documents/TorchScene/data/csv/fake_merchant_tagging_combined_set_result.csv',index_col = [0])\n",
    "victor_img_df = victor_img_df.query('outlet_photo_tagging!=\"Empty\"') # Removing empty images\n",
    "victor_img_df['restaurant_cart_inappropriateness_label'] = victor_img_df['prediction_score'] < 0.6\n",
    "\n",
    "# Replace Iter 1's labels with Iter 7's labels\n",
    "# victor_img_df['victor_label_inappropriate_flag'] = victor_img_df.apply(lambda row: 1 if row['outlet_photo_tagging'] == '1' else 0, axis=1) \n",
    "victor_img_df = victor_img_df.merge(datalabels_iter7['inappropriate_label_iter7'], how = 'left', left_on = 'saudagar_id', right_index=True)\n",
    "victor_img_df = victor_img_df.drop(columns=['victor_label_inappropriate_flag'])\n",
    "victor_img_df = victor_img_df.rename(columns={'inappropriate_label_iter7':'victor_label_inappropriate_flag'})\n",
    "# Note that outlet_photo_tagging == 1 are those that are tagged as bad by victor because they are fake. the rest are actually good labels\n",
    "\n",
    "# get group\n",
    "victor_img_df_val_set = pd.read_csv('/Users/travistang/Documents/TorchScene/result/intermediate/victor_img_tpot_df_result tpot_221109 122pm.csv')\n",
    "victor_img_df = victor_img_df.merge(victor_img_df_val_set[['saudagar_id','group']], how ='left', on ='saudagar_id')\n",
    "victor_img_df['group'] = victor_img_df['group'].fillna(victor_img_df['set'])\n",
    "\n",
    "# if a saudagar_id is in validation and test, keep it in validation and drop it from test\n",
    "victor_img_df = victor_img_df.sort_values('set',ascending=True).drop_duplicates(subset=['source','saudagar_id'],keep='last') \n",
    "\n",
    "df_prediction_result = pd.read_csv('/Users/travistang/Documents/TorchScene/result/csv/victor_set_resnet18.csv', index_col = [0])\n",
    "victor_img_df = victor_img_df.merge(df_prediction_result['pred'], how='inner', left_on = 'saudagar_id', right_index=True)\n",
    "\n",
    "victor_img_df = victor_img_df.dropna(subset=['victor_label_inappropriate_flag'])\n",
    "\n",
    "# Get the validation set only so I don't get biased\n",
    "victor_img_val_df = victor_img_df.query('set == \"val\"')\n",
    "\n",
    "victor_img_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Oct2022_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airfield 0</th>\n",
       "      <th>airplane_cabin 1</th>\n",
       "      <th>airport_terminal 2</th>\n",
       "      <th>alcove 3</th>\n",
       "      <th>alley 4</th>\n",
       "      <th>amphitheater 5</th>\n",
       "      <th>amusement_arcade 6</th>\n",
       "      <th>amusement_park 7</th>\n",
       "      <th>outdoor 8</th>\n",
       "      <th>aquarium 9</th>\n",
       "      <th>...</th>\n",
       "      <th>wet_bar 358</th>\n",
       "      <th>wheat_field 359</th>\n",
       "      <th>wind_farm 360</th>\n",
       "      <th>windmill 361</th>\n",
       "      <th>yard 362</th>\n",
       "      <th>youth_hostel 363</th>\n",
       "      <th>zen_garden 364</th>\n",
       "      <th>outlet_id</th>\n",
       "      <th>inappropriate_label</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25414.0</th>\n",
       "      <td>2.139274e-07</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>5.341184e-03</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>9.620219e-06</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.967058e-06</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>2.443199e-06</td>\n",
       "      <td>3.614401e-06</td>\n",
       "      <td>1.677299e-06</td>\n",
       "      <td>8.493458e-05</td>\n",
       "      <td>0.004273</td>\n",
       "      <td>3.606791e-06</td>\n",
       "      <td>G000007135</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8729.0</th>\n",
       "      <td>1.175332e-06</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>1.025874e-04</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>1.486519e-04</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>1.816568e-05</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>3.128750e-06</td>\n",
       "      <td>9.179776e-06</td>\n",
       "      <td>1.101525e-05</td>\n",
       "      <td>2.041509e-03</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>4.518936e-05</td>\n",
       "      <td>G000051136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15083.0</th>\n",
       "      <td>1.970256e-06</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>1.132516e-05</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>1.095202e-04</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>3.195454e-04</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>2.209334e-06</td>\n",
       "      <td>1.783030e-05</td>\n",
       "      <td>3.196685e-05</td>\n",
       "      <td>7.799471e-04</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>2.635096e-04</td>\n",
       "      <td>G000162899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26366.0</th>\n",
       "      <td>2.726324e-06</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>1.223479e-02</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>6.293109e-06</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>2.232212e-05</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>2.561831e-06</td>\n",
       "      <td>6.468579e-06</td>\n",
       "      <td>1.141056e-05</td>\n",
       "      <td>1.837652e-05</td>\n",
       "      <td>0.006582</td>\n",
       "      <td>1.709939e-04</td>\n",
       "      <td>G000224606</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207.0</th>\n",
       "      <td>2.137902e-08</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>9.194782e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>9.634322e-07</td>\n",
       "      <td>0.008203</td>\n",
       "      <td>0.001622</td>\n",
       "      <td>1.499786e-07</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>2.604203e-08</td>\n",
       "      <td>5.356325e-08</td>\n",
       "      <td>1.718631e-07</td>\n",
       "      <td>5.244693e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>8.652056e-08</td>\n",
       "      <td>G000224896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30517.0</th>\n",
       "      <td>4.026394e-06</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>8.751875e-03</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>1.261907e-05</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>1.577824e-05</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>2.119998e-05</td>\n",
       "      <td>2.131157e-05</td>\n",
       "      <td>1.032646e-05</td>\n",
       "      <td>1.803221e-04</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>1.103344e-03</td>\n",
       "      <td>G987336045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26012.0</th>\n",
       "      <td>1.040386e-06</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>1.985723e-04</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>3.115472e-06</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>2.270017e-06</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>5.551453e-07</td>\n",
       "      <td>6.444111e-07</td>\n",
       "      <td>5.649167e-07</td>\n",
       "      <td>1.306322e-05</td>\n",
       "      <td>0.001769</td>\n",
       "      <td>5.651703e-06</td>\n",
       "      <td>G991154114</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30648.0</th>\n",
       "      <td>4.006243e-04</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>8.886862e-04</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>8.098442e-05</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>4.211369e-05</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>1.206198e-03</td>\n",
       "      <td>2.263173e-03</td>\n",
       "      <td>1.173708e-03</td>\n",
       "      <td>2.118064e-04</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>1.086916e-03</td>\n",
       "      <td>G993559621</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30681.0</th>\n",
       "      <td>1.028183e-04</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>6.808520e-03</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>7.076355e-05</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>1.150000e-04</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>2.043070e-04</td>\n",
       "      <td>6.766088e-04</td>\n",
       "      <td>2.385151e-04</td>\n",
       "      <td>4.731342e-04</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>5.668707e-04</td>\n",
       "      <td>G996745489</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30696.0</th>\n",
       "      <td>5.126690e-04</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>6.616162e-03</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>5.307864e-05</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>1.164195e-04</td>\n",
       "      <td>0.004745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>4.602717e-03</td>\n",
       "      <td>9.164810e-03</td>\n",
       "      <td>3.649984e-03</td>\n",
       "      <td>4.080345e-04</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>5.874141e-04</td>\n",
       "      <td>G997665142</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30563 rows × 368 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           airfield 0  airplane_cabin 1  airport_terminal 2      alcove 3  \\\n",
       "25414.0  2.139274e-07          0.000009            0.000022  5.341184e-03   \n",
       "8729.0   1.175332e-06          0.000005            0.000076  1.025874e-04   \n",
       "15083.0  1.970256e-06          0.000023            0.000921  1.132516e-05   \n",
       "26366.0  2.726324e-06          0.000631            0.000017  1.223479e-02   \n",
       "2207.0   2.137902e-08          0.000001            0.000067  9.194782e-07   \n",
       "...               ...               ...                 ...           ...   \n",
       "30517.0  4.026394e-06          0.000781            0.000207  8.751875e-03   \n",
       "26012.0  1.040386e-06          0.000566            0.000361  1.985723e-04   \n",
       "30648.0  4.006243e-04          0.000021            0.000067  8.886862e-04   \n",
       "30681.0  1.028183e-04          0.000041            0.000122  6.808520e-03   \n",
       "30696.0  5.126690e-04          0.000129            0.000108  6.616162e-03   \n",
       "\n",
       "          alley 4  amphitheater 5  amusement_arcade 6  amusement_park 7  \\\n",
       "25414.0  0.000297    9.620219e-06            0.000250          0.000004   \n",
       "8729.0   0.000170    1.486519e-04            0.000595          0.001543   \n",
       "15083.0  0.001191    1.095202e-04            0.000144          0.010354   \n",
       "26366.0  0.000304    6.293109e-06            0.000534          0.000039   \n",
       "2207.0   0.000004    9.634322e-07            0.008203          0.001622   \n",
       "...           ...             ...                 ...               ...   \n",
       "30517.0  0.003511    1.261907e-05            0.000161          0.000054   \n",
       "26012.0  0.001025    3.115472e-06            0.001498          0.000154   \n",
       "30648.0  0.000014    8.098442e-05            0.000014          0.000221   \n",
       "30681.0  0.000256    7.076355e-05            0.000031          0.000144   \n",
       "30696.0  0.000047    5.307864e-05            0.000034          0.000242   \n",
       "\n",
       "            outdoor 8  aquarium 9  ...  wet_bar 358  wheat_field 359  \\\n",
       "25414.0  3.967058e-06    0.000024  ...     0.001111     2.443199e-06   \n",
       "8729.0   1.816568e-05    0.000050  ...     0.000060     3.128750e-06   \n",
       "15083.0  3.195454e-04    0.000720  ...     0.000061     2.209334e-06   \n",
       "26366.0  2.232212e-05    0.000116  ...     0.000529     2.561831e-06   \n",
       "2207.0   1.499786e-07    0.000023  ...     0.000015     2.604203e-08   \n",
       "...               ...         ...  ...          ...              ...   \n",
       "30517.0  1.577824e-05    0.001119  ...     0.001056     2.119998e-05   \n",
       "26012.0  2.270017e-06    0.000104  ...     0.000053     5.551453e-07   \n",
       "30648.0  4.211369e-05    0.000972  ...     0.000155     1.206198e-03   \n",
       "30681.0  1.150000e-04    0.000743  ...     0.000211     2.043070e-04   \n",
       "30696.0  1.164195e-04    0.004745  ...     0.000433     4.602717e-03   \n",
       "\n",
       "         wind_farm 360  windmill 361      yard 362  youth_hostel 363  \\\n",
       "25414.0   3.614401e-06  1.677299e-06  8.493458e-05          0.004273   \n",
       "8729.0    9.179776e-06  1.101525e-05  2.041509e-03          0.000012   \n",
       "15083.0   1.783030e-05  3.196685e-05  7.799471e-04          0.000025   \n",
       "26366.0   6.468579e-06  1.141056e-05  1.837652e-05          0.006582   \n",
       "2207.0    5.356325e-08  1.718631e-07  5.244693e-07          0.000004   \n",
       "...                ...           ...           ...               ...   \n",
       "30517.0   2.131157e-05  1.032646e-05  1.803221e-04          0.005164   \n",
       "26012.0   6.444111e-07  5.649167e-07  1.306322e-05          0.001769   \n",
       "30648.0   2.263173e-03  1.173708e-03  2.118064e-04          0.000106   \n",
       "30681.0   6.766088e-04  2.385151e-04  4.731342e-04          0.000295   \n",
       "30696.0   9.164810e-03  3.649984e-03  4.080345e-04          0.000265   \n",
       "\n",
       "         zen_garden 364   outlet_id  inappropriate_label  group  \n",
       "25414.0    3.606791e-06  G000007135                  1.0  train  \n",
       "8729.0     4.518936e-05  G000051136                  0.0  train  \n",
       "15083.0    2.635096e-04  G000162899                  0.0  train  \n",
       "26366.0    1.709939e-04  G000224606                  1.0  train  \n",
       "2207.0     8.652056e-08  G000224896                  0.0  train  \n",
       "...                 ...         ...                  ...    ...  \n",
       "30517.0    1.103344e-03  G987336045                  1.0  train  \n",
       "26012.0    5.651703e-06  G991154114                  1.0  train  \n",
       "30648.0    1.086916e-03  G993559621                  1.0  train  \n",
       "30681.0    5.668707e-04  G996745489                  1.0  train  \n",
       "30696.0    5.874141e-04  G997665142                  1.0  train  \n",
       "\n",
       "[30563 rows x 368 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read travis' labels from oct2022 set\n",
    "oct2022_df = pd.read_csv('/Users/travistang/Documents/TorchScene/data/labels/Oct2022_TravisLabel.csv')\n",
    "\n",
    "# # Preprocess victor's label\n",
    "# victor_new_df = pd.read_csv('/Users/travistang/Documents/TorchScene/data/labels/Travis Fake_Merchant_Tagging_2022 - Copy of ML training set addition 2.csv').drop(columns = ['random','set'])\n",
    "# victor_new_df['victor_label_inappropriate_flag'] = victor_new_df.apply(lambda row: 1 if row['victor_label_inappropriate_flag'] == '1' else 0, axis=1)  # Note that outlet_photo_tagging == 1 are those that are tagged as bad by victor because they are fake. the rest are actually good labels\n",
    "\n",
    "# # Get victor's label if travis has not labelled\n",
    "# oct2022_df = oct2022_df.merge(victor_new_df, how = 'left', on = 'restaurant_photo_url')\n",
    "# oct2022_df['travis_inappropriate_label'].fillna(oct2022_df['victor_label_inappropriate_flag'], inplace=True)\n",
    "# oct2022_df['inappropriate_label'] = oct2022_df['victor_label_inappropriate_flag'].combine_first(oct2022_df['travis_inappropriate_label'])\n",
    "\n",
    "# Replace Iter 1's labels with Iter 7's labels\n",
    "# victor_img_df['victor_label_inappropriate_flag'] = victor_img_df.apply(lambda row: 1 if row['outlet_photo_tagging'] == '1' else 0, axis=1) \n",
    "oct2022_df = oct2022_df.merge(datalabels_iter7['inappropriate_label_iter7'], how = 'left', left_on = 'outlet_id', right_index=True)\n",
    "oct2022_df = oct2022_df.drop(columns=['travis_inappropriate_label'])\n",
    "oct2022_df = oct2022_df.rename(columns={'inappropriate_label_iter7':'inappropriate_label'})\n",
    "\n",
    "# Get the embedding for oct2022 set\n",
    "df_prediction_result_oct2022_gooddata = pd.read_csv('/Users/travistang/Documents/TorchScene/result/intermediate/resnet18/oct2022_gooddata_resnet18.csv', index_col = [0])\n",
    "df_prediction_result_oct2022_baddata = pd.read_csv('/Users/travistang/Documents/TorchScene/result/intermediate/resnet18/oct2022_baddata_resnet18.csv', index_col = [0])\n",
    "\n",
    "df_prediction_result_oct2022 = pd.concat([df_prediction_result_oct2022_gooddata, df_prediction_result_oct2022_baddata])\n",
    "\n",
    "df_prediction_result_oct2022 = df_prediction_result_oct2022.merge(oct2022_df[['outlet_id','inappropriate_label','group']], \n",
    "                                    how = 'left', left_index=True,right_on='outlet_id')\n",
    "\n",
    "df_prediction_result_oct2022.set_index('outlet_id')\n",
    "\n",
    "# Drop images that have not been labelled\n",
    "df_prediction_result_oct2022.dropna(inplace=True)\n",
    "\n",
    "df_prediction_result_oct2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Baseline Performance of Restaurant Stall Cart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.98      0.80       802\n",
      "         1.0       0.96      0.47      0.63       714\n",
      "\n",
      "    accuracy                           0.74      1516\n",
      "   macro avg       0.82      0.73      0.72      1516\n",
      "weighted avg       0.81      0.74      0.72      1516\n",
      "\n",
      "Validation Set performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.98      0.80       265\n",
      "         1.0       0.96      0.48      0.64       239\n",
      "\n",
      "    accuracy                           0.74       504\n",
      "   macro avg       0.82      0.73      0.72       504\n",
      "weighted avg       0.81      0.74      0.72       504\n",
      "\n",
      "Test Set performance\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.98      0.78       987\n",
      "         1.0       0.96      0.46      0.62       973\n",
      "\n",
      "    accuracy                           0.72      1960\n",
      "   macro avg       0.80      0.72      0.70      1960\n",
      "weighted avg       0.80      0.72      0.70      1960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Set performance\")\n",
    "print(classification_report(victor_img_df.query(\"group == 'val_train'\")['victor_label_inappropriate_flag'],\n",
    "                            victor_img_df.query(\"group == 'val_train'\")['restaurant_cart_inappropriateness_label']))\n",
    "\n",
    "print(\"Validation Set performance\")\n",
    "print(classification_report(victor_img_df.query(\"group == 'val_test'\")['victor_label_inappropriate_flag'],\n",
    "                            victor_img_df.query(\"group == 'val_test'\")['restaurant_cart_inappropriateness_label']))\n",
    "\n",
    "\n",
    "print(\"Test Set performance\")\n",
    "print(classification_report(victor_img_df.query(\"group == 'test'\")['victor_label_inappropriate_flag'],\n",
    "                            victor_img_df.query(\"group == 'test'\")['restaurant_cart_inappropriateness_label']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay at 0x7fe848f17700>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "PrecisionRecallDisplay.from_predictions(victor_img_df.query(\"group == 'test'\")['victor_label_inappropriate_flag'],\n",
    "                                        1- victor_img_df.query(\"group == 'test'\")['prediction_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "victor_label_inappropriate_flag                                       0.0   1.0\n",
      "pred                       restaurant_cart_inappropriateness_label             \n",
      "airplane_cabin 1           False                                      1.0   NaN\n",
      "alcove 3                   False                                      2.0   6.0\n",
      "                           True                                       1.0   5.0\n",
      "alley 4                    False                                      3.0   7.0\n",
      "amusement_arcade 6         False                                     39.0   NaN\n",
      "amusement_park 7           False                                      5.0   NaN\n",
      "aquarium 9                 True                                       NaN   8.0\n",
      "archive 14                 False                                      1.0   1.0\n",
      "                           True                                       NaN   7.0\n",
      "art_gallery 19             False                                      1.0   1.0\n",
      "art_school 20              False                                      2.0   1.0\n",
      "art_studio 21              False                                      8.0   4.0\n",
      "                           True                                       1.0   NaN\n",
      "artists_loft 22            False                                      3.0   2.0\n",
      "asia 330                   False                                      2.0   NaN\n",
      "attic 26                   False                                      2.0   4.0\n",
      "                           True                                       NaN   1.0\n",
      "auditorium 27              False                                      NaN   1.0\n",
      "                           True                                       NaN   3.0\n",
      "badlands 30                True                                       NaN   1.0\n",
      "ball_pit 34                False                                      2.0   NaN\n",
      "                           True                                       NaN   1.0\n",
      "bank_vault 37              False                                      2.0   2.0\n",
      "barn 40                    False                                      NaN   1.0\n",
      "barndoor 41                False                                      3.0  14.0\n",
      "                           True                                       2.0   5.0\n",
      "baseball 312               False                                      2.0   NaN\n",
      "basement 43                False                                      8.0  20.0\n",
      "                           True                                       NaN  31.0\n",
      "bathroom 45                False                                      1.0   2.0\n",
      "beach 48                   True                                       NaN   2.0\n",
      "beauty_salon 50            False                                      3.0   1.0\n",
      "bedchamber 51              False                                      1.0   1.0\n",
      "beer_hall 54               True                                       NaN   1.0\n",
      "berth 55                   False                                      NaN  10.0\n",
      "                           True                                       NaN   6.0\n",
      "boardwalk 57               False                                      NaN   2.0\n",
      "                           True                                       NaN   3.0\n",
      "boat_deck 58               False                                      1.0   1.0\n",
      "bookstore 60               False                                      1.0   NaN\n",
      "bowling_alley 64           False                                      1.0   NaN\n",
      "                           True                                       NaN   1.0\n",
      "bullring 68                False                                      NaN   1.0\n",
      "burial_chamber 69          True                                       NaN   9.0\n",
      "butchers_shop 72           False                                      6.0   NaN\n",
      "cafeteria 75               False                                      1.0   1.0\n",
      "campsite 76                False                                      1.0   1.0\n",
      "candy_store 80             False                                     20.0   NaN\n",
      "                           True                                       2.0   NaN\n",
      "carrousel 83               False                                      1.0   NaN\n",
      "catacomb 85                False                                      NaN   1.0\n",
      "                           True                                       1.0   9.0\n",
      "cemetery 86                False                                      1.0   NaN\n",
      "chalet 87                  False                                      NaN   4.0\n",
      "chemistry_lab 88           False                                      1.0   NaN\n",
      "childs_room 89             False                                      7.0   2.0\n",
      "classroom 92               False                                      5.0   4.0\n",
      "                           True                                       NaN   3.0\n",
      "clean_room 93              False                                      NaN   1.0\n",
      "closet 95                  False                                      NaN  13.0\n",
      "                           True                                       NaN  34.0\n",
      "clothing_store 96          False                                      1.0   2.0\n",
      "                           True                                       NaN   2.0\n",
      "cockpit 98                 False                                      NaN   1.0\n",
      "coffee_shop 99             False                                      7.0   1.0\n",
      "construction_site 103      False                                      1.0   NaN\n",
      "                           True                                       NaN   1.0\n",
      "corridor 106               False                                      NaN   4.0\n",
      "                           True                                       NaN   2.0\n",
      "courtyard 109              False                                      NaN   5.0\n",
      "crevasse 111               True                                       NaN   2.0\n",
      "crosswalk 112              False                                      1.0   NaN\n",
      "delicatessen 114           False                                      1.0   NaN\n",
      "department_store 115       False                                      1.0   NaN\n",
      "dining_hall 120            False                                      2.0   NaN\n",
      "dining_room 121            False                                      1.0   2.0\n",
      "discotheque 122            False                                      1.0   NaN\n",
      "                           True                                       1.0   NaN\n",
      "door 129                   False                                      3.0  16.0\n",
      "                           True                                       NaN  14.0\n",
      "dorm_room 124              False                                      5.0  16.0\n",
      "                           True                                       NaN   2.0\n",
      "dressing_room 126          False                                      NaN   2.0\n",
      "driveway 127               False                                      NaN   8.0\n",
      "                           True                                       NaN   6.0\n",
      "drugstore 128              False                                      2.0   NaN\n",
      "elevator_lobby 130         False                                      NaN   4.0\n",
      "elevator_shaft 131         False                                      4.0   4.0\n",
      "                           True                                       NaN  13.0\n",
      "embassy 132                False                                      1.0   NaN\n",
      "engine_room 133            False                                      2.0   1.0\n",
      "                           True                                       NaN   1.0\n",
      "excavation 136             False                                      1.0   NaN\n",
      "exterior 32                False                                      2.0   3.0\n",
      "fabric_store 137           False                                      3.0   1.0\n",
      "                           True                                       NaN   1.0\n",
      "fastfood_restaurant 139    False                                     81.0   NaN\n",
      "                           True                                       4.0   NaN\n",
      "fire_escape 143            False                                      4.0   2.0\n",
      "fire_station 144           False                                      4.0   NaN\n",
      "food_court 148             False                                      6.0   1.0\n",
      "football_field 149         False                                      1.0   NaN\n",
      "galley 155                 False                                      3.0   1.0\n",
      "gas_station 158            False                                      9.0   1.0\n",
      "grotto 167                 True                                       NaN   2.0\n",
      "home_office 176            False                                      2.0   NaN\n",
      "home_theater 177           False                                      3.0   NaN\n",
      "                           True                                       1.0   NaN\n",
      "hospital 178               False                                      1.0   NaN\n",
      "                           True                                       NaN   2.0\n",
      "hospital_room 179          False                                      NaN   3.0\n",
      "hot_spring 180             True                                       NaN   3.0\n",
      "house 183                  False                                      NaN   2.0\n",
      "ice_cream_parlor 185       False                                     26.0   1.0\n",
      "ice_floe 186               True                                       NaN   3.0\n",
      "igloo 191                  False                                      NaN   1.0\n",
      "                           True                                       NaN  17.0\n",
      "indoor 146                 False                                      5.0   NaN\n",
      "indoor 147                 False                                      1.0   2.0\n",
      "indoor 156                 False                                     21.0  21.0\n",
      "                           True                                       NaN   5.0\n",
      "indoor 160                 False                                      3.0   NaN\n",
      "indoor 165                 False                                      1.0   NaN\n",
      "                           True                                       NaN   2.0\n",
      "indoor 168                 False                                      NaN   1.0\n",
      "indoor 212                 False                                      2.0   NaN\n",
      "indoor 235                 False                                      1.0   3.0\n",
      "indoor 236                 False                                      1.0   NaN\n",
      "indoor 255                 False                                      3.0   3.0\n",
      "                           True                                       NaN   1.0\n",
      "indoor 315                 False                                      NaN   1.0\n",
      "indoor 325                 False                                      NaN   1.0\n",
      "                           True                                       NaN   2.0\n",
      "indoor 61                  False                                     44.0   NaN\n",
      "indoor 63                  False                                      NaN   6.0\n",
      "                           True                                       NaN   6.0\n",
      "indoor 71                  False                                      4.0   NaN\n",
      "industrial_area 192        False                                      1.0   NaN\n",
      "interior 33                False                                      NaN   5.0\n",
      "islet 194                  True                                       NaN   1.0\n",
      "jail_cell 196              False                                      NaN  18.0\n",
      "                           True                                       NaN   6.0\n",
      "jewelry_shop 198           False                                      1.0   NaN\n",
      "                           True                                       1.0   NaN\n",
      "junkyard 199               False                                      1.0   NaN\n",
      "kindergarden_classroom 202 False                                     13.0   NaN\n",
      "kitchen 203                False                                      2.0   5.0\n",
      "landfill 206               True                                       NaN   1.0\n",
      "laundromat 208             False                                      2.0   1.0\n",
      "living_room 215            False                                      NaN   3.0\n",
      "                           True                                       NaN   1.0\n",
      "loading_dock 216           False                                     26.0  15.0\n",
      "lobby 217                  False                                      1.0   NaN\n",
      "lock_chamber 218           False                                      1.0   NaN\n",
      "locker_room 219            False                                      4.0   6.0\n",
      "manufactured_home 221      False                                      NaN   1.0\n",
      "marsh 224                  True                                       NaN   2.0\n",
      "mausoleum 226              True                                       NaN   1.0\n",
      "medina 227                 False                                      1.0   3.0\n",
      "mezzanine 228              False                                      6.0   5.0\n",
      "motel 231                  False                                      5.0   1.0\n",
      "music_studio 238           False                                      3.0   1.0\n",
      "                           True                                       1.0   1.0\n",
      "natural 205                True                                       NaN   3.0\n",
      "natural_history_museum 239 False                                      1.0   1.0\n",
      "nursery 240                True                                       1.0   NaN\n",
      "ocean 243                  True                                       NaN   1.0\n",
      "ocean_deep 342             True                                       NaN   6.0\n",
      "office 244                 False                                      1.0   NaN\n",
      "office_building 245        True                                       NaN   2.0\n",
      "office_cubicles 246        False                                      4.0   NaN\n",
      "                           True                                       NaN   8.0\n",
      "outdoor 119                False                                     37.0   6.0\n",
      "outdoor 123                False                                      4.0  19.0\n",
      "outdoor 157                False                                      NaN   1.0\n",
      "outdoor 161                False                                     52.0   2.0\n",
      "outdoor 166                False                                      1.0   NaN\n",
      "outdoor 181                False                                      1.0   NaN\n",
      "outdoor 184                False                                      NaN   1.0\n",
      "outdoor 189                True                                       NaN   2.0\n",
      "outdoor 201                False                                      3.0  10.0\n",
      "                           True                                       NaN   1.0\n",
      "outdoor 213                False                                      NaN   1.0\n",
      "outdoor 223                False                                     12.0   NaN\n",
      "outdoor 237                False                                      1.0   NaN\n",
      "outdoor 256                False                                      3.0   1.0\n",
      "outdoor 326                False                                      NaN   1.0\n",
      "outdoor 351                False                                      1.0   NaN\n",
      "outdoor 47                 False                                      2.0   NaN\n",
      "outdoor 74                 False                                      2.0   1.0\n",
      "pantry 253                 False                                     14.0   NaN\n",
      "                           True                                       1.0   NaN\n",
      "parking_lot 257            False                                      2.0   2.0\n",
      "                           True                                       NaN   2.0\n",
      "patio 259                  False                                      8.0  18.0\n",
      "pavilion 260               False                                      1.0   NaN\n",
      "pet_shop 261               False                                     49.0   NaN\n",
      "pharmacy 262               False                                      3.0   NaN\n",
      "phone_booth 263            False                                     11.0   3.0\n",
      "picnic_area 265            False                                      NaN   1.0\n",
      "platform 320               False                                      2.0   1.0\n",
      "platform 337               False                                      1.0   NaN\n",
      "playground 268             False                                      1.0   1.0\n",
      "playroom 269               False                                     16.0   6.0\n",
      "porch 272                  False                                      5.0  34.0\n",
      "                           True                                       1.0   NaN\n",
      "public 25                  True                                       NaN   1.0\n",
      "raceway 276                True                                       NaN   1.0\n",
      "rainforest 279             True                                       NaN   1.0\n",
      "reception 280              False                                     11.0   3.0\n",
      "recreation_room 281        False                                      2.0   3.0\n",
      "repair_shop 282            False                                     11.0   8.0\n",
      "                           True                                       NaN   3.0\n",
      "restaurant 284             False                                      2.0   NaN\n",
      "restaurant_kitchen 285     False                                      1.0   NaN\n",
      "restaurant_patio 286       False                                     16.0   1.0\n",
      "rice_paddy 287             False                                      NaN   1.0\n",
      "rodeo 17                   False                                      1.0   NaN\n",
      "roof_garden 290            False                                      3.0   9.0\n",
      "ruin 292                   False                                      NaN   1.0\n",
      "sand 116                   True                                       NaN  78.0\n",
      "sandbox 294                False                                      NaN   1.0\n",
      "sauna 295                  False                                      NaN   1.0\n",
      "                           True                                       NaN   2.0\n",
      "science_museum 297         False                                      3.0   1.0\n",
      "server_room 298            False                                     12.0   7.0\n",
      "shed 299                   False                                      2.0   2.0\n",
      "shoe_shop 300              False                                      5.0   NaN\n",
      "                           True                                       NaN   1.0\n",
      "shop 31                    False                                      2.0   NaN\n",
      "shopfront 301              False                                     27.0   1.0\n",
      "shower 303                 True                                       NaN  30.0\n",
      "sky 306                    True                                       NaN  51.0\n",
      "slum 308                   False                                      8.0  11.0\n",
      "                           True                                       NaN   1.0\n",
      "snowfield 309              True                                       NaN  14.0\n",
      "stable 311                 False                                      NaN   4.0\n",
      "staircase 317              False                                      NaN   2.0\n",
      "                           True                                       NaN   2.0\n",
      "storage_room 318           False                                     19.0   3.0\n",
      "                           True                                       NaN   1.0\n",
      "supermarket 321            False                                      9.0   1.0\n",
      "                           True                                       2.0   NaN\n",
      "sushi_bar 322              False                                      8.0   1.0\n",
      "swimming_hole 324          True                                       NaN   1.0\n",
      "television_studio 329      False                                      5.0   1.0\n",
      "throne_room 331            False                                      6.0   NaN\n",
      "ticket_booth 332           False                                    167.0   8.0\n",
      "toyshop 335                False                                      6.0   NaN\n",
      "tree_house 339             False                                      2.0   6.0\n",
      "                           True                                       NaN   1.0\n",
      "trench 340                 False                                      NaN  10.0\n",
      "                           True                                       NaN   1.0\n",
      "utility_room 343           False                                      2.0   3.0\n",
      "volcano 350                True                                       NaN   1.0\n",
      "waiting_room 352           False                                      2.0   2.0\n",
      "                           True                                       NaN   1.0\n",
      "wet_bar 358                False                                      4.0   NaN\n",
      "wheat_field 359            True                                       NaN   2.0\n",
      "yard 362                   False                                      3.0   4.0\n",
      "youth_hostel 363           False                                      1.0   NaN\n",
      "                           True                                       NaN   1.0\n",
      "zen_garden 364             False                                      NaN   2.0\n",
      "                           True                                       NaN   4.0\n"
     ]
    }
   ],
   "source": [
    "# Finding categories that are highly correlated with inappropriate categories\n",
    "victor_img_val_explore_str = victor_img_val_df.pivot_table(index = ['pred','restaurant_cart_inappropriateness_label'], columns = 'victor_label_inappropriate_flag', aggfunc = len)['source']\n",
    "\n",
    "print(victor_img_val_explore_str.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TPOT to train a decision tree classifier for the 365-length vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating TPOT set for victor_img_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/travistang/opt/anaconda3/envs/torch-scene/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Creating a dataframe for tpot only\n",
    "oct2022_tpot_df = df_prediction_result_oct2022.copy()\n",
    "oct2022_tpot_df = oct2022_tpot_df.set_index('outlet_id')\n",
    "# oct2022_tpot_df = oct2022_tpot_df.rename(columns = {'travis_inappropriate_label':'inappropriate_flag'})\n",
    "\n",
    "target_col = 'inappropriate_label' \n",
    "\n",
    "# Making sure this is idempotent\n",
    "oct_2022_X_train = oct2022_tpot_df.query('group == \"train\"').drop(columns=[target_col,'group'])\n",
    "oct_2022_y_train = oct2022_tpot_df.query('group == \"train\"').drop(columns=['group'])[target_col]\n",
    "oct_2022_X_test = oct2022_tpot_df.query('group == \"val\"').drop(columns=[target_col,'group'])\n",
    "oct_2022_y_test = oct2022_tpot_df.query('group == \"val\"').drop(columns=['group'])[target_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating TPOT Set for Oct_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Creating a dataframe for tpot only\n",
    "victor_img_tpot_df = victor_img_df.merge(df_prediction_result.drop(columns=['pred']), how='left', left_on = 'saudagar_id', right_index=True)\n",
    "victor_img_tpot_df = victor_img_tpot_df.dropna(subset=['airfield 0']) \n",
    "victor_img_tpot_df = victor_img_tpot_df.set_index('saudagar_id')\n",
    "victor_img_tpot_df = victor_img_tpot_df.query('set == \"val\"')\n",
    "\n",
    "victor_img_tpot_df = victor_img_tpot_df.drop(columns = ['source', 'entity_id', 'last_action', 'last_rule',\n",
    "       'last_sanction_datetime', 'outlet_photo_url', 'bank_acc_name',\n",
    "       'bank_acc_no', 'cnt_diff_entity_shared_bank_acc',\n",
    "       'diff_entity_id_shared_bank_acc',\n",
    "       'cnt_diff_entity_outlet_shared_bank_acc',\n",
    "       'diff_entity_outlet_id_shared_bank_acc', 'gofood_id', 'cnt_all_order',\n",
    "       'sum_gmv_all_order', 'cnt_co', 'sum_gmv_co', 'cnt_maf_defect_order',\n",
    "       'sum_gmv_maf_defect_order', 'cnt_cadf', 'sum_gmv_cadf', 'percent_co',\n",
    "       'percent_good_order', 'percent_bad_order', 'photo',\n",
    "       'outlet_photo_tagging', 'flag_fake_merchant', 'prediction_score',\n",
    "       'restaurant_cart_inappropriateness_label',\n",
    "       'random','set',\n",
    "       'restaurant_store_cart_false_positive','restaurant_store_cart_false_negative','label','pred','group'])\n",
    "\n",
    "victor_img_tpot_df = victor_img_tpot_df.rename(columns = {'victor_label_inappropriate_flag': 'inappropriate_label'})\n",
    "\n",
    "target_col = 'inappropriate_label' #restaurant_store_cart_false_positive\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(victor_img_tpot_df.drop(columns=[target_col]), \n",
    "                                                    victor_img_tpot_df[target_col],\n",
    "                                                    train_size=0.75, \n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Making sure this is idempotent\n",
    "# victor_img_df_val_set = pd.read_csv('/Users/travistang/Documents/TorchScene/result/intemediate/victor_img_tpot_df_result tpot_221108 122pm.csv')\n",
    "# X_train = victor_img_df_val_set.query('group == \"val_train\"').set_index('saudagar_id').drop(columns=['victor_label_inappropriate_flag','pred','group','inappropriate_prob','outlet_photo_url','prediction_score'])\n",
    "# y_train = victor_img_df_val_set.query('group == \"val_train\"')['victor_label_inappropriate_flag']\n",
    "# X_test = victor_img_df_val_set.query('group == \"val_test\"').set_index('saudagar_id').drop(columns=['victor_label_inappropriate_flag','pred','group','inappropriate_prob','outlet_photo_url','prediction_score'])\n",
    "# y_test = victor_img_df_val_set.query('group == \"val_test\"')['victor_label_inappropriate_flag']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging all TPOT sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = pd.concat([X_train, oct_2022_X_train])\n",
    "y_train_full = pd.concat([y_train, oct_2022_y_train])\n",
    "X_test = pd.concat([X_test, oct_2022_X_test])\n",
    "y_test = pd.concat([y_test, oct_2022_y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define oversampling strategy\n",
    "sample = imblearn.over_sampling.SMOTE(random_state = 42)\n",
    "X_train, y_train = sample.fit_resample(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training for TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9637330336301547\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# tpot = ExtraTreesClassifier(bootstrap=False, \n",
    "#                             criterion='gini', \n",
    "#                             max_features=0.5,\n",
    "#                             min_samples_leaf=15, \n",
    "#                             min_samples_split=12,\n",
    "#                             n_estimators=100,\n",
    "#                             random_state = 35)\n",
    "\n",
    "# tpot.fit(X_train, y_train)\n",
    "# print(tpot.score(X_train, y_train))\n",
    "\n",
    "# Never ran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# try:\n",
    "#     tpot.export(f'../tpot/{filename}.py')\n",
    "# except:\n",
    "#     with open(f'../tpot/{filename}.pkl', 'wb') as model_file:\n",
    "#         pickle.dump(tpot, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "import pickle\n",
    "tpot = pickle.load(open('/Users/travistang/Documents/TorchScene/tpot/tpot_221116 514pm Tree More Regularizer.pkl', 'rb'))\n",
    "# result = loaded_model.score(X_test, Y_test)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the final result dataset\n",
    "df_test = victor_img_df.merge(df_prediction_result.drop(columns=['pred']), how='left', left_on = 'saudagar_id', right_index=True)\n",
    "df_test = df_test.query('set == \"test\"')\n",
    "df_test = df_test.dropna(subset=['airfield 0']) \n",
    "df_test = df_test.set_index('saudagar_id')\n",
    "df_test = df_test.drop(columns = ['source', 'entity_id', 'last_action', 'last_rule',\n",
    "       'last_sanction_datetime', 'outlet_photo_url', 'bank_acc_name',\n",
    "       'bank_acc_no', 'cnt_diff_entity_shared_bank_acc',\n",
    "       'diff_entity_id_shared_bank_acc',\n",
    "       'cnt_diff_entity_outlet_shared_bank_acc',\n",
    "       'diff_entity_outlet_id_shared_bank_acc', 'gofood_id', 'cnt_all_order',\n",
    "       'sum_gmv_all_order', 'cnt_co', 'sum_gmv_co', 'cnt_maf_defect_order',\n",
    "       'sum_gmv_maf_defect_order', 'cnt_cadf', 'sum_gmv_cadf', 'percent_co',\n",
    "       'percent_good_order', 'percent_bad_order', 'photo',\n",
    "       'outlet_photo_tagging', 'flag_fake_merchant', 'prediction_score',\n",
    "       'restaurant_cart_inappropriateness_label',\n",
    "       'random','set',\n",
    "       'restaurant_store_cart_false_positive','restaurant_store_cart_false_negative','label','pred','set','group'])\n",
    "\n",
    "tpot_df = pd.concat([oct2022_tpot_df.drop(columns=['group']),victor_img_tpot_df,df_test.rename(columns = {'victor_label_inappropriate_flag':'inappropriate_label'})])\n",
    "\n",
    "# Making predictions on inappropriateness using classifier\n",
    "tpot_df['inappropriate_prob'] = tpot.predict_proba(tpot_df.drop(columns=['inappropriate_label']))[:,1]\n",
    "\n",
    "# assigning group\n",
    "tpot_df['group'] = ''\n",
    "tpot_df.loc[tpot_df.index.isin(victor_img_df_val_set.query('group == \"val_train\"').saudagar_id),'group']='train'\n",
    "tpot_df.loc[tpot_df.index.isin(victor_img_df_val_set.query('group == \"val_test\"').saudagar_id),'group']='val'\n",
    "tpot_df.loc[tpot_df.index.isin(oct_2022_X_train.index),'group']='train'\n",
    "tpot_df.loc[tpot_df.index.isin(oct_2022_X_test.index),'group']='val'\n",
    "tpot_df.loc[tpot_df.index.isin(victor_img_df.query('set == \"test\"').saudagar_id),'group']='test'\n",
    "\n",
    "# assigning source\n",
    "tpot_df['source'] = ''\n",
    "tpot_df.loc[tpot_df.index.isin(victor_img_df.query('source==\"data\"').saudagar_id),'source']='data'\n",
    "tpot_df.loc[tpot_df.index.isin(victor_img_df.query('source==\"good_photos\"').saudagar_id),'source']='good_photos'\n",
    "tpot_df.loc[tpot_df.index.isin(df_prediction_result_oct2022_gooddata.index),'source']='oct2022_gooddata'\n",
    "tpot_df.loc[tpot_df.index.isin(df_prediction_result_oct2022_baddata.index),'source']='oct2022_baddata'\n",
    "\n",
    "# assigning set\n",
    "tpot_df['set'] = ''\n",
    "tpot_df.loc[tpot_df.index.isin(victor_img_df.query('source==\"data\"').saudagar_id),'set']='victor'\n",
    "tpot_df.loc[tpot_df.index.isin(victor_img_df.query('source==\"good_photos\"').saudagar_id),'set']='victor'\n",
    "tpot_df.loc[tpot_df.index.isin(df_prediction_result_oct2022_gooddata.index),'set']='oct2022'\n",
    "tpot_df.loc[tpot_df.index.isin(df_prediction_result_oct2022_baddata.index),'set']='oct2022'\n",
    "\n",
    "# Merging results\n",
    "tpot_df = tpot_df.drop_duplicates()\n",
    "tpot_df[['inappropriate_prob']].to_csv(f'/Users/travistang/Documents/TorchScene/result/intermediate/{filename}/tpot_df.csv')\n",
    "\n",
    "# Generate a one-off dataset that contains the URL\n",
    "tpot_df = tpot_df.merge(victor_img_df[['saudagar_id','outlet_photo_url']], how='left',left_index = True, right_on = 'saudagar_id').set_index('saudagar_id')\n",
    "tpot_df = tpot_df.merge(oct2022_df[['outlet_id','restaurant_photo_url']], how='left',left_index = True, right_on = 'outlet_id')\n",
    "tpot_df['outlet_photo_url'] = tpot_df['outlet_photo_url'].fillna(tpot_df['restaurant_photo_url'])\n",
    "tpot_df = tpot_df.drop(columns = ['restaurant_photo_url'])\n",
    "\n",
    "tpot_df = tpot_df.set_index('outlet_id', drop=True)\n",
    "\n",
    "tpot_df = tpot_df.drop_duplicates()\n",
    "tpot_df[['outlet_photo_url','group','source','set','inappropriate_label']].to_csv(f'/Users/travistang/Documents/TorchScene/data/csv/oct2022+victor.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airfield 0</th>\n",
       "      <th>airplane_cabin 1</th>\n",
       "      <th>airport_terminal 2</th>\n",
       "      <th>alcove 3</th>\n",
       "      <th>alley 4</th>\n",
       "      <th>amphitheater 5</th>\n",
       "      <th>amusement_arcade 6</th>\n",
       "      <th>amusement_park 7</th>\n",
       "      <th>outdoor 8</th>\n",
       "      <th>aquarium 9</th>\n",
       "      <th>...</th>\n",
       "      <th>windmill 361</th>\n",
       "      <th>yard 362</th>\n",
       "      <th>youth_hostel 363</th>\n",
       "      <th>zen_garden 364</th>\n",
       "      <th>inappropriate_label</th>\n",
       "      <th>inappropriate_prob</th>\n",
       "      <th>group</th>\n",
       "      <th>source</th>\n",
       "      <th>set</th>\n",
       "      <th>outlet_photo_url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outlet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>G000007135</th>\n",
       "      <td>2.139274e-07</td>\n",
       "      <td>8.877712e-06</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>5.341184e-03</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>9.620219e-06</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>3.967058e-06</td>\n",
       "      <td>2.369832e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.677299e-06</td>\n",
       "      <td>8.493458e-05</td>\n",
       "      <td>0.004273</td>\n",
       "      <td>3.606791e-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.751642</td>\n",
       "      <td>train</td>\n",
       "      <td>oct2022_gooddata</td>\n",
       "      <td>oct2022</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G000051136</th>\n",
       "      <td>1.175332e-06</td>\n",
       "      <td>5.057530e-06</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>1.025874e-04</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>1.486519e-04</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>1.816568e-05</td>\n",
       "      <td>5.027789e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.101525e-05</td>\n",
       "      <td>2.041509e-03</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>4.518936e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008282</td>\n",
       "      <td>train</td>\n",
       "      <td>oct2022_gooddata</td>\n",
       "      <td>oct2022</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G000162899</th>\n",
       "      <td>1.970256e-06</td>\n",
       "      <td>2.253714e-05</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>1.132516e-05</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>1.095202e-04</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>3.195454e-04</td>\n",
       "      <td>7.204539e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>3.196685e-05</td>\n",
       "      <td>7.799471e-04</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>2.635096e-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166387</td>\n",
       "      <td>train</td>\n",
       "      <td>oct2022_gooddata</td>\n",
       "      <td>oct2022</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G000224606</th>\n",
       "      <td>2.726324e-06</td>\n",
       "      <td>6.312387e-04</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>1.223479e-02</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>6.293109e-06</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>2.232212e-05</td>\n",
       "      <td>1.159015e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.141056e-05</td>\n",
       "      <td>1.837652e-05</td>\n",
       "      <td>0.006582</td>\n",
       "      <td>1.709939e-04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.821917</td>\n",
       "      <td>train</td>\n",
       "      <td>oct2022_gooddata</td>\n",
       "      <td>oct2022</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G000224896</th>\n",
       "      <td>2.137902e-08</td>\n",
       "      <td>1.091339e-06</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>9.194782e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>9.634322e-07</td>\n",
       "      <td>0.008203</td>\n",
       "      <td>0.001622</td>\n",
       "      <td>1.499786e-07</td>\n",
       "      <td>2.290889e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.718631e-07</td>\n",
       "      <td>5.244693e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>8.652056e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>train</td>\n",
       "      <td>oct2022_gooddata</td>\n",
       "      <td>oct2022</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G506427626</th>\n",
       "      <td>8.964552e-05</td>\n",
       "      <td>2.812791e-04</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>2.508922e-02</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>9.770808e-06</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>1.187956e-04</td>\n",
       "      <td>2.093857e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>6.131802e-04</td>\n",
       "      <td>1.581691e-04</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>4.262529e-04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.984729</td>\n",
       "      <td>test</td>\n",
       "      <td>data</td>\n",
       "      <td>victor</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G050841328</th>\n",
       "      <td>2.620510e-06</td>\n",
       "      <td>2.401831e-05</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>3.385504e-02</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>7.213193e-06</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>1.453368e-05</td>\n",
       "      <td>1.549785e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>2.462671e-06</td>\n",
       "      <td>1.477298e-03</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>1.822124e-04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.469212</td>\n",
       "      <td>test</td>\n",
       "      <td>data</td>\n",
       "      <td>victor</td>\n",
       "      <td>https://api.midtrans.com/v1/onboardings/data/S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G436006229</th>\n",
       "      <td>1.548531e-04</td>\n",
       "      <td>7.768250e-04</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>3.176613e-02</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>7.352784e-05</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>1.506499e-04</td>\n",
       "      <td>1.673141e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>4.613529e-03</td>\n",
       "      <td>1.266370e-04</td>\n",
       "      <td>0.012177</td>\n",
       "      <td>3.188663e-04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997933</td>\n",
       "      <td>test</td>\n",
       "      <td>data</td>\n",
       "      <td>victor</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G798587885</th>\n",
       "      <td>1.630283e-07</td>\n",
       "      <td>5.286926e-08</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.978975e-06</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>2.308064e-06</td>\n",
       "      <td>0.017740</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>5.921898e-07</td>\n",
       "      <td>8.824487e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>3.122195e-06</td>\n",
       "      <td>3.543960e-05</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.463043e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022328</td>\n",
       "      <td>test</td>\n",
       "      <td>data</td>\n",
       "      <td>victor</td>\n",
       "      <td>https://api.gobiz.co.id/v1/onboardings/data/SF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G493893721</th>\n",
       "      <td>2.590220e-08</td>\n",
       "      <td>1.134038e-05</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>3.797090e-04</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>1.081675e-05</td>\n",
       "      <td>0.020451</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>1.046877e-06</td>\n",
       "      <td>2.551880e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>4.048332e-07</td>\n",
       "      <td>7.720412e-06</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.277067e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>test</td>\n",
       "      <td>data</td>\n",
       "      <td>victor</td>\n",
       "      <td>https://api.midtrans.com/v1/onboardings/data/S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34489 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              airfield 0  airplane_cabin 1  airport_terminal 2      alcove 3  \\\n",
       "outlet_id                                                                      \n",
       "G000007135  2.139274e-07      8.877712e-06            0.000022  5.341184e-03   \n",
       "G000051136  1.175332e-06      5.057530e-06            0.000076  1.025874e-04   \n",
       "G000162899  1.970256e-06      2.253714e-05            0.000921  1.132516e-05   \n",
       "G000224606  2.726324e-06      6.312387e-04            0.000017  1.223479e-02   \n",
       "G000224896  2.137902e-08      1.091339e-06            0.000067  9.194782e-07   \n",
       "...                  ...               ...                 ...           ...   \n",
       "G506427626  8.964552e-05      2.812791e-04            0.000127  2.508922e-02   \n",
       "G050841328  2.620510e-06      2.401831e-05            0.000058  3.385504e-02   \n",
       "G436006229  1.548531e-04      7.768250e-04            0.000342  3.176613e-02   \n",
       "G798587885  1.630283e-07      5.286926e-08            0.000007  1.978975e-06   \n",
       "G493893721  2.590220e-08      1.134038e-05            0.000008  3.797090e-04   \n",
       "\n",
       "             alley 4  amphitheater 5  amusement_arcade 6  amusement_park 7  \\\n",
       "outlet_id                                                                    \n",
       "G000007135  0.000297    9.620219e-06            0.000250          0.000004   \n",
       "G000051136  0.000170    1.486519e-04            0.000595          0.001543   \n",
       "G000162899  0.001191    1.095202e-04            0.000144          0.010354   \n",
       "G000224606  0.000304    6.293109e-06            0.000534          0.000039   \n",
       "G000224896  0.000004    9.634322e-07            0.008203          0.001622   \n",
       "...              ...             ...                 ...               ...   \n",
       "G506427626  0.000083    9.770808e-06            0.000157          0.000075   \n",
       "G050841328  0.000183    7.213193e-06            0.001122          0.000532   \n",
       "G436006229  0.000392    7.352784e-05            0.000043          0.000275   \n",
       "G798587885  0.000013    2.308064e-06            0.017740          0.000297   \n",
       "G493893721  0.000018    1.081675e-05            0.020451          0.000191   \n",
       "\n",
       "               outdoor 8    aquarium 9  ...  windmill 361      yard 362  \\\n",
       "outlet_id                               ...                               \n",
       "G000007135  3.967058e-06  2.369832e-05  ...  1.677299e-06  8.493458e-05   \n",
       "G000051136  1.816568e-05  5.027789e-05  ...  1.101525e-05  2.041509e-03   \n",
       "G000162899  3.195454e-04  7.204539e-04  ...  3.196685e-05  7.799471e-04   \n",
       "G000224606  2.232212e-05  1.159015e-04  ...  1.141056e-05  1.837652e-05   \n",
       "G000224896  1.499786e-07  2.290889e-05  ...  1.718631e-07  5.244693e-07   \n",
       "...                  ...           ...  ...           ...           ...   \n",
       "G506427626  1.187956e-04  2.093857e-03  ...  6.131802e-04  1.581691e-04   \n",
       "G050841328  1.453368e-05  1.549785e-03  ...  2.462671e-06  1.477298e-03   \n",
       "G436006229  1.506499e-04  1.673141e-03  ...  4.613529e-03  1.266370e-04   \n",
       "G798587885  5.921898e-07  8.824487e-07  ...  3.122195e-06  3.543960e-05   \n",
       "G493893721  1.046877e-06  2.551880e-04  ...  4.048332e-07  7.720412e-06   \n",
       "\n",
       "            youth_hostel 363  zen_garden 364  inappropriate_label  \\\n",
       "outlet_id                                                           \n",
       "G000007135          0.004273    3.606791e-06                  1.0   \n",
       "G000051136          0.000012    4.518936e-05                  0.0   \n",
       "G000162899          0.000025    2.635096e-04                  0.0   \n",
       "G000224606          0.006582    1.709939e-04                  1.0   \n",
       "G000224896          0.000004    8.652056e-08                  0.0   \n",
       "...                      ...             ...                  ...   \n",
       "G506427626          0.000889    4.262529e-04                  1.0   \n",
       "G050841328          0.000228    1.822124e-04                  1.0   \n",
       "G436006229          0.012177    3.188663e-04                  1.0   \n",
       "G798587885          0.000002    3.463043e-07                  0.0   \n",
       "G493893721          0.000001    1.277067e-06                  0.0   \n",
       "\n",
       "            inappropriate_prob  group            source      set  \\\n",
       "outlet_id                                                          \n",
       "G000007135            0.751642  train  oct2022_gooddata  oct2022   \n",
       "G000051136            0.008282  train  oct2022_gooddata  oct2022   \n",
       "G000162899            0.166387  train  oct2022_gooddata  oct2022   \n",
       "G000224606            0.821917  train  oct2022_gooddata  oct2022   \n",
       "G000224896            0.000000  train  oct2022_gooddata  oct2022   \n",
       "...                        ...    ...               ...      ...   \n",
       "G506427626            0.984729   test              data   victor   \n",
       "G050841328            0.469212   test              data   victor   \n",
       "G436006229            0.997933   test              data   victor   \n",
       "G798587885            0.022328   test              data   victor   \n",
       "G493893721            0.002900   test              data   victor   \n",
       "\n",
       "                                             outlet_photo_url  \n",
       "outlet_id                                                      \n",
       "G000007135  https://api.gobiz.co.id/v1/onboardings/data/SF...  \n",
       "G000051136  https://api.gobiz.co.id/v1/onboardings/data/SF...  \n",
       "G000162899  https://api.gobiz.co.id/v1/onboardings/data/SF...  \n",
       "G000224606  https://api.gobiz.co.id/v1/onboardings/data/SF...  \n",
       "G000224896  https://api.gobiz.co.id/v1/onboardings/data/SF...  \n",
       "...                                                       ...  \n",
       "G506427626  https://api.gobiz.co.id/v1/onboardings/data/SF...  \n",
       "G050841328  https://api.midtrans.com/v1/onboardings/data/S...  \n",
       "G436006229  https://api.gobiz.co.id/v1/onboardings/data/SF...  \n",
       "G798587885  https://api.gobiz.co.id/v1/onboardings/data/SF...  \n",
       "G493893721  https://api.midtrans.com/v1/onboardings/data/S...  \n",
       "\n",
       "[34489 rows x 371 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Victor+Oct2022\n",
      "the auc score is 0.9887269587602008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.987     0.938     0.962     23104\n",
      "         1.0      0.797     0.953     0.868      5928\n",
      "\n",
      "    accuracy                          0.941     29032\n",
      "   macro avg      0.892     0.945     0.915     29032\n",
      "weighted avg      0.948     0.941     0.943     29032\n",
      "\n",
      "Training: Victor+Oct2022+SMOTE Oversampled\n",
      "the auc score is 0.9901260292116426\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.959     0.938     0.949     23134\n",
      "         1.0      0.939     0.960     0.950     23134\n",
      "\n",
      "    accuracy                          0.949     46268\n",
      "   macro avg      0.949     0.949     0.949     46268\n",
      "weighted avg      0.949     0.949     0.949     46268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print(\"Training: Victor+Oct2022\")\n",
    "y_true = tpot_df.query('group==\"train\"')['inappropriate_label']\n",
    "y_score = tpot_df.query('group==\"train\"')['inappropriate_prob']\n",
    "y_pred = y_score >= 0.5\n",
    "print(f'the auc score is {roc_auc_score(y_true,y_score)}')\n",
    "print(classification_report(y_true,y_pred, digits=3))\n",
    "\n",
    "print(\"Training: Victor+Oct2022+SMOTE Oversampled\")\n",
    "y_pred = tpot.predict(X_train)\n",
    "y_score = tpot.predict_proba(X_train)[:,1]\n",
    "print(f'the auc score is {roc_auc_score(y_train,y_score)}')\n",
    "print(classification_report(y_train,y_pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Victor+Oct2022\n",
      "the auc score is 0.9813200926596932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.982     0.923     0.951      2738\n",
      "         1.0      0.771     0.938     0.847       759\n",
      "\n",
      "    accuracy                          0.926      3497\n",
      "   macro avg      0.877     0.931     0.899      3497\n",
      "weighted avg      0.936     0.926     0.929      3497\n",
      "\n",
      "Validation: Victor set\n",
      "the auc score is 0.9815602151576641\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.949     0.927     0.938       262\n",
      "         1.0      0.922     0.945     0.933       237\n",
      "\n",
      "    accuracy                          0.936       499\n",
      "   macro avg      0.936     0.936     0.936       499\n",
      "weighted avg      0.936     0.936     0.936       499\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.4749499 , 0.48865979, 0.48966942, 0.49170124, 0.49478079,\n",
       "        0.4958159 , 0.49685535, 0.49789916, 0.5       , 0.50105708,\n",
       "        0.50211864, 0.50318471, 0.50425532, 0.50533049, 0.50749465,\n",
       "        0.50858369, 0.50967742, 0.51077586, 0.51187905, 0.51298701,\n",
       "        0.51409978, 0.51521739, 0.51633987, 0.51746725, 0.51859956,\n",
       "        0.51973684, 0.52087912, 0.52202643, 0.52317881, 0.52433628,\n",
       "        0.52549889, 0.52666667, 0.52783964, 0.52901786, 0.53020134,\n",
       "        0.53139013, 0.53258427, 0.53378378, 0.53498871, 0.5361991 ,\n",
       "        0.53741497, 0.53863636, 0.53986333, 0.54109589, 0.5423341 ,\n",
       "        0.54357798, 0.54482759, 0.54608295, 0.54734411, 0.54861111,\n",
       "        0.54988399, 0.55116279, 0.55244755, 0.55373832, 0.55503513,\n",
       "        0.55633803, 0.55764706, 0.55896226, 0.56028369, 0.56161137,\n",
       "        0.56294537, 0.56428571, 0.56563246, 0.56698565, 0.56834532,\n",
       "        0.56971154, 0.57108434, 0.57246377, 0.57384988, 0.57524272,\n",
       "        0.57664234, 0.57804878, 0.5794621 , 0.58088235, 0.58230958,\n",
       "        0.58374384, 0.58518519, 0.58663366, 0.58808933, 0.58955224,\n",
       "        0.59102244, 0.5925    , 0.59398496, 0.59547739, 0.59697733,\n",
       "        0.59848485, 0.6       , 0.60152284, 0.60305344, 0.60459184,\n",
       "        0.60613811, 0.60769231, 0.6092545 , 0.61082474, 0.6124031 ,\n",
       "        0.61398964, 0.61558442, 0.6171875 , 0.61879896, 0.62041885,\n",
       "        0.62204724, 0.62368421, 0.62532982, 0.62698413, 0.62864721,\n",
       "        0.63031915, 0.632     , 0.63368984, 0.63538874, 0.63709677,\n",
       "        0.63881402, 0.64054054, 0.64227642, 0.64402174, 0.64577657,\n",
       "        0.64754098, 0.64931507, 0.6510989 , 0.65289256, 0.65469613,\n",
       "        0.6565097 , 0.65833333, 0.66016713, 0.66201117, 0.66386555,\n",
       "        0.66573034, 0.66760563, 0.66949153, 0.6713881 , 0.67329545,\n",
       "        0.67521368, 0.67714286, 0.67908309, 0.68103448, 0.68299712,\n",
       "        0.6849711 , 0.68695652, 0.68895349, 0.6909621 , 0.69298246,\n",
       "        0.69501466, 0.69705882, 0.69911504, 0.70118343, 0.70326409,\n",
       "        0.70535714, 0.70746269, 0.70958084, 0.71171171, 0.71385542,\n",
       "        0.71601208, 0.71818182, 0.72036474, 0.72256098, 0.72477064,\n",
       "        0.72699387, 0.72923077, 0.73148148, 0.73374613, 0.73602484,\n",
       "        0.73831776, 0.740625  , 0.74294671, 0.74528302, 0.74763407,\n",
       "        0.75      , 0.75238095, 0.75477707, 0.75399361, 0.75641026,\n",
       "        0.75884244, 0.76129032, 0.76375405, 0.76623377, 0.76872964,\n",
       "        0.77124183, 0.77377049, 0.77631579, 0.77887789, 0.78145695,\n",
       "        0.78405316, 0.78666667, 0.78929766, 0.79194631, 0.79461279,\n",
       "        0.7972973 , 0.8       , 0.79931973, 0.79863481, 0.80136986,\n",
       "        0.80412371, 0.80689655, 0.80968858, 0.8125    , 0.81184669,\n",
       "        0.81468531, 0.81754386, 0.82042254, 0.82332155, 0.82624113,\n",
       "        0.82562278, 0.82857143, 0.83154122, 0.83093525, 0.83393502,\n",
       "        0.83695652, 0.83636364, 0.83941606, 0.84249084, 0.84191176,\n",
       "        0.84132841, 0.84444444, 0.84758364, 0.85074627, 0.85393258,\n",
       "        0.85714286, 0.86037736, 0.86363636, 0.86692015, 0.87022901,\n",
       "        0.87356322, 0.87692308, 0.88030888, 0.88372093, 0.88715953,\n",
       "        0.890625  , 0.89411765, 0.8976378 , 0.90118577, 0.9047619 ,\n",
       "        0.90438247, 0.908     , 0.90763052, 0.90725806, 0.91093117,\n",
       "        0.91463415, 0.91836735, 0.92213115, 0.9218107 , 0.92561983,\n",
       "        0.92946058, 0.92916667, 0.92887029, 0.92857143, 0.93248945,\n",
       "        0.93220339, 0.93617021, 0.93589744, 0.93562232, 0.93534483,\n",
       "        0.93939394, 0.94347826, 0.94759825, 0.95175439, 0.95154185,\n",
       "        0.95575221, 0.95555556, 0.95535714, 0.95515695, 0.95495495,\n",
       "        0.95475113, 0.95909091, 0.95890411, 0.9587156 , 0.95852535,\n",
       "        0.96296296, 0.9627907 , 0.96261682, 0.96244131, 0.96226415,\n",
       "        0.96208531, 0.96190476, 0.96650718, 0.97115385, 0.97101449,\n",
       "        0.97572816, 0.97560976, 0.9754902 , 0.97536946, 0.97524752,\n",
       "        0.97512438, 0.975     , 0.97487437, 0.97474747, 0.97461929,\n",
       "        0.9744898 , 0.97435897, 0.9742268 , 0.97409326, 0.97916667,\n",
       "        0.97905759, 0.97894737, 0.97883598, 0.9787234 , 0.97860963,\n",
       "        0.97849462, 0.97837838, 0.97826087, 0.97814208, 0.97802198,\n",
       "        0.97790055, 0.97777778, 0.97765363, 0.97752809, 0.97740113,\n",
       "        0.97727273, 0.97714286, 0.97701149, 0.97687861, 0.98255814,\n",
       "        0.98245614, 0.98235294, 0.98224852, 0.98214286, 0.98203593,\n",
       "        0.98192771, 0.98181818, 0.98170732, 0.98159509, 0.98148148,\n",
       "        0.98136646, 0.98125   , 0.98113208, 0.98734177, 0.98726115,\n",
       "        0.98717949, 0.98709677, 0.98701299, 0.9869281 , 0.98684211,\n",
       "        0.98675497, 0.98666667, 0.98657718, 0.98648649, 0.98639456,\n",
       "        0.98630137, 0.9862069 , 0.98611111, 0.98601399, 0.98591549,\n",
       "        0.9858156 , 0.98571429, 0.98561151, 0.98550725, 0.98540146,\n",
       "        0.98529412, 0.98518519, 0.98507463, 0.98496241, 0.98484848,\n",
       "        0.98473282, 0.98461538, 0.98449612, 0.984375  , 0.98425197,\n",
       "        0.98412698, 0.984     , 0.98387097, 0.98373984, 0.98360656,\n",
       "        0.98347107, 0.98333333, 0.98319328, 0.98305085, 0.99145299,\n",
       "        0.99137931, 0.99130435, 0.99122807, 0.99115044, 0.99107143,\n",
       "        0.99099099, 0.99090909, 0.99082569, 0.99074074, 0.99065421,\n",
       "        0.99056604, 0.99047619, 0.99038462, 0.99029126, 0.99019608,\n",
       "        0.99009901, 0.99      , 0.98989899, 0.98979592, 0.98969072,\n",
       "        0.98958333, 0.98947368, 0.9893617 , 0.98924731, 0.98913043,\n",
       "        0.98901099, 0.98888889, 0.98876404, 0.98863636, 0.98850575,\n",
       "        0.98837209, 0.98823529, 0.98809524, 0.98795181, 0.98780488,\n",
       "        0.98765432, 0.9875    , 0.98734177, 0.98717949, 0.98701299,\n",
       "        0.98684211, 0.98666667, 0.98648649, 0.98630137, 0.98611111,\n",
       "        0.98591549, 0.98571429, 0.98550725, 0.98529412, 0.98507463,\n",
       "        0.98484848, 0.98461538, 0.984375  , 0.98412698, 0.98387097,\n",
       "        0.98360656, 0.98333333, 0.98305085, 0.98275862, 0.98245614,\n",
       "        0.98214286, 0.98181818, 0.98148148, 0.98113208, 0.98076923,\n",
       "        0.98039216, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        ]),\n",
       " array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.99578059, 0.99578059,\n",
       "        0.99578059, 0.99578059, 0.99578059, 0.99578059, 0.99578059,\n",
       "        0.99578059, 0.99578059, 0.99578059, 0.99578059, 0.99578059,\n",
       "        0.99578059, 0.99578059, 0.99578059, 0.99578059, 0.99578059,\n",
       "        0.99578059, 0.99578059, 0.99156118, 0.98734177, 0.98734177,\n",
       "        0.98734177, 0.98734177, 0.98734177, 0.98734177, 0.98312236,\n",
       "        0.98312236, 0.98312236, 0.98312236, 0.98312236, 0.98312236,\n",
       "        0.97890295, 0.97890295, 0.97890295, 0.97468354, 0.97468354,\n",
       "        0.97468354, 0.97046414, 0.97046414, 0.97046414, 0.96624473,\n",
       "        0.96202532, 0.96202532, 0.96202532, 0.96202532, 0.96202532,\n",
       "        0.96202532, 0.96202532, 0.96202532, 0.96202532, 0.96202532,\n",
       "        0.96202532, 0.96202532, 0.96202532, 0.96202532, 0.96202532,\n",
       "        0.96202532, 0.96202532, 0.96202532, 0.96202532, 0.96202532,\n",
       "        0.95780591, 0.95780591, 0.9535865 , 0.94936709, 0.94936709,\n",
       "        0.94936709, 0.94936709, 0.94936709, 0.94514768, 0.94514768,\n",
       "        0.94514768, 0.94092827, 0.93670886, 0.93248945, 0.93248945,\n",
       "        0.92827004, 0.92827004, 0.92405063, 0.91983122, 0.91561181,\n",
       "        0.91561181, 0.91561181, 0.91561181, 0.91561181, 0.91139241,\n",
       "        0.91139241, 0.907173  , 0.90295359, 0.89873418, 0.89451477,\n",
       "        0.89029536, 0.89029536, 0.88607595, 0.88185654, 0.87763713,\n",
       "        0.87763713, 0.87341772, 0.86919831, 0.8649789 , 0.86075949,\n",
       "        0.85654008, 0.85232068, 0.85232068, 0.85232068, 0.84810127,\n",
       "        0.84810127, 0.84388186, 0.83966245, 0.83544304, 0.83122363,\n",
       "        0.82700422, 0.82278481, 0.8185654 , 0.81434599, 0.81012658,\n",
       "        0.80590717, 0.80168776, 0.79746835, 0.79324895, 0.79324895,\n",
       "        0.78902954, 0.78481013, 0.78059072, 0.77637131, 0.7721519 ,\n",
       "        0.76793249, 0.76371308, 0.75949367, 0.75527426, 0.75105485,\n",
       "        0.74683544, 0.74261603, 0.73839662, 0.73417722, 0.72995781,\n",
       "        0.7257384 , 0.72151899, 0.71729958, 0.71308017, 0.71308017,\n",
       "        0.70886076, 0.70464135, 0.70042194, 0.69620253, 0.69198312,\n",
       "        0.68776371, 0.6835443 , 0.67932489, 0.67510549, 0.67088608,\n",
       "        0.66666667, 0.66244726, 0.65822785, 0.65822785, 0.65400844,\n",
       "        0.64978903, 0.64556962, 0.64135021, 0.6371308 , 0.63291139,\n",
       "        0.62869198, 0.62447257, 0.62025316, 0.61603376, 0.61181435,\n",
       "        0.60759494, 0.60337553, 0.59915612, 0.59493671, 0.5907173 ,\n",
       "        0.58649789, 0.58227848, 0.57805907, 0.57383966, 0.56962025,\n",
       "        0.56540084, 0.56118143, 0.55696203, 0.55274262, 0.54852321,\n",
       "        0.5443038 , 0.54008439, 0.53586498, 0.53164557, 0.52742616,\n",
       "        0.52320675, 0.51898734, 0.51476793, 0.51054852, 0.50632911,\n",
       "        0.5021097 , 0.4978903 , 0.49367089, 0.48945148, 0.48945148,\n",
       "        0.48523207, 0.48101266, 0.47679325, 0.47257384, 0.46835443,\n",
       "        0.46413502, 0.45991561, 0.4556962 , 0.45147679, 0.44725738,\n",
       "        0.44303797, 0.43881857, 0.43459916, 0.43037975, 0.42616034,\n",
       "        0.42194093, 0.41772152, 0.41350211, 0.4092827 , 0.40506329,\n",
       "        0.40084388, 0.39662447, 0.39240506, 0.38818565, 0.38396624,\n",
       "        0.37974684, 0.37552743, 0.37130802, 0.36708861, 0.3628692 ,\n",
       "        0.35864979, 0.35443038, 0.35021097, 0.34599156, 0.34177215,\n",
       "        0.33755274, 0.33333333, 0.32911392, 0.32489451, 0.32067511,\n",
       "        0.3164557 , 0.31223629, 0.30801688, 0.30379747, 0.29957806,\n",
       "        0.29535865, 0.29113924, 0.28691983, 0.28270042, 0.27848101,\n",
       "        0.2742616 , 0.27004219, 0.26582278, 0.26160338, 0.25738397,\n",
       "        0.25316456, 0.24894515, 0.24472574, 0.24050633, 0.23628692,\n",
       "        0.23206751, 0.2278481 , 0.22362869, 0.21940928, 0.21518987,\n",
       "        0.21097046, 0.21097046, 0.20675105, 0.20253165, 0.19831224,\n",
       "        0.19409283, 0.18987342, 0.18565401, 0.1814346 , 0.17721519,\n",
       "        0.17299578, 0.16877637, 0.16455696, 0.16033755, 0.15611814,\n",
       "        0.15189873, 0.14767932, 0.14345992, 0.13924051, 0.1350211 ,\n",
       "        0.13080169, 0.12658228, 0.12236287, 0.11814346, 0.11392405,\n",
       "        0.10970464, 0.10548523, 0.10126582, 0.09704641, 0.092827  ,\n",
       "        0.08860759, 0.08438819, 0.08016878, 0.07594937, 0.07172996,\n",
       "        0.06751055, 0.06329114, 0.05907173, 0.05485232, 0.05063291,\n",
       "        0.0464135 , 0.04219409, 0.03797468, 0.03375527, 0.02953586,\n",
       "        0.02531646, 0.02109705, 0.01687764, 0.01265823, 0.00843882,\n",
       "        0.        ]),\n",
       " array([0.00000000e+00, 4.76190476e-04, 5.26315789e-04, 6.66666667e-04,\n",
       "        9.55555556e-04, 9.88235294e-04, 1.00000000e-03, 1.03703704e-03,\n",
       "        1.05978261e-03, 1.21597096e-03, 1.22222222e-03, 1.22828623e-03,\n",
       "        1.32631579e-03, 1.33333333e-03, 1.48148148e-03, 1.83831909e-03,\n",
       "        1.91666667e-03, 1.94978632e-03, 2.10526316e-03, 2.15733183e-03,\n",
       "        2.39057239e-03, 2.42647059e-03, 2.50000000e-03, 2.64423002e-03,\n",
       "        2.74906832e-03, 2.84722222e-03, 2.92840623e-03, 2.98268398e-03,\n",
       "        3.17156863e-03, 3.17752101e-03, 3.18181818e-03, 3.18461538e-03,\n",
       "        3.19166667e-03, 3.32478632e-03, 3.50144928e-03, 3.50927999e-03,\n",
       "        3.51319876e-03, 3.78223408e-03, 3.91187739e-03, 3.91239316e-03,\n",
       "        3.92712551e-03, 3.99749455e-03, 4.09463046e-03, 4.20000000e-03,\n",
       "        4.20278638e-03, 4.25490196e-03, 4.30386165e-03, 4.39785068e-03,\n",
       "        4.43994337e-03, 4.49913854e-03, 4.66629009e-03, 4.71032031e-03,\n",
       "        4.79431217e-03, 4.87394958e-03, 5.12729662e-03, 5.42116605e-03,\n",
       "        5.42262922e-03, 5.45977011e-03, 5.55857488e-03, 5.74592483e-03,\n",
       "        6.22075351e-03, 6.31091800e-03, 6.38888889e-03, 6.50900413e-03,\n",
       "        6.51426713e-03, 6.58333333e-03, 6.99485612e-03, 7.09376339e-03,\n",
       "        7.33480392e-03, 7.38686995e-03, 7.46993267e-03, 7.59401709e-03,\n",
       "        7.89580588e-03, 8.05973339e-03, 8.25215770e-03, 8.31588162e-03,\n",
       "        8.90483840e-03, 8.94212026e-03, 9.21879047e-03, 9.22368563e-03,\n",
       "        9.42879393e-03, 9.51041778e-03, 9.55032715e-03, 9.57558079e-03,\n",
       "        9.72925040e-03, 9.81249916e-03, 1.01369809e-02, 1.02193781e-02,\n",
       "        1.04661875e-02, 1.05080599e-02, 1.05901954e-02, 1.06229885e-02,\n",
       "        1.10959523e-02, 1.13156575e-02, 1.13212434e-02, 1.15337070e-02,\n",
       "        1.27868457e-02, 1.28368283e-02, 1.29970760e-02, 1.43620298e-02,\n",
       "        1.50659773e-02, 1.53733043e-02, 1.67187125e-02, 1.67609660e-02,\n",
       "        1.75828645e-02, 1.85724959e-02, 2.01506447e-02, 2.06340506e-02,\n",
       "        2.10927065e-02, 2.12408490e-02, 2.19001037e-02, 2.22263938e-02,\n",
       "        2.23104122e-02, 2.26764889e-02, 2.27426904e-02, 2.36750549e-02,\n",
       "        2.41853281e-02, 2.46762009e-02, 2.51211195e-02, 2.56116267e-02,\n",
       "        2.75100285e-02, 2.75464176e-02, 2.79175510e-02, 2.84001016e-02,\n",
       "        2.88998818e-02, 2.91814585e-02, 2.93570648e-02, 2.97323942e-02,\n",
       "        2.99859969e-02, 3.16157495e-02, 3.26749277e-02, 3.30993770e-02,\n",
       "        3.37887772e-02, 3.44293984e-02, 3.61976853e-02, 3.99703925e-02,\n",
       "        4.05324819e-02, 4.37506580e-02, 4.49621555e-02, 4.90058422e-02,\n",
       "        4.91859912e-02, 4.96588053e-02, 4.97998580e-02, 5.01822028e-02,\n",
       "        5.13698057e-02, 5.32534350e-02, 5.55950126e-02, 6.00969131e-02,\n",
       "        6.39108079e-02, 6.73211490e-02, 6.81566579e-02, 6.94864803e-02,\n",
       "        7.03234766e-02, 7.29932450e-02, 7.34605128e-02, 7.43964894e-02,\n",
       "        7.49974509e-02, 7.64795658e-02, 7.67621120e-02, 7.75983848e-02,\n",
       "        7.99230586e-02, 8.23422891e-02, 8.32683516e-02, 8.66663475e-02,\n",
       "        9.33442560e-02, 9.38602057e-02, 9.46308857e-02, 9.55386444e-02,\n",
       "        9.59600400e-02, 9.74674964e-02, 9.78250398e-02, 9.87056002e-02,\n",
       "        9.90380441e-02, 1.04605389e-01, 1.06959895e-01, 1.18389456e-01,\n",
       "        1.19658353e-01, 1.35568808e-01, 1.42003745e-01, 1.43466815e-01,\n",
       "        1.45083356e-01, 1.47893467e-01, 1.48146998e-01, 1.49701779e-01,\n",
       "        1.53595213e-01, 1.54731462e-01, 1.57267003e-01, 1.62344743e-01,\n",
       "        1.64263577e-01, 1.74116715e-01, 1.79064528e-01, 1.84331641e-01,\n",
       "        1.97937618e-01, 2.01571265e-01, 2.06470874e-01, 2.09396129e-01,\n",
       "        2.25781838e-01, 2.25923274e-01, 2.40933170e-01, 2.48160645e-01,\n",
       "        2.50500255e-01, 2.54416822e-01, 2.55744583e-01, 2.59607082e-01,\n",
       "        2.62307500e-01, 2.62541826e-01, 2.64690297e-01, 2.64718399e-01,\n",
       "        2.74103207e-01, 2.74162867e-01, 2.75058355e-01, 2.78681141e-01,\n",
       "        2.86418804e-01, 2.89752132e-01, 2.96757553e-01, 3.07740228e-01,\n",
       "        3.14730968e-01, 3.19126219e-01, 3.46801166e-01, 3.51348342e-01,\n",
       "        3.51791939e-01, 3.60851165e-01, 3.61103523e-01, 3.67818952e-01,\n",
       "        3.71163776e-01, 3.89292952e-01, 3.89467352e-01, 3.92455980e-01,\n",
       "        3.93208226e-01, 4.05685810e-01, 4.21100463e-01, 4.46831871e-01,\n",
       "        4.60209831e-01, 4.63396510e-01, 4.78003346e-01, 4.87027197e-01,\n",
       "        4.88960685e-01, 4.97567693e-01, 5.12155287e-01, 5.16475529e-01,\n",
       "        5.19213032e-01, 5.23650849e-01, 5.26794365e-01, 5.27073397e-01,\n",
       "        5.41956074e-01, 5.42778078e-01, 5.44834923e-01, 5.46452721e-01,\n",
       "        5.50431006e-01, 5.67158409e-01, 5.75077666e-01, 5.76875675e-01,\n",
       "        5.81865930e-01, 5.99643029e-01, 6.02447365e-01, 6.03406837e-01,\n",
       "        6.14313443e-01, 6.20794518e-01, 6.42823759e-01, 6.61698071e-01,\n",
       "        6.72633665e-01, 6.81254262e-01, 6.82019440e-01, 6.84528226e-01,\n",
       "        6.85658837e-01, 6.91946812e-01, 6.94063557e-01, 7.10069630e-01,\n",
       "        7.34939002e-01, 7.37775006e-01, 7.39971715e-01, 7.43850268e-01,\n",
       "        7.53603429e-01, 7.54461123e-01, 7.58168135e-01, 7.65770483e-01,\n",
       "        7.67536405e-01, 7.67726947e-01, 7.73724595e-01, 7.80461310e-01,\n",
       "        7.80913823e-01, 7.81928840e-01, 7.83847642e-01, 7.84436976e-01,\n",
       "        7.84517948e-01, 7.87173895e-01, 7.94742423e-01, 7.95236593e-01,\n",
       "        7.96101164e-01, 7.97485044e-01, 8.00861123e-01, 8.02082157e-01,\n",
       "        8.18394320e-01, 8.19470326e-01, 8.19720645e-01, 8.31646203e-01,\n",
       "        8.42444927e-01, 8.44707162e-01, 8.45614564e-01, 8.46247234e-01,\n",
       "        8.53071146e-01, 8.55608367e-01, 8.64553166e-01, 8.67164112e-01,\n",
       "        8.67170396e-01, 8.67921164e-01, 8.70572656e-01, 8.71457416e-01,\n",
       "        8.72107220e-01, 8.72225553e-01, 8.74435190e-01, 8.79489895e-01,\n",
       "        8.81712708e-01, 8.82991576e-01, 8.86091294e-01, 8.86210997e-01,\n",
       "        8.86384312e-01, 8.87649308e-01, 8.88743430e-01, 8.89137896e-01,\n",
       "        8.89343329e-01, 8.89424816e-01, 8.90573480e-01, 8.92031035e-01,\n",
       "        8.93287765e-01, 8.94625605e-01, 8.97560883e-01, 9.04506585e-01,\n",
       "        9.06104780e-01, 9.09395193e-01, 9.11529725e-01, 9.12794612e-01,\n",
       "        9.20164051e-01, 9.21009845e-01, 9.21869542e-01, 9.22009535e-01,\n",
       "        9.22600343e-01, 9.23622859e-01, 9.25955609e-01, 9.28712754e-01,\n",
       "        9.30025122e-01, 9.30405189e-01, 9.30584939e-01, 9.30605867e-01,\n",
       "        9.30926300e-01, 9.31349060e-01, 9.31561639e-01, 9.32118583e-01,\n",
       "        9.35155111e-01, 9.35991587e-01, 9.36168709e-01, 9.38888788e-01,\n",
       "        9.40064716e-01, 9.40751396e-01, 9.41484973e-01, 9.42521474e-01,\n",
       "        9.42715587e-01, 9.45049192e-01, 9.46732813e-01, 9.47166474e-01,\n",
       "        9.48241907e-01, 9.48563321e-01, 9.50692449e-01, 9.51824078e-01,\n",
       "        9.52948211e-01, 9.54671316e-01, 9.57231348e-01, 9.58414715e-01,\n",
       "        9.59169455e-01, 9.61470716e-01, 9.62076014e-01, 9.62115463e-01,\n",
       "        9.62424495e-01, 9.63859729e-01, 9.64620719e-01, 9.65500418e-01,\n",
       "        9.66438396e-01, 9.67117395e-01, 9.67753802e-01, 9.67794848e-01,\n",
       "        9.68795243e-01, 9.69083264e-01, 9.69761084e-01, 9.70464573e-01,\n",
       "        9.70513907e-01, 9.70579724e-01, 9.72158246e-01, 9.72319086e-01,\n",
       "        9.72602132e-01, 9.73398611e-01, 9.73427115e-01, 9.73948187e-01,\n",
       "        9.74434959e-01, 9.74810362e-01, 9.74876309e-01, 9.75898331e-01,\n",
       "        9.76111938e-01, 9.76327973e-01, 9.76374504e-01, 9.76392014e-01,\n",
       "        9.76505664e-01, 9.76577435e-01, 9.77180066e-01, 9.77553918e-01,\n",
       "        9.78238346e-01, 9.78290792e-01, 9.78378922e-01, 9.78419456e-01,\n",
       "        9.79392120e-01, 9.80082350e-01, 9.80903302e-01, 9.81861540e-01,\n",
       "        9.82949477e-01, 9.83060227e-01, 9.83250808e-01, 9.83994272e-01,\n",
       "        9.84056714e-01, 9.84075751e-01, 9.84380694e-01, 9.85014782e-01,\n",
       "        9.85381892e-01, 9.85573934e-01, 9.87517911e-01, 9.87717514e-01,\n",
       "        9.87837193e-01, 9.87849336e-01, 9.89436900e-01, 9.89557941e-01,\n",
       "        9.89585301e-01, 9.89939634e-01, 9.90232795e-01, 9.90489542e-01,\n",
       "        9.90639286e-01, 9.91010190e-01, 9.91302556e-01, 9.91653644e-01,\n",
       "        9.91838768e-01, 9.91883176e-01, 9.92027922e-01, 9.92131092e-01,\n",
       "        9.92426676e-01, 9.92574496e-01, 9.92729614e-01, 9.92861862e-01,\n",
       "        9.93272913e-01, 9.93860110e-01, 9.93992899e-01, 9.94350800e-01,\n",
       "        9.94508418e-01, 9.94522695e-01, 9.94651515e-01, 9.94705502e-01,\n",
       "        9.94888889e-01, 9.94986111e-01, 9.95310250e-01, 9.95590531e-01,\n",
       "        9.95762515e-01, 9.96052583e-01, 9.96065217e-01, 9.96550802e-01,\n",
       "        9.97115385e-01, 9.97224617e-01, 9.97238095e-01, 9.97490028e-01,\n",
       "        9.97661765e-01, 9.97806324e-01, 9.98152778e-01, 9.98245098e-01,\n",
       "        9.98400270e-01, 9.98505435e-01, 9.98571429e-01, 9.98666667e-01,\n",
       "        9.98856209e-01, 9.98888889e-01, 9.98916667e-01, 9.99188312e-01,\n",
       "        9.99333333e-01, 9.99411765e-01, 9.99565217e-01, 1.00000000e+00]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, PrecisionRecallDisplay, precision_recall_curve\n",
    "print(\"Validation: Victor+Oct2022\")\n",
    "y_true = tpot_df.query('group==\"val\"')['inappropriate_label']\n",
    "y_score = tpot_df.query('group==\"val\"')['inappropriate_prob']\n",
    "y_pred = y_score >= 0.5\n",
    "print(f'the auc score is {roc_auc_score(y_true,y_score)}')\n",
    "print(classification_report(y_true,y_pred, digits=3))\n",
    "\n",
    "print(\"Validation: Victor set\")\n",
    "y_true = tpot_df.query('group==\"val\" & set == \"victor\"')['inappropriate_label']\n",
    "y_score = tpot_df.query('group==\"val\" & set == \"victor\"')['inappropriate_prob']\n",
    "y_pred = y_score >= 0.5\n",
    "print(f'the auc score is {roc_auc_score(y_true,y_score)}')\n",
    "print(classification_report(y_true,y_pred, digits=3))\n",
    "\n",
    "PrecisionRecallDisplay.from_predictions(y_true, y_score)\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, y_score)\n",
    "precision, recall, thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Victor set\n",
      "the auc score is 0.9736565068396867\n",
      "Classification report when threshold is 0.3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.951     0.856     0.901       987\n",
      "         1.0      0.867     0.955     0.909       973\n",
      "\n",
      "    accuracy                          0.905      1960\n",
      "   macro avg      0.909     0.905     0.905      1960\n",
      "weighted avg      0.909     0.905     0.905      1960\n",
      "\n",
      "Classification report when threshold is 0.3025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.951     0.858     0.902       987\n",
      "         1.0      0.869     0.955     0.910       973\n",
      "\n",
      "    accuracy                          0.906      1960\n",
      "   macro avg      0.910     0.906     0.906      1960\n",
      "weighted avg      0.910     0.906     0.906      1960\n",
      "\n",
      "Classification report when threshold is 0.305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.949     0.861     0.903       987\n",
      "         1.0      0.871     0.953     0.910       973\n",
      "\n",
      "    accuracy                          0.907      1960\n",
      "   macro avg      0.910     0.907     0.906      1960\n",
      "weighted avg      0.910     0.907     0.906      1960\n",
      "\n",
      "Classification report when threshold is 0.3075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.949     0.863     0.904       987\n",
      "         1.0      0.873     0.953     0.911       973\n",
      "\n",
      "    accuracy                          0.908      1960\n",
      "   macro avg      0.911     0.908     0.908      1960\n",
      "weighted avg      0.911     0.908     0.907      1960\n",
      "\n",
      "Classification report when threshold is 0.31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.949     0.863     0.904       987\n",
      "         1.0      0.873     0.953     0.911       973\n",
      "\n",
      "    accuracy                          0.908      1960\n",
      "   macro avg      0.911     0.908     0.908      1960\n",
      "weighted avg      0.911     0.908     0.907      1960\n",
      "\n",
      "Classification report when threshold is 0.3125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.949     0.865     0.905       987\n",
      "         1.0      0.875     0.953     0.912       973\n",
      "\n",
      "    accuracy                          0.909      1960\n",
      "   macro avg      0.912     0.909     0.909      1960\n",
      "weighted avg      0.912     0.909     0.909      1960\n",
      "\n",
      "Classification report when threshold is 0.315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.949     0.866     0.906       987\n",
      "         1.0      0.875     0.953     0.912       973\n",
      "\n",
      "    accuracy                          0.909      1960\n",
      "   macro avg      0.912     0.909     0.909      1960\n",
      "weighted avg      0.912     0.909     0.909      1960\n",
      "\n",
      "Classification report when threshold is 0.3175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.948     0.867     0.906       987\n",
      "         1.0      0.876     0.952     0.912       973\n",
      "\n",
      "    accuracy                          0.909      1960\n",
      "   macro avg      0.912     0.909     0.909      1960\n",
      "weighted avg      0.912     0.909     0.909      1960\n",
      "\n",
      "Classification report when threshold is 0.32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.947     0.867     0.905       987\n",
      "         1.0      0.876     0.951     0.912       973\n",
      "\n",
      "    accuracy                          0.909      1960\n",
      "   macro avg      0.911     0.909     0.909      1960\n",
      "weighted avg      0.912     0.909     0.909      1960\n",
      "\n",
      "Classification report when threshold is 0.3225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.946     0.868     0.905       987\n",
      "         1.0      0.877     0.950     0.912       973\n",
      "\n",
      "    accuracy                          0.909      1960\n",
      "   macro avg      0.911     0.909     0.909      1960\n",
      "weighted avg      0.912     0.909     0.909      1960\n",
      "\n",
      "Classification report when threshold is 0.325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.946     0.871     0.907       987\n",
      "         1.0      0.879     0.950     0.913       973\n",
      "\n",
      "    accuracy                          0.910      1960\n",
      "   macro avg      0.913     0.910     0.910      1960\n",
      "weighted avg      0.913     0.910     0.910      1960\n",
      "\n",
      "Classification report when threshold is 0.3275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.944     0.873     0.907       987\n",
      "         1.0      0.881     0.948     0.913       973\n",
      "\n",
      "    accuracy                          0.910      1960\n",
      "   macro avg      0.912     0.910     0.910      1960\n",
      "weighted avg      0.913     0.910     0.910      1960\n",
      "\n",
      "Classification report when threshold is 0.33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.943     0.875     0.908       987\n",
      "         1.0      0.882     0.947     0.913       973\n",
      "\n",
      "    accuracy                          0.911      1960\n",
      "   macro avg      0.913     0.911     0.911      1960\n",
      "weighted avg      0.913     0.911     0.911      1960\n",
      "\n",
      "Classification report when threshold is 0.3325\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.943     0.875     0.908       987\n",
      "         1.0      0.882     0.947     0.913       973\n",
      "\n",
      "    accuracy                          0.911      1960\n",
      "   macro avg      0.913     0.911     0.911      1960\n",
      "weighted avg      0.913     0.911     0.911      1960\n",
      "\n",
      "Classification report when threshold is 0.335\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.943     0.877     0.909       987\n",
      "         1.0      0.884     0.947     0.914       973\n",
      "\n",
      "    accuracy                          0.912      1960\n",
      "   macro avg      0.914     0.912     0.912      1960\n",
      "weighted avg      0.914     0.912     0.912      1960\n",
      "\n",
      "Classification report when threshold is 0.3375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.943     0.877     0.909       987\n",
      "         1.0      0.884     0.947     0.914       973\n",
      "\n",
      "    accuracy                          0.912      1960\n",
      "   macro avg      0.914     0.912     0.912      1960\n",
      "weighted avg      0.914     0.912     0.912      1960\n",
      "\n",
      "Classification report when threshold is 0.34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.943     0.879     0.910       987\n",
      "         1.0      0.886     0.947     0.915       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.915     0.913     0.913      1960\n",
      "weighted avg      0.915     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.3425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.943     0.880     0.910       987\n",
      "         1.0      0.886     0.946     0.915       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.914     0.913     0.913      1960\n",
      "weighted avg      0.915     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.34500000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.942     0.882     0.911       987\n",
      "         1.0      0.888     0.945     0.915       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.915     0.913     0.913      1960\n",
      "weighted avg      0.915     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.34750000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.941     0.883     0.911       987\n",
      "         1.0      0.889     0.943     0.915       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.915     0.913     0.913      1960\n",
      "weighted avg      0.915     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.35000000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.940     0.884     0.911       987\n",
      "         1.0      0.889     0.942     0.915       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.915     0.913     0.913      1960\n",
      "weighted avg      0.915     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.35250000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.939     0.886     0.911       987\n",
      "         1.0      0.890     0.941     0.915       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.914     0.913     0.913      1960\n",
      "weighted avg      0.915     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.35500000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.939     0.886     0.911       987\n",
      "         1.0      0.890     0.941     0.915       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.914     0.913     0.913      1960\n",
      "weighted avg      0.915     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.35750000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.939     0.886     0.911       987\n",
      "         1.0      0.890     0.941     0.915       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.914     0.913     0.913      1960\n",
      "weighted avg      0.915     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.36000000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.939     0.888     0.913       987\n",
      "         1.0      0.892     0.941     0.916       973\n",
      "\n",
      "    accuracy                          0.914      1960\n",
      "   macro avg      0.915     0.914     0.914      1960\n",
      "weighted avg      0.916     0.914     0.914      1960\n",
      "\n",
      "Classification report when threshold is 0.36250000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.939     0.888     0.913       987\n",
      "         1.0      0.892     0.941     0.916       973\n",
      "\n",
      "    accuracy                          0.914      1960\n",
      "   macro avg      0.915     0.914     0.914      1960\n",
      "weighted avg      0.916     0.914     0.914      1960\n",
      "\n",
      "Classification report when threshold is 0.36500000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.938     0.889     0.913       987\n",
      "         1.0      0.893     0.940     0.916       973\n",
      "\n",
      "    accuracy                          0.914      1960\n",
      "   macro avg      0.915     0.914     0.914      1960\n",
      "weighted avg      0.915     0.914     0.914      1960\n",
      "\n",
      "Classification report when threshold is 0.36750000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.936     0.890     0.912       987\n",
      "         1.0      0.893     0.938     0.915       973\n",
      "\n",
      "    accuracy                          0.914      1960\n",
      "   macro avg      0.915     0.914     0.914      1960\n",
      "weighted avg      0.915     0.914     0.914      1960\n",
      "\n",
      "Classification report when threshold is 0.37000000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.935     0.891     0.912       987\n",
      "         1.0      0.894     0.937     0.915       973\n",
      "\n",
      "    accuracy                          0.914      1960\n",
      "   macro avg      0.915     0.914     0.914      1960\n",
      "weighted avg      0.915     0.914     0.914      1960\n",
      "\n",
      "Classification report when threshold is 0.37250000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.935     0.891     0.912       987\n",
      "         1.0      0.894     0.937     0.915       973\n",
      "\n",
      "    accuracy                          0.914      1960\n",
      "   macro avg      0.915     0.914     0.914      1960\n",
      "weighted avg      0.915     0.914     0.914      1960\n",
      "\n",
      "Classification report when threshold is 0.37500000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.934     0.891     0.912       987\n",
      "         1.0      0.894     0.936     0.915       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.914     0.913     0.913      1960\n",
      "weighted avg      0.914     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.37750000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.933     0.891     0.911       987\n",
      "         1.0      0.894     0.935     0.914       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.914     0.913     0.913      1960\n",
      "weighted avg      0.914     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.38000000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.933     0.893     0.912       987\n",
      "         1.0      0.896     0.935     0.915       973\n",
      "\n",
      "    accuracy                          0.914      1960\n",
      "   macro avg      0.914     0.914     0.914      1960\n",
      "weighted avg      0.915     0.914     0.914      1960\n",
      "\n",
      "Classification report when threshold is 0.38250000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.932     0.894     0.913       987\n",
      "         1.0      0.896     0.934     0.915       973\n",
      "\n",
      "    accuracy                          0.914      1960\n",
      "   macro avg      0.914     0.914     0.914      1960\n",
      "weighted avg      0.915     0.914     0.914      1960\n",
      "\n",
      "Classification report when threshold is 0.38500000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.932     0.894     0.913       987\n",
      "         1.0      0.896     0.934     0.915       973\n",
      "\n",
      "    accuracy                          0.914      1960\n",
      "   macro avg      0.914     0.914     0.914      1960\n",
      "weighted avg      0.915     0.914     0.914      1960\n",
      "\n",
      "Classification report when threshold is 0.38750000000000007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.931     0.895     0.913       987\n",
      "         1.0      0.897     0.933     0.915       973\n",
      "\n",
      "    accuracy                          0.914      1960\n",
      "   macro avg      0.914     0.914     0.914      1960\n",
      "weighted avg      0.914     0.914     0.914      1960\n",
      "\n",
      "Classification report when threshold is 0.39000000000000007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.932     0.898     0.914       987\n",
      "         1.0      0.900     0.933     0.916       973\n",
      "\n",
      "    accuracy                          0.915      1960\n",
      "   macro avg      0.916     0.915     0.915      1960\n",
      "weighted avg      0.916     0.915     0.915      1960\n",
      "\n",
      "Classification report when threshold is 0.39250000000000007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.931     0.898     0.914       987\n",
      "         1.0      0.900     0.932     0.916       973\n",
      "\n",
      "    accuracy                          0.915      1960\n",
      "   macro avg      0.915     0.915     0.915      1960\n",
      "weighted avg      0.915     0.915     0.915      1960\n",
      "\n",
      "Classification report when threshold is 0.3950000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.930     0.898     0.913       987\n",
      "         1.0      0.900     0.931     0.915       973\n",
      "\n",
      "    accuracy                          0.914      1960\n",
      "   macro avg      0.915     0.914     0.914      1960\n",
      "weighted avg      0.915     0.914     0.914      1960\n",
      "\n",
      "Classification report when threshold is 0.3975000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.928     0.899     0.913       987\n",
      "         1.0      0.900     0.929     0.915       973\n",
      "\n",
      "    accuracy                          0.914      1960\n",
      "   macro avg      0.914     0.914     0.914      1960\n",
      "weighted avg      0.914     0.914     0.914      1960\n",
      "\n",
      "Classification report when threshold is 0.4000000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.925     0.899     0.912       987\n",
      "         1.0      0.900     0.926     0.913       973\n",
      "\n",
      "    accuracy                          0.912      1960\n",
      "   macro avg      0.913     0.912     0.912      1960\n",
      "weighted avg      0.913     0.912     0.912      1960\n",
      "\n",
      "Classification report when threshold is 0.4025000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.924     0.900     0.912       987\n",
      "         1.0      0.901     0.925     0.913       973\n",
      "\n",
      "    accuracy                          0.912      1960\n",
      "   macro avg      0.912     0.912     0.912      1960\n",
      "weighted avg      0.913     0.912     0.912      1960\n",
      "\n",
      "Classification report when threshold is 0.4050000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.924     0.902     0.913       987\n",
      "         1.0      0.903     0.925     0.914       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.913     0.913     0.913      1960\n",
      "weighted avg      0.914     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.4075000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.924     0.902     0.913       987\n",
      "         1.0      0.903     0.925     0.914       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.913     0.913     0.913      1960\n",
      "weighted avg      0.914     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.4100000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.923     0.904     0.913       987\n",
      "         1.0      0.904     0.924     0.914       973\n",
      "\n",
      "    accuracy                          0.914      1960\n",
      "   macro avg      0.914     0.914     0.914      1960\n",
      "weighted avg      0.914     0.914     0.914      1960\n",
      "\n",
      "Classification report when threshold is 0.4125000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.923     0.905     0.914       987\n",
      "         1.0      0.905     0.923     0.914       973\n",
      "\n",
      "    accuracy                          0.914      1960\n",
      "   macro avg      0.914     0.914     0.914      1960\n",
      "weighted avg      0.914     0.914     0.914      1960\n",
      "\n",
      "Classification report when threshold is 0.4150000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.922     0.905     0.913       987\n",
      "         1.0      0.905     0.922     0.913       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.913     0.913     0.913      1960\n",
      "weighted avg      0.913     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.4175000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.921     0.905     0.913       987\n",
      "         1.0      0.905     0.921     0.913       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.913     0.913     0.913      1960\n",
      "weighted avg      0.913     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.4200000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.920     0.905     0.912       987\n",
      "         1.0      0.905     0.920     0.912       973\n",
      "\n",
      "    accuracy                          0.912      1960\n",
      "   macro avg      0.912     0.912     0.912      1960\n",
      "weighted avg      0.912     0.912     0.912      1960\n",
      "\n",
      "Classification report when threshold is 0.4225000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.920     0.906     0.913       987\n",
      "         1.0      0.906     0.920     0.913       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.913     0.913     0.913      1960\n",
      "weighted avg      0.913     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.4250000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.920     0.908     0.914       987\n",
      "         1.0      0.908     0.920     0.914       973\n",
      "\n",
      "    accuracy                          0.914      1960\n",
      "   macro avg      0.914     0.914     0.914      1960\n",
      "weighted avg      0.914     0.914     0.914      1960\n",
      "\n",
      "Classification report when threshold is 0.4275000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.920     0.908     0.914       987\n",
      "         1.0      0.908     0.920     0.914       973\n",
      "\n",
      "    accuracy                          0.914      1960\n",
      "   macro avg      0.914     0.914     0.914      1960\n",
      "weighted avg      0.914     0.914     0.914      1960\n",
      "\n",
      "Classification report when threshold is 0.4300000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.919     0.909     0.914       987\n",
      "         1.0      0.909     0.919     0.914       973\n",
      "\n",
      "    accuracy                          0.914      1960\n",
      "   macro avg      0.914     0.914     0.914      1960\n",
      "weighted avg      0.914     0.914     0.914      1960\n",
      "\n",
      "Classification report when threshold is 0.4325000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.918     0.910     0.914       987\n",
      "         1.0      0.909     0.918     0.914       973\n",
      "\n",
      "    accuracy                          0.914      1960\n",
      "   macro avg      0.914     0.914     0.914      1960\n",
      "weighted avg      0.914     0.914     0.914      1960\n",
      "\n",
      "Classification report when threshold is 0.4350000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.917     0.910     0.914       987\n",
      "         1.0      0.909     0.917     0.913       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.913     0.913     0.913      1960\n",
      "weighted avg      0.913     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.4375000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.917     0.912     0.915       987\n",
      "         1.0      0.911     0.917     0.914       973\n",
      "\n",
      "    accuracy                          0.914      1960\n",
      "   macro avg      0.914     0.914     0.914      1960\n",
      "weighted avg      0.914     0.914     0.914      1960\n",
      "\n",
      "Classification report when threshold is 0.4400000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.916     0.912     0.914       987\n",
      "         1.0      0.911     0.915     0.913       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.913     0.913     0.913      1960\n",
      "weighted avg      0.913     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.4425000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.916     0.913     0.914       987\n",
      "         1.0      0.912     0.915     0.913       973\n",
      "\n",
      "    accuracy                          0.914      1960\n",
      "   macro avg      0.914     0.914     0.914      1960\n",
      "weighted avg      0.914     0.914     0.914      1960\n",
      "\n",
      "Classification report when threshold is 0.4450000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.916     0.915     0.915       987\n",
      "         1.0      0.914     0.915     0.914       973\n",
      "\n",
      "    accuracy                          0.915      1960\n",
      "   macro avg      0.915     0.915     0.915      1960\n",
      "weighted avg      0.915     0.915     0.915      1960\n",
      "\n",
      "Classification report when threshold is 0.4475000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.916     0.915     0.915       987\n",
      "         1.0      0.914     0.915     0.914       973\n",
      "\n",
      "    accuracy                          0.915      1960\n",
      "   macro avg      0.915     0.915     0.915      1960\n",
      "weighted avg      0.915     0.915     0.915      1960\n",
      "\n",
      "Classification report when threshold is 0.4500000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.915     0.916     0.915       987\n",
      "         1.0      0.915     0.914     0.914       973\n",
      "\n",
      "    accuracy                          0.915      1960\n",
      "   macro avg      0.915     0.915     0.915      1960\n",
      "weighted avg      0.915     0.915     0.915      1960\n",
      "\n",
      "Classification report when threshold is 0.4525000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.913     0.916     0.915       987\n",
      "         1.0      0.914     0.912     0.913       973\n",
      "\n",
      "    accuracy                          0.914      1960\n",
      "   macro avg      0.914     0.914     0.914      1960\n",
      "weighted avg      0.914     0.914     0.914      1960\n",
      "\n",
      "Classification report when threshold is 0.4550000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.913     0.917     0.915       987\n",
      "         1.0      0.915     0.912     0.913       973\n",
      "\n",
      "    accuracy                          0.914      1960\n",
      "   macro avg      0.914     0.914     0.914      1960\n",
      "weighted avg      0.914     0.914     0.914      1960\n",
      "\n",
      "Classification report when threshold is 0.45750000000000013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.913     0.917     0.915       987\n",
      "         1.0      0.915     0.912     0.913       973\n",
      "\n",
      "    accuracy                          0.914      1960\n",
      "   macro avg      0.914     0.914     0.914      1960\n",
      "weighted avg      0.914     0.914     0.914      1960\n",
      "\n",
      "Classification report when threshold is 0.46000000000000013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.912     0.918     0.915       987\n",
      "         1.0      0.916     0.911     0.913       973\n",
      "\n",
      "    accuracy                          0.914      1960\n",
      "   macro avg      0.914     0.914     0.914      1960\n",
      "weighted avg      0.914     0.914     0.914      1960\n",
      "\n",
      "Classification report when threshold is 0.46250000000000013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.912     0.919     0.915       987\n",
      "         1.0      0.917     0.910     0.913       973\n",
      "\n",
      "    accuracy                          0.914      1960\n",
      "   macro avg      0.914     0.914     0.914      1960\n",
      "weighted avg      0.914     0.914     0.914      1960\n",
      "\n",
      "Classification report when threshold is 0.46500000000000014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.910     0.919     0.914       987\n",
      "         1.0      0.917     0.908     0.912       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.913     0.913     0.913      1960\n",
      "weighted avg      0.913     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.46750000000000014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.909     0.920     0.914       987\n",
      "         1.0      0.918     0.906     0.912       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.913     0.913     0.913      1960\n",
      "weighted avg      0.913     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.47000000000000014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.906     0.921     0.914       987\n",
      "         1.0      0.918     0.903     0.911       973\n",
      "\n",
      "    accuracy                          0.912      1960\n",
      "   macro avg      0.912     0.912     0.912      1960\n",
      "weighted avg      0.912     0.912     0.912      1960\n",
      "\n",
      "Classification report when threshold is 0.47250000000000014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.906     0.922     0.914       987\n",
      "         1.0      0.919     0.903     0.911       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.913     0.913     0.913      1960\n",
      "weighted avg      0.913     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.47500000000000014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.906     0.922     0.914       987\n",
      "         1.0      0.919     0.903     0.911       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.913     0.913     0.913      1960\n",
      "weighted avg      0.913     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.47750000000000015\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.905     0.922     0.914       987\n",
      "         1.0      0.919     0.902     0.911       973\n",
      "\n",
      "    accuracy                          0.912      1960\n",
      "   macro avg      0.912     0.912     0.912      1960\n",
      "weighted avg      0.912     0.912     0.912      1960\n",
      "\n",
      "Classification report when threshold is 0.48000000000000015\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.903     0.922     0.912       987\n",
      "         1.0      0.919     0.899     0.909       973\n",
      "\n",
      "    accuracy                          0.911      1960\n",
      "   macro avg      0.911     0.911     0.911      1960\n",
      "weighted avg      0.911     0.911     0.911      1960\n",
      "\n",
      "Classification report when threshold is 0.48250000000000015\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.902     0.923     0.912       987\n",
      "         1.0      0.920     0.898     0.909       973\n",
      "\n",
      "    accuracy                          0.911      1960\n",
      "   macro avg      0.911     0.911     0.911      1960\n",
      "weighted avg      0.911     0.911     0.911      1960\n",
      "\n",
      "Classification report when threshold is 0.48500000000000015\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.902     0.924     0.913       987\n",
      "         1.0      0.921     0.898     0.909       973\n",
      "\n",
      "    accuracy                          0.911      1960\n",
      "   macro avg      0.912     0.911     0.911      1960\n",
      "weighted avg      0.911     0.911     0.911      1960\n",
      "\n",
      "Classification report when threshold is 0.48750000000000016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.902     0.926     0.914       987\n",
      "         1.0      0.923     0.898     0.910       973\n",
      "\n",
      "    accuracy                          0.912      1960\n",
      "   macro avg      0.913     0.912     0.912      1960\n",
      "weighted avg      0.913     0.912     0.912      1960\n",
      "\n",
      "Classification report when threshold is 0.49000000000000016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.902     0.926     0.914       987\n",
      "         1.0      0.923     0.898     0.910       973\n",
      "\n",
      "    accuracy                          0.912      1960\n",
      "   macro avg      0.913     0.912     0.912      1960\n",
      "weighted avg      0.913     0.912     0.912      1960\n",
      "\n",
      "Classification report when threshold is 0.49250000000000016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.902     0.928     0.915       987\n",
      "         1.0      0.925     0.898     0.911       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.914     0.913     0.913      1960\n",
      "weighted avg      0.914     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.49500000000000016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.902     0.928     0.915       987\n",
      "         1.0      0.925     0.898     0.911       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.914     0.913     0.913      1960\n",
      "weighted avg      0.914     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.49750000000000016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.903     0.929     0.916       987\n",
      "         1.0      0.926     0.898     0.912       973\n",
      "\n",
      "    accuracy                          0.914      1960\n",
      "   macro avg      0.914     0.914     0.914      1960\n",
      "weighted avg      0.914     0.914     0.914      1960\n",
      "\n",
      "Classification report when threshold is 0.5000000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.902     0.929     0.915       987\n",
      "         1.0      0.926     0.897     0.911       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.914     0.913     0.913      1960\n",
      "weighted avg      0.914     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.5025000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.901     0.929     0.915       987\n",
      "         1.0      0.926     0.896     0.911       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.913     0.913     0.913      1960\n",
      "weighted avg      0.913     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.5050000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.900     0.929     0.914       987\n",
      "         1.0      0.926     0.895     0.910       973\n",
      "\n",
      "    accuracy                          0.912      1960\n",
      "   macro avg      0.913     0.912     0.912      1960\n",
      "weighted avg      0.913     0.912     0.912      1960\n",
      "\n",
      "Classification report when threshold is 0.5075000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.900     0.930     0.915       987\n",
      "         1.0      0.927     0.895     0.911       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.913     0.913     0.913      1960\n",
      "weighted avg      0.913     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.5100000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.898     0.930     0.914       987\n",
      "         1.0      0.926     0.893     0.909       973\n",
      "\n",
      "    accuracy                          0.912      1960\n",
      "   macro avg      0.912     0.912     0.912      1960\n",
      "weighted avg      0.912     0.912     0.912      1960\n",
      "\n",
      "Classification report when threshold is 0.5125000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.897     0.931     0.914       987\n",
      "         1.0      0.927     0.891     0.909       973\n",
      "\n",
      "    accuracy                          0.911      1960\n",
      "   macro avg      0.912     0.911     0.911      1960\n",
      "weighted avg      0.912     0.911     0.911      1960\n",
      "\n",
      "Classification report when threshold is 0.5150000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.897     0.931     0.914       987\n",
      "         1.0      0.927     0.891     0.909       973\n",
      "\n",
      "    accuracy                          0.911      1960\n",
      "   macro avg      0.912     0.911     0.911      1960\n",
      "weighted avg      0.912     0.911     0.911      1960\n",
      "\n",
      "Classification report when threshold is 0.5175000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.896     0.934     0.915       987\n",
      "         1.0      0.930     0.890     0.910       973\n",
      "\n",
      "    accuracy                          0.912      1960\n",
      "   macro avg      0.913     0.912     0.912      1960\n",
      "weighted avg      0.913     0.912     0.912      1960\n",
      "\n",
      "Classification report when threshold is 0.5200000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.895     0.936     0.915       987\n",
      "         1.0      0.932     0.889     0.910       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.914     0.913     0.913      1960\n",
      "weighted avg      0.914     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.5225000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.895     0.937     0.916       987\n",
      "         1.0      0.933     0.889     0.911       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.914     0.913     0.913      1960\n",
      "weighted avg      0.914     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.5250000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.895     0.937     0.915       987\n",
      "         1.0      0.933     0.888     0.910       973\n",
      "\n",
      "    accuracy                          0.913      1960\n",
      "   macro avg      0.914     0.913     0.913      1960\n",
      "weighted avg      0.914     0.913     0.913      1960\n",
      "\n",
      "Classification report when threshold is 0.5275000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.894     0.937     0.915       987\n",
      "         1.0      0.933     0.887     0.909       973\n",
      "\n",
      "    accuracy                          0.912      1960\n",
      "   macro avg      0.913     0.912     0.912      1960\n",
      "weighted avg      0.913     0.912     0.912      1960\n",
      "\n",
      "Classification report when threshold is 0.5300000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.892     0.937     0.914       987\n",
      "         1.0      0.933     0.885     0.908       973\n",
      "\n",
      "    accuracy                          0.911      1960\n",
      "   macro avg      0.912     0.911     0.911      1960\n",
      "weighted avg      0.912     0.911     0.911      1960\n",
      "\n",
      "Classification report when threshold is 0.5325000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.892     0.938     0.915       987\n",
      "         1.0      0.934     0.885     0.909       973\n",
      "\n",
      "    accuracy                          0.912      1960\n",
      "   macro avg      0.913     0.912     0.912      1960\n",
      "weighted avg      0.913     0.912     0.912      1960\n",
      "\n",
      "Classification report when threshold is 0.5350000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.892     0.938     0.915       987\n",
      "         1.0      0.934     0.885     0.909       973\n",
      "\n",
      "    accuracy                          0.912      1960\n",
      "   macro avg      0.913     0.912     0.912      1960\n",
      "weighted avg      0.913     0.912     0.912      1960\n",
      "\n",
      "Classification report when threshold is 0.5375000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.890     0.938     0.914       987\n",
      "         1.0      0.934     0.883     0.908       973\n",
      "\n",
      "    accuracy                          0.911      1960\n",
      "   macro avg      0.912     0.911     0.911      1960\n",
      "weighted avg      0.912     0.911     0.911      1960\n",
      "\n",
      "Classification report when threshold is 0.5400000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.890     0.938     0.914       987\n",
      "         1.0      0.934     0.883     0.908       973\n",
      "\n",
      "    accuracy                          0.911      1960\n",
      "   macro avg      0.912     0.911     0.911      1960\n",
      "weighted avg      0.912     0.911     0.911      1960\n",
      "\n",
      "Classification report when threshold is 0.5425000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.890     0.939     0.914       987\n",
      "         1.0      0.935     0.883     0.908       973\n",
      "\n",
      "    accuracy                          0.911      1960\n",
      "   macro avg      0.913     0.911     0.911      1960\n",
      "weighted avg      0.912     0.911     0.911      1960\n",
      "\n",
      "Classification report when threshold is 0.5450000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.889     0.939     0.913       987\n",
      "         1.0      0.935     0.881     0.907       973\n",
      "\n",
      "    accuracy                          0.910      1960\n",
      "   macro avg      0.912     0.910     0.910      1960\n",
      "weighted avg      0.912     0.910     0.910      1960\n",
      "\n",
      "Classification report when threshold is 0.5475000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.887     0.939     0.912       987\n",
      "         1.0      0.934     0.879     0.906       973\n",
      "\n",
      "    accuracy                          0.909      1960\n",
      "   macro avg      0.911     0.909     0.909      1960\n",
      "weighted avg      0.911     0.909     0.909      1960\n",
      "\n",
      "Classification report when threshold is 0.5500000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.886     0.940     0.912       987\n",
      "         1.0      0.935     0.878     0.906       973\n",
      "\n",
      "    accuracy                          0.909      1960\n",
      "   macro avg      0.911     0.909     0.909      1960\n",
      "weighted avg      0.911     0.909     0.909      1960\n",
      "\n",
      "Classification report when threshold is 0.5525000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.885     0.941     0.912       987\n",
      "         1.0      0.936     0.876     0.905       973\n",
      "\n",
      "    accuracy                          0.909      1960\n",
      "   macro avg      0.911     0.908     0.909      1960\n",
      "weighted avg      0.910     0.909     0.909      1960\n",
      "\n",
      "Classification report when threshold is 0.5550000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.884     0.942     0.912       987\n",
      "         1.0      0.937     0.875     0.905       973\n",
      "\n",
      "    accuracy                          0.909      1960\n",
      "   macro avg      0.911     0.908     0.909      1960\n",
      "weighted avg      0.910     0.909     0.909      1960\n",
      "\n",
      "Classification report when threshold is 0.5575000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.884     0.943     0.913       987\n",
      "         1.0      0.938     0.875     0.905       973\n",
      "\n",
      "    accuracy                          0.909      1960\n",
      "   macro avg      0.911     0.909     0.909      1960\n",
      "weighted avg      0.911     0.909     0.909      1960\n",
      "\n",
      "Classification report when threshold is 0.5600000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.884     0.943     0.913       987\n",
      "         1.0      0.938     0.875     0.905       973\n",
      "\n",
      "    accuracy                          0.909      1960\n",
      "   macro avg      0.911     0.909     0.909      1960\n",
      "weighted avg      0.911     0.909     0.909      1960\n",
      "\n",
      "Classification report when threshold is 0.5625000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.884     0.943     0.913       987\n",
      "         1.0      0.938     0.875     0.905       973\n",
      "\n",
      "    accuracy                          0.909      1960\n",
      "   macro avg      0.911     0.909     0.909      1960\n",
      "weighted avg      0.911     0.909     0.909      1960\n",
      "\n",
      "Classification report when threshold is 0.5650000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.884     0.943     0.913       987\n",
      "         1.0      0.938     0.875     0.905       973\n",
      "\n",
      "    accuracy                          0.909      1960\n",
      "   macro avg      0.911     0.909     0.909      1960\n",
      "weighted avg      0.911     0.909     0.909      1960\n",
      "\n",
      "Classification report when threshold is 0.5675000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.884     0.944     0.913       987\n",
      "         1.0      0.939     0.875     0.906       973\n",
      "\n",
      "    accuracy                          0.910      1960\n",
      "   macro avg      0.912     0.909     0.910      1960\n",
      "weighted avg      0.912     0.910     0.910      1960\n",
      "\n",
      "Classification report when threshold is 0.5700000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.884     0.944     0.913       987\n",
      "         1.0      0.939     0.875     0.906       973\n",
      "\n",
      "    accuracy                          0.910      1960\n",
      "   macro avg      0.912     0.909     0.910      1960\n",
      "weighted avg      0.912     0.910     0.910      1960\n",
      "\n",
      "Classification report when threshold is 0.5725000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.884     0.946     0.914       987\n",
      "         1.0      0.941     0.874     0.906       973\n",
      "\n",
      "    accuracy                          0.910      1960\n",
      "   macro avg      0.912     0.910     0.910      1960\n",
      "weighted avg      0.912     0.910     0.910      1960\n",
      "\n",
      "Classification report when threshold is 0.5750000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.884     0.946     0.914       987\n",
      "         1.0      0.941     0.874     0.906       973\n",
      "\n",
      "    accuracy                          0.910      1960\n",
      "   macro avg      0.912     0.910     0.910      1960\n",
      "weighted avg      0.912     0.910     0.910      1960\n",
      "\n",
      "Classification report when threshold is 0.5775000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.884     0.947     0.914       987\n",
      "         1.0      0.942     0.874     0.907       973\n",
      "\n",
      "    accuracy                          0.911      1960\n",
      "   macro avg      0.913     0.910     0.911      1960\n",
      "weighted avg      0.913     0.911     0.911      1960\n",
      "\n",
      "Classification report when threshold is 0.5800000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.882     0.948     0.914       987\n",
      "         1.0      0.943     0.872     0.906       973\n",
      "\n",
      "    accuracy                          0.910      1960\n",
      "   macro avg      0.913     0.910     0.910      1960\n",
      "weighted avg      0.913     0.910     0.910      1960\n",
      "\n",
      "Classification report when threshold is 0.5825000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.881     0.948     0.914       987\n",
      "         1.0      0.943     0.871     0.905       973\n",
      "\n",
      "    accuracy                          0.910      1960\n",
      "   macro avg      0.912     0.909     0.910      1960\n",
      "weighted avg      0.912     0.910     0.910      1960\n",
      "\n",
      "Classification report when threshold is 0.5850000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.881     0.948     0.914       987\n",
      "         1.0      0.943     0.871     0.905       973\n",
      "\n",
      "    accuracy                          0.910      1960\n",
      "   macro avg      0.912     0.909     0.910      1960\n",
      "weighted avg      0.912     0.910     0.910      1960\n",
      "\n",
      "Classification report when threshold is 0.5875000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.881     0.948     0.913       987\n",
      "         1.0      0.943     0.869     0.905       973\n",
      "\n",
      "    accuracy                          0.909      1960\n",
      "   macro avg      0.912     0.909     0.909      1960\n",
      "weighted avg      0.912     0.909     0.909      1960\n",
      "\n",
      "Classification report when threshold is 0.5900000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.879     0.948     0.912       987\n",
      "         1.0      0.943     0.867     0.904       973\n",
      "\n",
      "    accuracy                          0.908      1960\n",
      "   macro avg      0.911     0.908     0.908      1960\n",
      "weighted avg      0.911     0.908     0.908      1960\n",
      "\n",
      "Classification report when threshold is 0.5925000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.878     0.949     0.912       987\n",
      "         1.0      0.944     0.866     0.904       973\n",
      "\n",
      "    accuracy                          0.908      1960\n",
      "   macro avg      0.911     0.908     0.908      1960\n",
      "weighted avg      0.911     0.908     0.908      1960\n",
      "\n",
      "Classification report when threshold is 0.5950000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.877     0.949     0.912       987\n",
      "         1.0      0.944     0.865     0.903       973\n",
      "\n",
      "    accuracy                          0.908      1960\n",
      "   macro avg      0.911     0.907     0.907      1960\n",
      "weighted avg      0.910     0.908     0.907      1960\n",
      "\n",
      "Classification report when threshold is 0.5975000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.876     0.950     0.912       987\n",
      "         1.0      0.945     0.863     0.902       973\n",
      "\n",
      "    accuracy                          0.907      1960\n",
      "   macro avg      0.910     0.907     0.907      1960\n",
      "weighted avg      0.910     0.907     0.907      1960\n",
      "\n",
      "Classification report when threshold is 0.6000000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.876     0.952     0.913       987\n",
      "         1.0      0.947     0.863     0.903       973\n",
      "\n",
      "    accuracy                          0.908      1960\n",
      "   macro avg      0.912     0.908     0.908      1960\n",
      "weighted avg      0.911     0.908     0.908      1960\n",
      "\n",
      "Classification report when threshold is 0.6025000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.875     0.952     0.912       987\n",
      "         1.0      0.947     0.862     0.903       973\n",
      "\n",
      "    accuracy                          0.908      1960\n",
      "   macro avg      0.911     0.907     0.907      1960\n",
      "weighted avg      0.911     0.908     0.907      1960\n",
      "\n",
      "Classification report when threshold is 0.6050000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.875     0.953     0.912       987\n",
      "         1.0      0.948     0.861     0.903       973\n",
      "\n",
      "    accuracy                          0.908      1960\n",
      "   macro avg      0.911     0.907     0.907      1960\n",
      "weighted avg      0.911     0.908     0.907      1960\n",
      "\n",
      "Classification report when threshold is 0.6075000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.873     0.953     0.911       987\n",
      "         1.0      0.948     0.859     0.901       973\n",
      "\n",
      "    accuracy                          0.907      1960\n",
      "   macro avg      0.910     0.906     0.906      1960\n",
      "weighted avg      0.910     0.907     0.906      1960\n",
      "\n",
      "Classification report when threshold is 0.6100000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.872     0.953     0.911       987\n",
      "         1.0      0.948     0.858     0.901       973\n",
      "\n",
      "    accuracy                          0.906      1960\n",
      "   macro avg      0.910     0.906     0.906      1960\n",
      "weighted avg      0.910     0.906     0.906      1960\n",
      "\n",
      "Classification report when threshold is 0.6125000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.870     0.953     0.910       987\n",
      "         1.0      0.948     0.855     0.899       973\n",
      "\n",
      "    accuracy                          0.905      1960\n",
      "   macro avg      0.909     0.904     0.904      1960\n",
      "weighted avg      0.908     0.905     0.904      1960\n",
      "\n",
      "Classification report when threshold is 0.6150000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.869     0.953     0.909       987\n",
      "         1.0      0.948     0.854     0.898       973\n",
      "\n",
      "    accuracy                          0.904      1960\n",
      "   macro avg      0.908     0.904     0.904      1960\n",
      "weighted avg      0.908     0.904     0.904      1960\n",
      "\n",
      "Classification report when threshold is 0.6175000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.868     0.953     0.909       987\n",
      "         1.0      0.947     0.853     0.898       973\n",
      "\n",
      "    accuracy                          0.904      1960\n",
      "   macro avg      0.908     0.903     0.903      1960\n",
      "weighted avg      0.908     0.904     0.903      1960\n",
      "\n",
      "Classification report when threshold is 0.6200000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.867     0.954     0.909       987\n",
      "         1.0      0.949     0.852     0.898       973\n",
      "\n",
      "    accuracy                          0.904      1960\n",
      "   macro avg      0.908     0.903     0.903      1960\n",
      "weighted avg      0.908     0.904     0.903      1960\n",
      "\n",
      "Classification report when threshold is 0.6225000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.868     0.955     0.909       987\n",
      "         1.0      0.950     0.852     0.898       973\n",
      "\n",
      "    accuracy                          0.904      1960\n",
      "   macro avg      0.909     0.904     0.904      1960\n",
      "weighted avg      0.908     0.904     0.904      1960\n",
      "\n",
      "Classification report when threshold is 0.6250000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.867     0.956     0.909       987\n",
      "         1.0      0.951     0.851     0.898       973\n",
      "\n",
      "    accuracy                          0.904      1960\n",
      "   macro avg      0.909     0.904     0.904      1960\n",
      "weighted avg      0.908     0.904     0.904      1960\n",
      "\n",
      "Classification report when threshold is 0.6275000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.866     0.956     0.909       987\n",
      "         1.0      0.951     0.850     0.897       973\n",
      "\n",
      "    accuracy                          0.904      1960\n",
      "   macro avg      0.908     0.903     0.903      1960\n",
      "weighted avg      0.908     0.904     0.903      1960\n",
      "\n",
      "Classification report when threshold is 0.6300000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.865     0.956     0.909       987\n",
      "         1.0      0.951     0.849     0.897       973\n",
      "\n",
      "    accuracy                          0.903      1960\n",
      "   macro avg      0.908     0.903     0.903      1960\n",
      "weighted avg      0.908     0.903     0.903      1960\n",
      "\n",
      "Classification report when threshold is 0.6325000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.864     0.956     0.908       987\n",
      "         1.0      0.950     0.847     0.896       973\n",
      "\n",
      "    accuracy                          0.902      1960\n",
      "   macro avg      0.907     0.902     0.902      1960\n",
      "weighted avg      0.907     0.902     0.902      1960\n",
      "\n",
      "Classification report when threshold is 0.6350000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.862     0.960     0.908       987\n",
      "         1.0      0.955     0.844     0.896       973\n",
      "\n",
      "    accuracy                          0.903      1960\n",
      "   macro avg      0.908     0.902     0.902      1960\n",
      "weighted avg      0.908     0.903     0.902      1960\n",
      "\n",
      "Classification report when threshold is 0.6375000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.862     0.960     0.908       987\n",
      "         1.0      0.955     0.844     0.896       973\n",
      "\n",
      "    accuracy                          0.903      1960\n",
      "   macro avg      0.908     0.902     0.902      1960\n",
      "weighted avg      0.908     0.903     0.902      1960\n",
      "\n",
      "Classification report when threshold is 0.6400000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.862     0.961     0.909       987\n",
      "         1.0      0.956     0.844     0.896       973\n",
      "\n",
      "    accuracy                          0.903      1960\n",
      "   macro avg      0.909     0.903     0.903      1960\n",
      "weighted avg      0.909     0.903     0.903      1960\n",
      "\n",
      "Classification report when threshold is 0.6425000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.861     0.964     0.909       987\n",
      "         1.0      0.958     0.842     0.896       973\n",
      "\n",
      "    accuracy                          0.903      1960\n",
      "   macro avg      0.909     0.903     0.903      1960\n",
      "weighted avg      0.909     0.903     0.903      1960\n",
      "\n",
      "Classification report when threshold is 0.6450000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.860     0.964     0.909       987\n",
      "         1.0      0.958     0.841     0.895       973\n",
      "\n",
      "    accuracy                          0.903      1960\n",
      "   macro avg      0.909     0.902     0.902      1960\n",
      "weighted avg      0.909     0.903     0.902      1960\n",
      "\n",
      "Classification report when threshold is 0.6475000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.858     0.965     0.908       987\n",
      "         1.0      0.959     0.838     0.894       973\n",
      "\n",
      "    accuracy                          0.902      1960\n",
      "   macro avg      0.908     0.901     0.901      1960\n",
      "weighted avg      0.908     0.902     0.901      1960\n",
      "\n",
      "Classification report when threshold is 0.6500000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.856     0.966     0.908       987\n",
      "         1.0      0.960     0.836     0.893       973\n",
      "\n",
      "    accuracy                          0.901      1960\n",
      "   macro avg      0.908     0.901     0.901      1960\n",
      "weighted avg      0.908     0.901     0.901      1960\n",
      "\n",
      "Classification report when threshold is 0.6525000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.855     0.966     0.907       987\n",
      "         1.0      0.960     0.835     0.893       973\n",
      "\n",
      "    accuracy                          0.901      1960\n",
      "   macro avg      0.908     0.900     0.900      1960\n",
      "weighted avg      0.907     0.901     0.900      1960\n",
      "\n",
      "Classification report when threshold is 0.6550000000000002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.855     0.966     0.907       987\n",
      "         1.0      0.960     0.834     0.892       973\n",
      "\n",
      "    accuracy                          0.900      1960\n",
      "   macro avg      0.907     0.900     0.899      1960\n",
      "weighted avg      0.907     0.900     0.900      1960\n",
      "\n",
      "Classification report when threshold is 0.6575000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.853     0.967     0.906       987\n",
      "         1.0      0.961     0.831     0.891       973\n",
      "\n",
      "    accuracy                          0.899      1960\n",
      "   macro avg      0.907     0.899     0.899      1960\n",
      "weighted avg      0.907     0.899     0.899      1960\n",
      "\n",
      "Classification report when threshold is 0.6600000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.853     0.967     0.906       987\n",
      "         1.0      0.961     0.831     0.891       973\n",
      "\n",
      "    accuracy                          0.899      1960\n",
      "   macro avg      0.907     0.899     0.899      1960\n",
      "weighted avg      0.907     0.899     0.899      1960\n",
      "\n",
      "Classification report when threshold is 0.6625000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.853     0.967     0.906       987\n",
      "         1.0      0.961     0.831     0.891       973\n",
      "\n",
      "    accuracy                          0.899      1960\n",
      "   macro avg      0.907     0.899     0.899      1960\n",
      "weighted avg      0.907     0.899     0.899      1960\n",
      "\n",
      "Classification report when threshold is 0.6650000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.853     0.967     0.906       987\n",
      "         1.0      0.961     0.830     0.891       973\n",
      "\n",
      "    accuracy                          0.899      1960\n",
      "   macro avg      0.907     0.898     0.898      1960\n",
      "weighted avg      0.906     0.899     0.898      1960\n",
      "\n",
      "Classification report when threshold is 0.6675000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.852     0.967     0.906       987\n",
      "         1.0      0.961     0.829     0.890       973\n",
      "\n",
      "    accuracy                          0.898      1960\n",
      "   macro avg      0.906     0.898     0.898      1960\n",
      "weighted avg      0.906     0.898     0.898      1960\n",
      "\n",
      "Classification report when threshold is 0.6700000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.851     0.967     0.905       987\n",
      "         1.0      0.961     0.828     0.890       973\n",
      "\n",
      "    accuracy                          0.898      1960\n",
      "   macro avg      0.906     0.897     0.897      1960\n",
      "weighted avg      0.905     0.898     0.897      1960\n",
      "\n",
      "Classification report when threshold is 0.6725000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.850     0.967     0.905       987\n",
      "         1.0      0.961     0.827     0.889       973\n",
      "\n",
      "    accuracy                          0.897      1960\n",
      "   macro avg      0.905     0.897     0.897      1960\n",
      "weighted avg      0.905     0.897     0.897      1960\n",
      "\n",
      "Classification report when threshold is 0.6750000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.850     0.968     0.905       987\n",
      "         1.0      0.962     0.827     0.890       973\n",
      "\n",
      "    accuracy                          0.898      1960\n",
      "   macro avg      0.906     0.897     0.897      1960\n",
      "weighted avg      0.906     0.898     0.897      1960\n",
      "\n",
      "Classification report when threshold is 0.6775000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.850     0.968     0.905       987\n",
      "         1.0      0.962     0.827     0.890       973\n",
      "\n",
      "    accuracy                          0.898      1960\n",
      "   macro avg      0.906     0.897     0.897      1960\n",
      "weighted avg      0.906     0.898     0.897      1960\n",
      "\n",
      "Classification report when threshold is 0.6800000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.850     0.968     0.905       987\n",
      "         1.0      0.962     0.827     0.890       973\n",
      "\n",
      "    accuracy                          0.898      1960\n",
      "   macro avg      0.906     0.897     0.897      1960\n",
      "weighted avg      0.906     0.898     0.897      1960\n",
      "\n",
      "Classification report when threshold is 0.6825000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.849     0.969     0.905       987\n",
      "         1.0      0.963     0.825     0.889       973\n",
      "\n",
      "    accuracy                          0.897      1960\n",
      "   macro avg      0.906     0.897     0.897      1960\n",
      "weighted avg      0.906     0.897     0.897      1960\n",
      "\n",
      "Classification report when threshold is 0.6850000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.848     0.969     0.904       987\n",
      "         1.0      0.963     0.823     0.888       973\n",
      "\n",
      "    accuracy                          0.896      1960\n",
      "   macro avg      0.905     0.896     0.896      1960\n",
      "weighted avg      0.905     0.896     0.896      1960\n",
      "\n",
      "Classification report when threshold is 0.6875000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.846     0.969     0.903       987\n",
      "         1.0      0.963     0.821     0.886       973\n",
      "\n",
      "    accuracy                          0.895      1960\n",
      "   macro avg      0.904     0.895     0.895      1960\n",
      "weighted avg      0.904     0.895     0.895      1960\n",
      "\n",
      "Classification report when threshold is 0.6900000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.845     0.969     0.903       987\n",
      "         1.0      0.963     0.820     0.886       973\n",
      "\n",
      "    accuracy                          0.895      1960\n",
      "   macro avg      0.904     0.894     0.894      1960\n",
      "weighted avg      0.904     0.895     0.894      1960\n",
      "\n",
      "Classification report when threshold is 0.6925000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.845     0.969     0.902       987\n",
      "         1.0      0.963     0.819     0.885       973\n",
      "\n",
      "    accuracy                          0.894      1960\n",
      "   macro avg      0.904     0.894     0.894      1960\n",
      "weighted avg      0.903     0.894     0.894      1960\n",
      "\n",
      "Classification report when threshold is 0.6950000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.842     0.969     0.901       987\n",
      "         1.0      0.962     0.815     0.883       973\n",
      "\n",
      "    accuracy                          0.892      1960\n",
      "   macro avg      0.902     0.892     0.892      1960\n",
      "weighted avg      0.902     0.892     0.892      1960\n",
      "\n",
      "Classification report when threshold is 0.6975000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.839     0.969     0.899       987\n",
      "         1.0      0.962     0.811     0.880       973\n",
      "\n",
      "    accuracy                          0.890      1960\n",
      "   macro avg      0.900     0.890     0.890      1960\n",
      "weighted avg      0.900     0.890     0.890      1960\n",
      "\n",
      "Classification report when threshold is 0.7000000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.837     0.969     0.898       987\n",
      "         1.0      0.962     0.809     0.879       973\n",
      "\n",
      "    accuracy                          0.889      1960\n",
      "   macro avg      0.900     0.889     0.888      1960\n",
      "weighted avg      0.899     0.889     0.889      1960\n",
      "\n",
      "Classification report when threshold is 0.7025000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.836     0.969     0.898       987\n",
      "         1.0      0.962     0.808     0.878       973\n",
      "\n",
      "    accuracy                          0.889      1960\n",
      "   macro avg      0.899     0.888     0.888      1960\n",
      "weighted avg      0.899     0.889     0.888      1960\n",
      "\n",
      "Classification report when threshold is 0.7050000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.836     0.969     0.898       987\n",
      "         1.0      0.962     0.808     0.878       973\n",
      "\n",
      "    accuracy                          0.889      1960\n",
      "   macro avg      0.899     0.888     0.888      1960\n",
      "weighted avg      0.899     0.889     0.888      1960\n",
      "\n",
      "Classification report when threshold is 0.7075000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.833     0.969     0.896       987\n",
      "         1.0      0.962     0.804     0.876       973\n",
      "\n",
      "    accuracy                          0.887      1960\n",
      "   macro avg      0.898     0.886     0.886      1960\n",
      "weighted avg      0.897     0.887     0.886      1960\n",
      "\n",
      "Classification report when threshold is 0.7100000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.833     0.969     0.896       987\n",
      "         1.0      0.962     0.804     0.876       973\n",
      "\n",
      "    accuracy                          0.887      1960\n",
      "   macro avg      0.898     0.886     0.886      1960\n",
      "weighted avg      0.897     0.887     0.886      1960\n",
      "\n",
      "Classification report when threshold is 0.7125000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.834     0.970     0.896       987\n",
      "         1.0      0.963     0.804     0.876       973\n",
      "\n",
      "    accuracy                          0.887      1960\n",
      "   macro avg      0.898     0.887     0.886      1960\n",
      "weighted avg      0.898     0.887     0.886      1960\n",
      "\n",
      "Classification report when threshold is 0.7150000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.833     0.970     0.896       987\n",
      "         1.0      0.963     0.803     0.876       973\n",
      "\n",
      "    accuracy                          0.887      1960\n",
      "   macro avg      0.898     0.886     0.886      1960\n",
      "weighted avg      0.897     0.887     0.886      1960\n",
      "\n",
      "Classification report when threshold is 0.7175000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.831     0.970     0.895       987\n",
      "         1.0      0.963     0.801     0.874       973\n",
      "\n",
      "    accuracy                          0.886      1960\n",
      "   macro avg      0.897     0.885     0.885      1960\n",
      "weighted avg      0.897     0.886     0.885      1960\n",
      "\n",
      "Classification report when threshold is 0.7200000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.830     0.970     0.894       987\n",
      "         1.0      0.963     0.799     0.873       973\n",
      "\n",
      "    accuracy                          0.885      1960\n",
      "   macro avg      0.896     0.884     0.884      1960\n",
      "weighted avg      0.896     0.885     0.884      1960\n",
      "\n",
      "Classification report when threshold is 0.7225000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.829     0.970     0.894       987\n",
      "         1.0      0.963     0.797     0.872       973\n",
      "\n",
      "    accuracy                          0.884      1960\n",
      "   macro avg      0.896     0.883     0.883      1960\n",
      "weighted avg      0.895     0.884     0.883      1960\n",
      "\n",
      "Classification report when threshold is 0.7250000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.827     0.970     0.893       987\n",
      "         1.0      0.963     0.794     0.870       973\n",
      "\n",
      "    accuracy                          0.883      1960\n",
      "   macro avg      0.895     0.882     0.882      1960\n",
      "weighted avg      0.894     0.883     0.882      1960\n",
      "\n",
      "Classification report when threshold is 0.7275000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.826     0.970     0.892       987\n",
      "         1.0      0.963     0.793     0.870       973\n",
      "\n",
      "    accuracy                          0.882      1960\n",
      "   macro avg      0.895     0.882     0.881      1960\n",
      "weighted avg      0.894     0.882     0.881      1960\n",
      "\n",
      "Classification report when threshold is 0.7300000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.826     0.971     0.892       987\n",
      "         1.0      0.964     0.792     0.870       973\n",
      "\n",
      "    accuracy                          0.882      1960\n",
      "   macro avg      0.895     0.882     0.881      1960\n",
      "weighted avg      0.894     0.882     0.881      1960\n",
      "\n",
      "Classification report when threshold is 0.7325000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.825     0.971     0.892       987\n",
      "         1.0      0.964     0.791     0.869       973\n",
      "\n",
      "    accuracy                          0.882      1960\n",
      "   macro avg      0.894     0.881     0.881      1960\n",
      "weighted avg      0.894     0.882     0.881      1960\n",
      "\n",
      "Classification report when threshold is 0.7350000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.824     0.971     0.892       987\n",
      "         1.0      0.964     0.790     0.868       973\n",
      "\n",
      "    accuracy                          0.881      1960\n",
      "   macro avg      0.894     0.880     0.880      1960\n",
      "weighted avg      0.894     0.881     0.880      1960\n",
      "\n",
      "Classification report when threshold is 0.7375000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.824     0.971     0.891       987\n",
      "         1.0      0.964     0.789     0.868       973\n",
      "\n",
      "    accuracy                          0.881      1960\n",
      "   macro avg      0.894     0.880     0.879      1960\n",
      "weighted avg      0.893     0.881     0.880      1960\n",
      "\n",
      "Classification report when threshold is 0.7400000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.824     0.975     0.893       987\n",
      "         1.0      0.968     0.788     0.869       973\n",
      "\n",
      "    accuracy                          0.882      1960\n",
      "   macro avg      0.896     0.881     0.881      1960\n",
      "weighted avg      0.896     0.882     0.881      1960\n",
      "\n",
      "Classification report when threshold is 0.7425000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.823     0.975     0.892       987\n",
      "         1.0      0.968     0.787     0.868       973\n",
      "\n",
      "    accuracy                          0.882      1960\n",
      "   macro avg      0.896     0.881     0.880      1960\n",
      "weighted avg      0.895     0.882     0.881      1960\n",
      "\n",
      "Classification report when threshold is 0.7450000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.821     0.975     0.891       987\n",
      "         1.0      0.968     0.784     0.867       973\n",
      "\n",
      "    accuracy                          0.880      1960\n",
      "   macro avg      0.895     0.879     0.879      1960\n",
      "weighted avg      0.894     0.880     0.879      1960\n",
      "\n",
      "Classification report when threshold is 0.7475000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.820     0.976     0.891       987\n",
      "         1.0      0.969     0.783     0.866       973\n",
      "\n",
      "    accuracy                          0.880      1960\n",
      "   macro avg      0.895     0.879     0.879      1960\n",
      "weighted avg      0.894     0.880     0.879      1960\n",
      "\n",
      "Classification report when threshold is 0.7500000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.820     0.976     0.891       987\n",
      "         1.0      0.969     0.782     0.866       973\n",
      "\n",
      "    accuracy                          0.880      1960\n",
      "   macro avg      0.895     0.879     0.878      1960\n",
      "weighted avg      0.894     0.880     0.878      1960\n",
      "\n",
      "Classification report when threshold is 0.7525000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.819     0.977     0.891       987\n",
      "         1.0      0.971     0.781     0.866       973\n",
      "\n",
      "    accuracy                          0.880      1960\n",
      "   macro avg      0.895     0.879     0.878      1960\n",
      "weighted avg      0.894     0.880     0.878      1960\n",
      "\n",
      "Classification report when threshold is 0.7550000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.819     0.977     0.891       987\n",
      "         1.0      0.971     0.781     0.866       973\n",
      "\n",
      "    accuracy                          0.880      1960\n",
      "   macro avg      0.895     0.879     0.878      1960\n",
      "weighted avg      0.894     0.880     0.878      1960\n",
      "\n",
      "Classification report when threshold is 0.7575000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.816     0.977     0.889       987\n",
      "         1.0      0.970     0.777     0.863       973\n",
      "\n",
      "    accuracy                          0.878      1960\n",
      "   macro avg      0.893     0.877     0.876      1960\n",
      "weighted avg      0.893     0.878     0.876      1960\n",
      "\n",
      "Classification report when threshold is 0.7600000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.815     0.977     0.888       987\n",
      "         1.0      0.970     0.775     0.862       973\n",
      "\n",
      "    accuracy                          0.877      1960\n",
      "   macro avg      0.893     0.876     0.875      1960\n",
      "weighted avg      0.892     0.877     0.875      1960\n",
      "\n",
      "Classification report when threshold is 0.7625000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.815     0.977     0.888       987\n",
      "         1.0      0.970     0.775     0.862       973\n",
      "\n",
      "    accuracy                          0.877      1960\n",
      "   macro avg      0.893     0.876     0.875      1960\n",
      "weighted avg      0.892     0.877     0.875      1960\n",
      "\n",
      "Classification report when threshold is 0.7650000000000003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.815     0.979     0.889       987\n",
      "         1.0      0.973     0.774     0.862       973\n",
      "\n",
      "    accuracy                          0.877      1960\n",
      "   macro avg      0.894     0.876     0.876      1960\n",
      "weighted avg      0.893     0.877     0.876      1960\n",
      "\n",
      "Classification report when threshold is 0.7675000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.814     0.979     0.889       987\n",
      "         1.0      0.973     0.773     0.861       973\n",
      "\n",
      "    accuracy                          0.877      1960\n",
      "   macro avg      0.893     0.876     0.875      1960\n",
      "weighted avg      0.893     0.877     0.875      1960\n",
      "\n",
      "Classification report when threshold is 0.7700000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.814     0.979     0.889       987\n",
      "         1.0      0.973     0.773     0.861       973\n",
      "\n",
      "    accuracy                          0.877      1960\n",
      "   macro avg      0.893     0.876     0.875      1960\n",
      "weighted avg      0.893     0.877     0.875      1960\n",
      "\n",
      "Classification report when threshold is 0.7725000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.812     0.979     0.888       987\n",
      "         1.0      0.973     0.771     0.860       973\n",
      "\n",
      "    accuracy                          0.876      1960\n",
      "   macro avg      0.893     0.875     0.874      1960\n",
      "weighted avg      0.892     0.876     0.874      1960\n",
      "\n",
      "Classification report when threshold is 0.7750000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.812     0.979     0.887       987\n",
      "         1.0      0.973     0.770     0.859       973\n",
      "\n",
      "    accuracy                          0.875      1960\n",
      "   macro avg      0.892     0.874     0.873      1960\n",
      "weighted avg      0.892     0.875     0.874      1960\n",
      "\n",
      "Classification report when threshold is 0.7775000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.808     0.979     0.885       987\n",
      "         1.0      0.973     0.764     0.855       973\n",
      "\n",
      "    accuracy                          0.872      1960\n",
      "   macro avg      0.890     0.871     0.870      1960\n",
      "weighted avg      0.890     0.872     0.870      1960\n",
      "\n",
      "Classification report when threshold is 0.7800000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.807     0.979     0.885       987\n",
      "         1.0      0.972     0.763     0.855       973\n",
      "\n",
      "    accuracy                          0.871      1960\n",
      "   macro avg      0.890     0.871     0.870      1960\n",
      "weighted avg      0.889     0.871     0.870      1960\n",
      "\n",
      "Classification report when threshold is 0.7825000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.807     0.981     0.886       987\n",
      "         1.0      0.975     0.763     0.856       973\n",
      "\n",
      "    accuracy                          0.872      1960\n",
      "   macro avg      0.891     0.872     0.871      1960\n",
      "weighted avg      0.891     0.872     0.871      1960\n",
      "\n",
      "Classification report when threshold is 0.7850000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.805     0.982     0.885       987\n",
      "         1.0      0.976     0.760     0.854       973\n",
      "\n",
      "    accuracy                          0.871      1960\n",
      "   macro avg      0.891     0.871     0.870      1960\n",
      "weighted avg      0.890     0.871     0.870      1960\n",
      "\n",
      "Classification report when threshold is 0.7875000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.803     0.982     0.884       987\n",
      "         1.0      0.976     0.756     0.852       973\n",
      "\n",
      "    accuracy                          0.870      1960\n",
      "   macro avg      0.890     0.869     0.868      1960\n",
      "weighted avg      0.889     0.870     0.868      1960\n",
      "\n",
      "Classification report when threshold is 0.7900000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.802     0.982     0.883       987\n",
      "         1.0      0.976     0.754     0.851       973\n",
      "\n",
      "    accuracy                          0.869      1960\n",
      "   macro avg      0.889     0.868     0.867      1960\n",
      "weighted avg      0.888     0.869     0.867      1960\n",
      "\n",
      "Classification report when threshold is 0.7925000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.801     0.982     0.882       987\n",
      "         1.0      0.976     0.752     0.850       973\n",
      "\n",
      "    accuracy                          0.868      1960\n",
      "   macro avg      0.888     0.867     0.866      1960\n",
      "weighted avg      0.888     0.868     0.866      1960\n",
      "\n",
      "Classification report when threshold is 0.7950000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.800     0.982     0.882       987\n",
      "         1.0      0.976     0.751     0.849       973\n",
      "\n",
      "    accuracy                          0.867      1960\n",
      "   macro avg      0.888     0.867     0.865      1960\n",
      "weighted avg      0.887     0.867     0.865      1960\n",
      "\n",
      "Classification report when threshold is 0.7975000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.800     0.983     0.882       987\n",
      "         1.0      0.977     0.750     0.849       973\n",
      "\n",
      "    accuracy                          0.867      1960\n",
      "   macro avg      0.888     0.867     0.865      1960\n",
      "weighted avg      0.888     0.867     0.865      1960\n",
      "\n",
      "Classification report when threshold is 0.8000000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.799     0.984     0.882       987\n",
      "         1.0      0.978     0.748     0.848       973\n",
      "\n",
      "    accuracy                          0.867      1960\n",
      "   macro avg      0.889     0.866     0.865      1960\n",
      "weighted avg      0.888     0.867     0.865      1960\n",
      "\n",
      "Classification report when threshold is 0.8025000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.796     0.984     0.880       987\n",
      "         1.0      0.978     0.744     0.845       973\n",
      "\n",
      "    accuracy                          0.865      1960\n",
      "   macro avg      0.887     0.864     0.863      1960\n",
      "weighted avg      0.886     0.865     0.863      1960\n",
      "\n",
      "Classification report when threshold is 0.8050000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.793     0.985     0.878       987\n",
      "         1.0      0.980     0.739     0.842       973\n",
      "\n",
      "    accuracy                          0.863      1960\n",
      "   macro avg      0.886     0.862     0.860      1960\n",
      "weighted avg      0.886     0.863     0.861      1960\n",
      "\n",
      "Classification report when threshold is 0.8075000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.791     0.986     0.878       987\n",
      "         1.0      0.981     0.736     0.841       973\n",
      "\n",
      "    accuracy                          0.862      1960\n",
      "   macro avg      0.886     0.861     0.859      1960\n",
      "weighted avg      0.885     0.862     0.859      1960\n",
      "\n",
      "Classification report when threshold is 0.8100000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.790     0.986     0.877       987\n",
      "         1.0      0.981     0.735     0.840       973\n",
      "\n",
      "    accuracy                          0.861      1960\n",
      "   macro avg      0.886     0.860     0.859      1960\n",
      "weighted avg      0.885     0.861     0.859      1960\n",
      "\n",
      "Classification report when threshold is 0.8125000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.788     0.986     0.876       987\n",
      "         1.0      0.981     0.732     0.838       973\n",
      "\n",
      "    accuracy                          0.860      1960\n",
      "   macro avg      0.885     0.859     0.857      1960\n",
      "weighted avg      0.884     0.860     0.857      1960\n",
      "\n",
      "Classification report when threshold is 0.8150000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.787     0.986     0.875       987\n",
      "         1.0      0.981     0.729     0.836       973\n",
      "\n",
      "    accuracy                          0.858      1960\n",
      "   macro avg      0.884     0.857     0.856      1960\n",
      "weighted avg      0.883     0.858     0.856      1960\n",
      "\n",
      "Classification report when threshold is 0.8175000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.785     0.986     0.874       987\n",
      "         1.0      0.981     0.726     0.834       973\n",
      "\n",
      "    accuracy                          0.857      1960\n",
      "   macro avg      0.883     0.856     0.854      1960\n",
      "weighted avg      0.882     0.857     0.854      1960\n",
      "\n",
      "Classification report when threshold is 0.8200000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.783     0.987     0.873       987\n",
      "         1.0      0.982     0.723     0.832       973\n",
      "\n",
      "    accuracy                          0.856      1960\n",
      "   macro avg      0.882     0.855     0.853      1960\n",
      "weighted avg      0.882     0.856     0.853      1960\n",
      "\n",
      "Classification report when threshold is 0.8225000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.780     0.987     0.871       987\n",
      "         1.0      0.982     0.717     0.829       973\n",
      "\n",
      "    accuracy                          0.853      1960\n",
      "   macro avg      0.881     0.852     0.850      1960\n",
      "weighted avg      0.880     0.853     0.850      1960\n",
      "\n",
      "Classification report when threshold is 0.8250000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.779     0.987     0.870       987\n",
      "         1.0      0.982     0.715     0.828       973\n",
      "\n",
      "    accuracy                          0.852      1960\n",
      "   macro avg      0.880     0.851     0.849      1960\n",
      "weighted avg      0.879     0.852     0.849      1960\n",
      "\n",
      "Classification report when threshold is 0.8275000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.775     0.987     0.868       987\n",
      "         1.0      0.982     0.709     0.823       973\n",
      "\n",
      "    accuracy                          0.849      1960\n",
      "   macro avg      0.878     0.848     0.846      1960\n",
      "weighted avg      0.877     0.849     0.846      1960\n",
      "\n",
      "Classification report when threshold is 0.8300000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.771     0.987     0.866       987\n",
      "         1.0      0.981     0.703     0.819       973\n",
      "\n",
      "    accuracy                          0.846      1960\n",
      "   macro avg      0.876     0.845     0.842      1960\n",
      "weighted avg      0.876     0.846     0.843      1960\n",
      "\n",
      "Classification report when threshold is 0.8325000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.769     0.987     0.865       987\n",
      "         1.0      0.981     0.700     0.817       973\n",
      "\n",
      "    accuracy                          0.844      1960\n",
      "   macro avg      0.875     0.843     0.841      1960\n",
      "weighted avg      0.875     0.844     0.841      1960\n",
      "\n",
      "Classification report when threshold is 0.8350000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.766     0.987     0.863       987\n",
      "         1.0      0.981     0.695     0.813       973\n",
      "\n",
      "    accuracy                          0.842      1960\n",
      "   macro avg      0.874     0.841     0.838      1960\n",
      "weighted avg      0.873     0.842     0.838      1960\n",
      "\n",
      "Classification report when threshold is 0.8375000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.764     0.988     0.861       987\n",
      "         1.0      0.982     0.690     0.810       973\n",
      "\n",
      "    accuracy                          0.840      1960\n",
      "   macro avg      0.873     0.839     0.836      1960\n",
      "weighted avg      0.872     0.840     0.836      1960\n",
      "\n",
      "Classification report when threshold is 0.8400000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.762     0.988     0.860       987\n",
      "         1.0      0.982     0.687     0.808       973\n",
      "\n",
      "    accuracy                          0.838      1960\n",
      "   macro avg      0.872     0.837     0.834      1960\n",
      "weighted avg      0.871     0.838     0.834      1960\n",
      "\n",
      "Classification report when threshold is 0.8425000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.760     0.989     0.860       987\n",
      "         1.0      0.984     0.683     0.807       973\n",
      "\n",
      "    accuracy                          0.837      1960\n",
      "   macro avg      0.872     0.836     0.833      1960\n",
      "weighted avg      0.871     0.837     0.833      1960\n",
      "\n",
      "Classification report when threshold is 0.8450000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.756     0.989     0.857       987\n",
      "         1.0      0.984     0.676     0.801       973\n",
      "\n",
      "    accuracy                          0.834      1960\n",
      "   macro avg      0.870     0.833     0.829      1960\n",
      "weighted avg      0.869     0.834     0.829      1960\n",
      "\n",
      "Classification report when threshold is 0.8475000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.755     0.989     0.856       987\n",
      "         1.0      0.984     0.674     0.800       973\n",
      "\n",
      "    accuracy                          0.833      1960\n",
      "   macro avg      0.869     0.832     0.828      1960\n",
      "weighted avg      0.868     0.833     0.828      1960\n",
      "\n",
      "Classification report when threshold is 0.8500000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.751     0.989     0.854       987\n",
      "         1.0      0.983     0.667     0.795       973\n",
      "\n",
      "    accuracy                          0.829      1960\n",
      "   macro avg      0.867     0.828     0.824      1960\n",
      "weighted avg      0.866     0.829     0.824      1960\n",
      "\n",
      "Classification report when threshold is 0.8525000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.749     0.990     0.853       987\n",
      "         1.0      0.985     0.664     0.793       973\n",
      "\n",
      "    accuracy                          0.828      1960\n",
      "   macro avg      0.867     0.827     0.823      1960\n",
      "weighted avg      0.866     0.828     0.823      1960\n",
      "\n",
      "Classification report when threshold is 0.8550000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.745     0.990     0.850       987\n",
      "         1.0      0.985     0.657     0.788       973\n",
      "\n",
      "    accuracy                          0.824      1960\n",
      "   macro avg      0.865     0.823     0.819      1960\n",
      "weighted avg      0.864     0.824     0.819      1960\n",
      "\n",
      "Classification report when threshold is 0.8575000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.744     0.990     0.850       987\n",
      "         1.0      0.985     0.655     0.786       973\n",
      "\n",
      "    accuracy                          0.823      1960\n",
      "   macro avg      0.864     0.822     0.818      1960\n",
      "weighted avg      0.863     0.823     0.818      1960\n",
      "\n",
      "Classification report when threshold is 0.8600000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.743     0.990     0.849       987\n",
      "         1.0      0.984     0.653     0.785       973\n",
      "\n",
      "    accuracy                          0.822      1960\n",
      "   macro avg      0.864     0.821     0.817      1960\n",
      "weighted avg      0.863     0.822     0.817      1960\n",
      "\n",
      "Classification report when threshold is 0.8625000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.742     0.990     0.848       987\n",
      "         1.0      0.984     0.651     0.783       973\n",
      "\n",
      "    accuracy                          0.821      1960\n",
      "   macro avg      0.863     0.820     0.816      1960\n",
      "weighted avg      0.862     0.821     0.816      1960\n",
      "\n",
      "Classification report when threshold is 0.8650000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.737     0.990     0.845       987\n",
      "         1.0      0.984     0.641     0.777       973\n",
      "\n",
      "    accuracy                          0.817      1960\n",
      "   macro avg      0.861     0.816     0.811      1960\n",
      "weighted avg      0.860     0.817     0.811      1960\n",
      "\n",
      "Classification report when threshold is 0.8675000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.735     0.990     0.844       987\n",
      "         1.0      0.984     0.638     0.774       973\n",
      "\n",
      "    accuracy                          0.815      1960\n",
      "   macro avg      0.860     0.814     0.809      1960\n",
      "weighted avg      0.859     0.815     0.809      1960\n",
      "\n",
      "Classification report when threshold is 0.8700000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.731     0.990     0.841       987\n",
      "         1.0      0.984     0.631     0.769       973\n",
      "\n",
      "    accuracy                          0.812      1960\n",
      "   macro avg      0.858     0.810     0.805      1960\n",
      "weighted avg      0.857     0.812     0.805      1960\n",
      "\n",
      "Classification report when threshold is 0.8725000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.729     0.990     0.839       987\n",
      "         1.0      0.984     0.626     0.765       973\n",
      "\n",
      "    accuracy                          0.809      1960\n",
      "   macro avg      0.856     0.808     0.802      1960\n",
      "weighted avg      0.855     0.809     0.802      1960\n",
      "\n",
      "Classification report when threshold is 0.8750000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.725     0.990     0.837       987\n",
      "         1.0      0.984     0.620     0.760       973\n",
      "\n",
      "    accuracy                          0.806      1960\n",
      "   macro avg      0.855     0.805     0.799      1960\n",
      "weighted avg      0.854     0.806     0.799      1960\n",
      "\n",
      "Classification report when threshold is 0.8775000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.723     0.990     0.835       987\n",
      "         1.0      0.984     0.615     0.756       973\n",
      "\n",
      "    accuracy                          0.804      1960\n",
      "   macro avg      0.853     0.802     0.796      1960\n",
      "weighted avg      0.852     0.804     0.796      1960\n",
      "\n",
      "Classification report when threshold is 0.8800000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.721     0.990     0.834       987\n",
      "         1.0      0.983     0.612     0.754       973\n",
      "\n",
      "    accuracy                          0.802      1960\n",
      "   macro avg      0.852     0.801     0.794      1960\n",
      "weighted avg      0.851     0.802     0.795      1960\n",
      "\n",
      "Classification report when threshold is 0.8825000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.719     0.990     0.833       987\n",
      "         1.0      0.983     0.608     0.752       973\n",
      "\n",
      "    accuracy                          0.801      1960\n",
      "   macro avg      0.851     0.799     0.793      1960\n",
      "weighted avg      0.850     0.801     0.793      1960\n",
      "\n",
      "Classification report when threshold is 0.8850000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.717     0.990     0.831       987\n",
      "         1.0      0.983     0.603     0.748       973\n",
      "\n",
      "    accuracy                          0.798      1960\n",
      "   macro avg      0.850     0.797     0.790      1960\n",
      "weighted avg      0.849     0.798     0.790      1960\n",
      "\n",
      "Classification report when threshold is 0.8875000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.715     0.990     0.830       987\n",
      "         1.0      0.983     0.599     0.745       973\n",
      "\n",
      "    accuracy                          0.796      1960\n",
      "   macro avg      0.849     0.795     0.787      1960\n",
      "weighted avg      0.848     0.796     0.788      1960\n",
      "\n",
      "Classification report when threshold is 0.8900000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.712     0.991     0.828       987\n",
      "         1.0      0.985     0.593     0.740       973\n",
      "\n",
      "    accuracy                          0.793      1960\n",
      "   macro avg      0.848     0.792     0.784      1960\n",
      "weighted avg      0.847     0.793     0.785      1960\n",
      "\n",
      "Classification report when threshold is 0.8925000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.710     0.992     0.828       987\n",
      "         1.0      0.986     0.590     0.738       973\n",
      "\n",
      "    accuracy                          0.792      1960\n",
      "   macro avg      0.848     0.791     0.783      1960\n",
      "weighted avg      0.847     0.792     0.783      1960\n",
      "\n",
      "Classification report when threshold is 0.8950000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.708     0.992     0.827       987\n",
      "         1.0      0.986     0.586     0.735       973\n",
      "\n",
      "    accuracy                          0.790      1960\n",
      "   macro avg      0.847     0.789     0.781      1960\n",
      "weighted avg      0.846     0.790     0.781      1960\n",
      "\n",
      "Classification report when threshold is 0.8975000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.707     0.992     0.825       987\n",
      "         1.0      0.986     0.583     0.733       973\n",
      "\n",
      "    accuracy                          0.789      1960\n",
      "   macro avg      0.846     0.787     0.779      1960\n",
      "weighted avg      0.845     0.789     0.779      1960\n",
      "\n",
      "Classification report when threshold is 0.9000000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.704     0.992     0.823       987\n",
      "         1.0      0.986     0.577     0.728       973\n",
      "\n",
      "    accuracy                          0.786      1960\n",
      "   macro avg      0.845     0.784     0.776      1960\n",
      "weighted avg      0.844     0.786     0.776      1960\n",
      "\n",
      "Classification report when threshold is 0.9025000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.703     0.992     0.823       987\n",
      "         1.0      0.986     0.575     0.726       973\n",
      "\n",
      "    accuracy                          0.785      1960\n",
      "   macro avg      0.844     0.783     0.774      1960\n",
      "weighted avg      0.843     0.785     0.775      1960\n",
      "\n",
      "Classification report when threshold is 0.9050000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.703     0.993     0.823       987\n",
      "         1.0      0.988     0.573     0.726       973\n",
      "\n",
      "    accuracy                          0.785      1960\n",
      "   macro avg      0.845     0.783     0.774      1960\n",
      "weighted avg      0.844     0.785     0.775      1960\n",
      "\n",
      "Classification report when threshold is 0.9075000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.703     0.993     0.823       987\n",
      "         1.0      0.988     0.573     0.726       973\n",
      "\n",
      "    accuracy                          0.785      1960\n",
      "   macro avg      0.845     0.783     0.774      1960\n",
      "weighted avg      0.844     0.785     0.775      1960\n",
      "\n",
      "Classification report when threshold is 0.9100000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.700     0.993     0.821       987\n",
      "         1.0      0.987     0.567     0.721       973\n",
      "\n",
      "    accuracy                          0.782      1960\n",
      "   macro avg      0.843     0.780     0.771      1960\n",
      "weighted avg      0.842     0.782     0.771      1960\n",
      "\n",
      "Classification report when threshold is 0.9125000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.696     0.993     0.818       987\n",
      "         1.0      0.987     0.560     0.715       973\n",
      "\n",
      "    accuracy                          0.778      1960\n",
      "   macro avg      0.842     0.777     0.767      1960\n",
      "weighted avg      0.841     0.778     0.767      1960\n",
      "\n",
      "Classification report when threshold is 0.9150000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.692     0.993     0.816       987\n",
      "         1.0      0.987     0.552     0.708       973\n",
      "\n",
      "    accuracy                          0.774      1960\n",
      "   macro avg      0.840     0.772     0.762      1960\n",
      "weighted avg      0.839     0.774     0.762      1960\n",
      "\n",
      "Classification report when threshold is 0.9175000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.689     0.993     0.814       987\n",
      "         1.0      0.987     0.546     0.703       973\n",
      "\n",
      "    accuracy                          0.771      1960\n",
      "   macro avg      0.838     0.769     0.758      1960\n",
      "weighted avg      0.837     0.771     0.759      1960\n",
      "\n",
      "Classification report when threshold is 0.9200000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.686     0.993     0.812       987\n",
      "         1.0      0.987     0.540     0.698       973\n",
      "\n",
      "    accuracy                          0.768      1960\n",
      "   macro avg      0.837     0.766     0.755      1960\n",
      "weighted avg      0.835     0.768     0.755      1960\n",
      "\n",
      "Classification report when threshold is 0.9225000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.683     0.993     0.810       987\n",
      "         1.0      0.987     0.533     0.692       973\n",
      "\n",
      "    accuracy                          0.765      1960\n",
      "   macro avg      0.835     0.763     0.751      1960\n",
      "weighted avg      0.834     0.765     0.751      1960\n",
      "\n",
      "Classification report when threshold is 0.9250000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.679     0.993     0.806       987\n",
      "         1.0      0.986     0.523     0.684       973\n",
      "\n",
      "    accuracy                          0.760      1960\n",
      "   macro avg      0.833     0.758     0.745      1960\n",
      "weighted avg      0.831     0.760     0.745      1960\n",
      "\n",
      "Classification report when threshold is 0.9275000000000007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.677     0.994     0.805       987\n",
      "         1.0      0.988     0.518     0.680       973\n",
      "\n",
      "    accuracy                          0.758      1960\n",
      "   macro avg      0.832     0.756     0.742      1960\n",
      "weighted avg      0.831     0.758     0.743      1960\n",
      "\n",
      "Classification report when threshold is 0.9300000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.671     0.994     0.801       987\n",
      "         1.0      0.988     0.507     0.670       973\n",
      "\n",
      "    accuracy                          0.752      1960\n",
      "   macro avg      0.830     0.750     0.736      1960\n",
      "weighted avg      0.829     0.752     0.736      1960\n",
      "\n",
      "Classification report when threshold is 0.9325000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.669     0.994     0.800       987\n",
      "         1.0      0.988     0.502     0.665       973\n",
      "\n",
      "    accuracy                          0.749      1960\n",
      "   macro avg      0.829     0.748     0.733      1960\n",
      "weighted avg      0.827     0.749     0.733      1960\n",
      "\n",
      "Classification report when threshold is 0.9350000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.661     0.994     0.794       987\n",
      "         1.0      0.987     0.483     0.649       973\n",
      "\n",
      "    accuracy                          0.740      1960\n",
      "   macro avg      0.824     0.738     0.721      1960\n",
      "weighted avg      0.823     0.740     0.722      1960\n",
      "\n",
      "Classification report when threshold is 0.9375000000000007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.658     0.995     0.792       987\n",
      "         1.0      0.989     0.476     0.643       973\n",
      "\n",
      "    accuracy                          0.737      1960\n",
      "   macro avg      0.824     0.735     0.717      1960\n",
      "weighted avg      0.823     0.737     0.718      1960\n",
      "\n",
      "Classification report when threshold is 0.9400000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.656     0.996     0.791       987\n",
      "         1.0      0.991     0.470     0.637       973\n",
      "\n",
      "    accuracy                          0.735      1960\n",
      "   macro avg      0.824     0.733     0.714      1960\n",
      "weighted avg      0.822     0.735     0.715      1960\n",
      "\n",
      "Classification report when threshold is 0.9425000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.652     0.997     0.788       987\n",
      "         1.0      0.993     0.459     0.628       973\n",
      "\n",
      "    accuracy                          0.730      1960\n",
      "   macro avg      0.822     0.728     0.708      1960\n",
      "weighted avg      0.821     0.730     0.709      1960\n",
      "\n",
      "Classification report when threshold is 0.9450000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.647     0.997     0.785       987\n",
      "         1.0      0.993     0.449     0.619       973\n",
      "\n",
      "    accuracy                          0.725      1960\n",
      "   macro avg      0.820     0.723     0.702      1960\n",
      "weighted avg      0.819     0.725     0.702      1960\n",
      "\n",
      "Classification report when threshold is 0.9475000000000007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.644     0.997     0.783       987\n",
      "         1.0      0.993     0.442     0.612       973\n",
      "\n",
      "    accuracy                          0.721      1960\n",
      "   macro avg      0.819     0.719     0.697      1960\n",
      "weighted avg      0.817     0.721     0.698      1960\n",
      "\n",
      "Classification report when threshold is 0.9500000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.641     0.997     0.781       987\n",
      "         1.0      0.993     0.435     0.605       973\n",
      "\n",
      "    accuracy                          0.718      1960\n",
      "   macro avg      0.817     0.716     0.693      1960\n",
      "weighted avg      0.816     0.718     0.693      1960\n",
      "\n",
      "Classification report when threshold is 0.9525000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.639     0.997     0.778       987\n",
      "         1.0      0.993     0.428     0.598       973\n",
      "\n",
      "    accuracy                          0.714      1960\n",
      "   macro avg      0.816     0.712     0.688      1960\n",
      "weighted avg      0.814     0.714     0.689      1960\n",
      "\n",
      "Classification report when threshold is 0.9550000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.633     0.998     0.775       987\n",
      "         1.0      0.995     0.413     0.584       973\n",
      "\n",
      "    accuracy                          0.708      1960\n",
      "   macro avg      0.814     0.706     0.679      1960\n",
      "weighted avg      0.813     0.708     0.680      1960\n",
      "\n",
      "Classification report when threshold is 0.9575000000000007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.628     0.999     0.772       987\n",
      "         1.0      0.997     0.401     0.572       973\n",
      "\n",
      "    accuracy                          0.702      1960\n",
      "   macro avg      0.813     0.700     0.672      1960\n",
      "weighted avg      0.812     0.702     0.672      1960\n",
      "\n",
      "Classification report when threshold is 0.9600000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.626     0.999     0.770       987\n",
      "         1.0      0.997     0.395     0.566       973\n",
      "\n",
      "    accuracy                          0.699      1960\n",
      "   macro avg      0.812     0.697     0.668      1960\n",
      "weighted avg      0.810     0.699     0.668      1960\n",
      "\n",
      "Classification report when threshold is 0.9625000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.619     0.999     0.764       987\n",
      "         1.0      0.997     0.376     0.546       973\n",
      "\n",
      "    accuracy                          0.690      1960\n",
      "   macro avg      0.808     0.688     0.655      1960\n",
      "weighted avg      0.807     0.690     0.656      1960\n",
      "\n",
      "Classification report when threshold is 0.9650000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.613     1.000     0.760       987\n",
      "         1.0      1.000     0.360     0.529       973\n",
      "\n",
      "    accuracy                          0.682      1960\n",
      "   macro avg      0.807     0.680     0.645      1960\n",
      "weighted avg      0.805     0.682     0.645      1960\n",
      "\n",
      "Classification report when threshold is 0.9675000000000007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.609     1.000     0.757       987\n",
      "         1.0      1.000     0.349     0.518       973\n",
      "\n",
      "    accuracy                          0.677      1960\n",
      "   macro avg      0.805     0.675     0.638      1960\n",
      "weighted avg      0.803     0.677     0.638      1960\n",
      "\n",
      "Classification report when threshold is 0.9700000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.605     1.000     0.754       987\n",
      "         1.0      1.000     0.338     0.505       973\n",
      "\n",
      "    accuracy                          0.671      1960\n",
      "   macro avg      0.803     0.669     0.630      1960\n",
      "weighted avg      0.801     0.671     0.631      1960\n",
      "\n",
      "Classification report when threshold is 0.9725000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.597     1.000     0.748       987\n",
      "         1.0      1.000     0.317     0.481       973\n",
      "\n",
      "    accuracy                          0.661      1960\n",
      "   macro avg      0.799     0.658     0.614      1960\n",
      "weighted avg      0.797     0.661     0.615      1960\n",
      "\n",
      "Classification report when threshold is 0.9750000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.593     1.000     0.744       987\n",
      "         1.0      1.000     0.303     0.465       973\n",
      "\n",
      "    accuracy                          0.654      1960\n",
      "   macro avg      0.796     0.652     0.605      1960\n",
      "weighted avg      0.795     0.654     0.606      1960\n",
      "\n",
      "Classification report when threshold is 0.9775000000000007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.587     1.000     0.740       987\n",
      "         1.0      1.000     0.286     0.444       973\n",
      "\n",
      "    accuracy                          0.645      1960\n",
      "   macro avg      0.793     0.643     0.592      1960\n",
      "weighted avg      0.792     0.645     0.593      1960\n",
      "\n",
      "Classification report when threshold is 0.9800000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.581     1.000     0.735       987\n",
      "         1.0      1.000     0.269     0.424       973\n",
      "\n",
      "    accuracy                          0.637      1960\n",
      "   macro avg      0.791     0.635     0.580      1960\n",
      "weighted avg      0.789     0.637     0.581      1960\n",
      "\n",
      "Classification report when threshold is 0.9825000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.575     1.000     0.730       987\n",
      "         1.0      1.000     0.251     0.401       973\n",
      "\n",
      "    accuracy                          0.628      1960\n",
      "   macro avg      0.788     0.625     0.566      1960\n",
      "weighted avg      0.786     0.628     0.567      1960\n",
      "\n",
      "Classification report when threshold is 0.9850000000000005\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.566     1.000     0.723       987\n",
      "         1.0      1.000     0.223     0.365       973\n",
      "\n",
      "    accuracy                          0.614      1960\n",
      "   macro avg      0.783     0.612     0.544      1960\n",
      "weighted avg      0.782     0.614     0.545      1960\n",
      "\n",
      "Classification report when threshold is 0.9875000000000007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.557     1.000     0.715       987\n",
      "         1.0      1.000     0.193     0.324       973\n",
      "\n",
      "    accuracy                          0.599      1960\n",
      "   macro avg      0.778     0.597     0.520      1960\n",
      "weighted avg      0.777     0.599     0.521      1960\n",
      "\n",
      "Classification report when threshold is 0.9900000000000007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.548     1.000     0.708       987\n",
      "         1.0      1.000     0.162     0.279       973\n",
      "\n",
      "    accuracy                          0.584      1960\n",
      "   macro avg      0.774     0.581     0.494      1960\n",
      "weighted avg      0.772     0.584     0.495      1960\n",
      "\n",
      "Classification report when threshold is 0.9925000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.539     1.000     0.700       987\n",
      "         1.0      1.000     0.132     0.233       973\n",
      "\n",
      "    accuracy                          0.569      1960\n",
      "   macro avg      0.769     0.566     0.466      1960\n",
      "weighted avg      0.768     0.569     0.468      1960\n",
      "\n",
      "Classification report when threshold is 0.9950000000000006\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.528     1.000     0.691       987\n",
      "         1.0      1.000     0.094     0.171       973\n",
      "\n",
      "    accuracy                          0.550      1960\n",
      "   macro avg      0.764     0.547     0.431      1960\n",
      "weighted avg      0.762     0.550     0.433      1960\n",
      "\n",
      "Classification report when threshold is 0.9975000000000007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.519     1.000     0.684       987\n",
      "         1.0      1.000     0.061     0.114       973\n",
      "\n",
      "    accuracy                          0.534      1960\n",
      "   macro avg      0.760     0.530     0.399      1960\n",
      "weighted avg      0.758     0.534     0.401      1960\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.49642857, 0.51102941, 0.51129795, ..., 1.        , 1.        ,\n",
       "        1.        ]),\n",
       " array([1.        , 1.        , 1.        , ..., 0.01233299, 0.01130524,\n",
       "        0.        ]),\n",
       " array([0.00000000e+00, 3.44827586e-04, 3.57142857e-04, ...,\n",
       "        9.99500000e-01, 9.99615385e-01, 1.00000000e+00]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "print(\"Test: Victor set\")\n",
    "# drop_cols = ['group','source','set','inappropriate_prob','outlet_photo_url']\n",
    "y_true = tpot_df.query('group==\"test\"')['inappropriate_label']\n",
    "y_score = tpot_df.query('group==\"test\"')['inappropriate_prob']\n",
    "\n",
    "print(f'the auc score is {roc_auc_score(y_true,y_score)}')\n",
    "\n",
    "for thres in np.arange(0.3,1,0.0025):\n",
    "       print(f\"Classification report when threshold is {thres}\")\n",
    "       print(classification_report(y_true,y_score > thres, digits = 3))\n",
    "\n",
    "PrecisionRecallDisplay.from_predictions(y_true, y_score)\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, y_score)\n",
    "\n",
    "precision, recall, thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('torch-scene')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4cecc1edad2a69be17f78d8ff657e79a52ecac530560caa02874b10846fd4e2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
